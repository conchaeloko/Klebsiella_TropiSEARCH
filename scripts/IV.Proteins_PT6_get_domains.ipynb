{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Screen the depolymerase Protein Units against the depolymerase database \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the SWORD2 predictions in the same file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "path_project = \"/media/concha-eloko/Linux/PPT_clean/ficheros_28032023\"\n",
    "dir_out = f\"{path_project}/seekfold_PPT\"\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "path_info = f\"/media/concha-eloko/Linux/depolymerase_building/depolymerase_fold.csv\"\n",
    "info_df = pd.read_csv(path_info , sep = \"\\t\", header = 0)\n",
    "dico_folds = {\"jelly-roll\" : [],\n",
    "              \"alpha/alpha toroid\" : [],\n",
    "              \"right-handed beta-helix\" : [] ,\n",
    "              \"TIM beta/alpha-barrel\" : [],\n",
    "              \"6-bladed beta-propeller\" : [] ,\n",
    "              \"Flavodoxin-like\" : [] ,\n",
    "              \"Alpha/Beta hydrolase fold\" : [] ,\n",
    "              \"Other\" : [],\n",
    "             }\n",
    "\n",
    "outputs = [f\"{dir_out}/{file}\" for file in os.listdir(dir_out) if file[-3:]==\"out\"]\n",
    "header_seekfold = [\"query\",\"target\",\"pident\",\"alnlen\",\"gapopen\",\"qstart\",\"qend\",\"tstart\",\"tend\",\"bits\",\"prob\"]\n",
    "depo_results = {}\n",
    "for results in outputs :\n",
    "    results_df = pd.read_csv(f\"{results}\", sep = \"\\t\" , names = header_seekfold)\n",
    "    for _,row in results_df.iterrows() :\n",
    "        fold = info_df[info_df[\"ID\"] == row[\"target\"]][\"X_Group_Name\"].values[0]\n",
    "        if fold != \"jelly-roll\" :\n",
    "            if row[\"prob\"] >= 0.5 :\n",
    "                depo_results[row[\"query\"].split(\".pdb\")[0]] = {\"Fold\" : fold , \"Prob\" : row[\"prob\"]}\n",
    "            elif fold == \"right-handed beta-helix\" and row[\"prob\"] >= 0.2 :\n",
    "                depo_results[row[\"query\"].split(\".pdb\")[0]] = {\"Fold\" : fold , \"Prob\" : row[\"prob\"]}\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1987"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(depo_results)\n",
    "\n",
    "# Apparently, all the good ppt are already in place. Let's check with minibatch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "path_project = \"/media/concha-eloko/Linux/PPT_clean/ficheros_28032023\"\n",
    "dir_out = f\"{path_project}/seekfold_minibatch\"\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "path_info = f\"/media/concha-eloko/Linux/depolymerase_building/depolymerase_fold.csv\"\n",
    "info_df = pd.read_csv(path_info , sep = \"\\t\", header = 0)\n",
    "dico_folds = {\"jelly-roll\" : [],\n",
    "              \"alpha/alpha toroid\" : [],\n",
    "              \"right-handed beta-helix\" : [] ,\n",
    "              \"TIM beta/alpha-barrel\" : [],\n",
    "              \"6-bladed beta-propeller\" : [] ,\n",
    "              \"Flavodoxin-like\" : [] ,\n",
    "              \"Alpha/Beta hydrolase fold\" : [] ,\n",
    "              \"Other\" : [],\n",
    "             }\n",
    "\n",
    "outputs = [f\"{dir_out}/{file}\" for file in os.listdir(dir_out) if file[-3:]==\"out\"]\n",
    "header_seekfold = [\"query\",\"target\",\"pident\",\"alnlen\",\"gapopen\",\"qstart\",\"qend\",\"tstart\",\"tend\",\"bits\",\"prob\"]\n",
    "depo_results = {}\n",
    "for results in outputs :\n",
    "    results_df = pd.read_csv(f\"{results}\", sep = \"\\t\" , names = header_seekfold)\n",
    "    for _,row in results_df.iterrows() :\n",
    "        fold = info_df[info_df[\"ID\"] == row[\"target\"]][\"X_Group_Name\"].values[0]\n",
    "        if fold != \"jelly-roll\" :\n",
    "            if row[\"prob\"] >= 0.5 :\n",
    "                depo_results[row[\"query\"].split(\".pdb\")[0]] = {\"Fold\" : fold , \"Prob\" : row[\"prob\"]}\n",
    "            elif fold == \"right-handed beta-helix\" and row[\"prob\"] >= 0.2 :\n",
    "                depo_results[row[\"query\"].split(\".pdb\")[0]] = {\"Fold\" : fold , \"Prob\" : row[\"prob\"]}\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "649"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(depo_results)\n",
    "\n",
    "# All the minibatch as well. Let's start the scan !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# The command : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "foldseek createdb \\\n",
    "/home/conchae/depolymerase/pdb_depolymerase_domains \\\n",
    "/home/conchae/depolymerase/RefDepo_domains/RefDepo_domains_db\n",
    "\n",
    "# Generate index files : \n",
    "\n",
    "foldseek createindex \\\n",
    "/home/conchae/depolymerase/RefDepo_domains/RefDepo_domains_db \\ \n",
    "/home/conchae/depolymerase/tmp/tmp\n",
    "\n",
    "# *************************\n",
    "#!/bin/bash\n",
    "#BATCH --job-name=create_db\n",
    "#SBATCH --qos=short \n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=5\n",
    "#SBATCH --mem=50gb \n",
    "#SBATCH --time=1-00:00:00 \n",
    "#SBATCH --output=create_db%j.log \n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate HH-suite3\n",
    "\n",
    "foldseek createdb \\\n",
    "/home/conchae/depolymerase/pdb_depolymerase_domains \\\n",
    "/home/conchae/depolymerase/RefDepo_domains/RefDepo_domains_db\n",
    "\n",
    "# Generate index files : \n",
    "\n",
    "foldseek createindex \\\n",
    "/home/conchae/depolymerase/RefDepo_domains/RefDepo_domains_db \\ \n",
    "/home/conchae/depolymerase/tmp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The PPT dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "path_project = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "path_pdb = f\"{path_project}/output_ppt\"\n",
    "path_prot = f\"{path_project}/sword2_DepoSeq_pt2\"\n",
    "path_db = \"/home/conchae/depolymerase/RefDepo_domains/RefDepo_domains_db\"\n",
    "path_tmp = f\"{path_project}/tmp/tmp_depo\"\n",
    "\n",
    "def seek_beta_helix(path_in) :\n",
    "    with open(f\"{path_project}/scan_full.ppt.log\",\"a+\") as outfile : \n",
    "        dir_out = f\"{path_project}/seekfold_PPT_full\"\n",
    "        protein_id = path_in.split(\"/\")[-1].split(\".pdb\")[0]\n",
    "        path_out = f\"{dir_out}/{protein_id}.out\"\n",
    "        output_frmt = f\"query,target,pident,alnlen,gapopen,qstart,qend,tstart,tend,bits,prob,alntmscore\"\n",
    "        seek = f\"foldseek easy-search {path_in} {path_db} {path_out} {path_tmp} --format-output {output_frmt}\"\n",
    "        seek_process = subprocess.Popen(seek, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "        press_out, press_err = seek_process.communicate()\n",
    "        print (press_out, press_err)\n",
    "        outfile.write(f\"{protein_id}\\n\")\n",
    "        \n",
    "\n",
    "prot_full = ['2601', '3287', '7104', '6022', '2743', '3702', '6065', '3898', '158', '4677', '6972', '5351', '2758', '832', '3867', '5159', '5111', '7033', '4502', '4486', '3536', '4294', '3162', '4023', '598', '5736', '4117', '7084', '2563', '1777', '993', '3379', '6044', '5650', '5579', '2750', '5287', '5450', '3314', '5538', '1840', '764', '5979', '1695', '6826', '6754', '4704', '4013', '7015', '1604', '1182', '4038', '3649', '5857', '4712', '2632', '2892', '3471', '5512', '1287', '5610', '6887', '1812', '530', '3547', '1388', '6012']\n",
    "\n",
    "paths_full = []\n",
    "for file in prot_full :\n",
    "    path = f\"{path_pdb}/{file}.pdb\"\n",
    "    paths_full.append(path)\n",
    "\n",
    "\n",
    "#paths_full = []\n",
    "#for file in os.listdir(f\"{path_prot}\") :\n",
    "#    path = f\"{path_pdb}/{file}.pdb\"\n",
    "#    if os.path.isfile(f\"{path_project}/seekfold_PPT_full/{file}.out\") == False :\n",
    "#        paths_full.append(path)\n",
    "\n",
    "for path in paths_full :\n",
    "    seek_beta_helix(path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with ThreadPool(20) as p:\n",
    "        p.map(seek_beta_helix, paths_full)\n",
    "    \n",
    "# ******************************************************************************************\n",
    "#!/bin/bash\n",
    "#BATCH --job-name=seek_PPT__\n",
    "#SBATCH --qos=short \n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=30\n",
    "#SBATCH --mem=90gb \n",
    "#SBATCH --time=1-00:00:00 \n",
    "#SBATCH --output=seek_PPT__%j.log \n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate HH-suite3\n",
    "\n",
    "#python /home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/script_files/seek_betahelix.full.ppt.py\n",
    "\n",
    "python /home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/script_files/missing_full.ppt.py\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "path_project = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "path_pdb = f\"{path_project}/sword2_DepoSeq_pt2\"\n",
    "path_db = \"/home/conchae/depolymerase/RefDepo_domains/RefDepo_domains_db\"\n",
    "path_tmp = f\"{path_project}/tmp/tmp_mini\"\n",
    "\n",
    "def seek_beta_helix(path_in) :\n",
    "    with open(f\"{path_project}/scan_domains.ppt.log\",\"a+\") as outfile : \n",
    "        dir_out = f\"{path_project}/seekfold_PPT_domains\"\n",
    "        protein_id = path_in.split(\"/\")[-1].split(\".pdb\")[0]\n",
    "        path_out = f\"{dir_out}/{protein_id}.out\"\n",
    "        output_frmt = f\"query,target,pident,alnlen,gapopen,qstart,qend,tstart,tend,bits,prob\"\n",
    "        seek = f\"foldseek easy-search {path_in} {path_db} {path_out} {path_tmp} --format-output {output_frmt}\"\n",
    "        seek_process = subprocess.Popen(seek, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "        press_out, press_err = seek_process.communicate()\n",
    "        print (press_out, press_err)\n",
    "        outfile.write(f\"{protein_id}\\n\")\n",
    "\n",
    "paths_domain = []\n",
    "for file in os.listdir(f\"{path_pdb}\") :\n",
    "    try : \n",
    "        for file_2 in os.listdir(f\"{path_pdb}/{file}/{file}_A/Protein_Units\") :\n",
    "            if file_2[-3:] == \"pdb\" :\n",
    "                file_2_name = file_2.split(\".pdb\")[0]\n",
    "                if os.path.isfile(f\"{path_project}/seekfold_PPT_domains/{file_2_name}.out\") == False :\n",
    "                    path = f\"{path_pdb}/{file}/{file}_A/Protein_Units/{file_2}\"\n",
    "                    paths_domain.append(path)\n",
    "    except Exception as e:\n",
    "        print(file)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with ThreadPool(30) as p:\n",
    "        p.map(seek_beta_helix, paths_domain)\n",
    "    \n",
    "# ******************************************************************************************\n",
    "#!/bin/bash\n",
    "#BATCH --job-name=seek_PPT__\n",
    "#SBATCH --partition=medium \n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=40\n",
    "#SBATCH --mem=90gb \n",
    "#SBATCH --time=2-00:00:00 \n",
    "#SBATCH --output=seek_PPT__%j.log \n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate HH-suite3\n",
    "\n",
    "python /home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/script_files/seek_betahelix.ppt.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The minibatch dataset : full proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "path_project = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "path_pdb = f\"{path_project}/out_minibatch\"\n",
    "path_prot = f\"{path_project}/sword2_Minibatch_pt2\"\n",
    "path_db = \"/home/conchae/depolymerase/RefDepo_domains/RefDepo_domains_db\"\n",
    "path_tmp = f\"{path_project}/tmp/tmp_mini\"\n",
    "\n",
    "def seek_beta_helix(path_in) :\n",
    "    with open(f\"{path_project}/scan_full.minibatch.log\",\"a+\") as outfile : \n",
    "        dir_out = f\"{path_project}/seekfold_minibatch_full\"\n",
    "        protein_id = path_in.split(\"/\")[-1].split(\".pdb\")[0]\n",
    "        path_out = f\"{dir_out}/{protein_id}.out\"\n",
    "        output_frmt = f\"query,target,pident,alnlen,gapopen,qstart,qend,tstart,tend,bits,prob,alntmscore\"\n",
    "        seek = f\"foldseek easy-search {path_in} {path_db} {path_out} {path_tmp} --format-output {output_frmt}\"\n",
    "        seek_process = subprocess.Popen(seek, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "        press_out, press_err = seek_process.communicate()\n",
    "        print (press_out, press_err)\n",
    "        outfile.write(f\"{protein_id}\\n\")\n",
    "\n",
    "        \n",
    "prot_full = ['1576', '379', '423', '1934', '1906', '1220', '1902', '179', '1755', '2143', '1108', '2113', '253', '1326', '1585', '1081', '1581', '1504', '15', '339', '600', '2061', '337', '2135', '1520', '1901', '1524', '1440', '1192', '1233', '1568', '1693', '2173', '393', '1587', '850', '1281', '77', '1286', '723', '1283']\n",
    "\n",
    "paths_full = []\n",
    "for file in prot_full :\n",
    "    path = f\"{path_pdb}/{file}.pdb\"\n",
    "    paths_full.append(path)\n",
    "\n",
    "\n",
    "for path in paths_full :\n",
    "    seek_beta_helix(path)\n",
    "\n",
    "        \n",
    "paths_full = []\n",
    "for file in os.listdir(f\"{path_prot}\") :\n",
    "    path = f\"{path_pdb}/{file}.pdb\"\n",
    "    if os.path.isfile(f\"{path_project}/seekfold_minibatch_full/{file}.out\") == False :\n",
    "        paths_full.append(path)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with ThreadPool(30) as p:\n",
    "        p.map(seek_beta_helix, paths_full)\n",
    "    \n",
    "# ******************************************************************************************\n",
    "#!/bin/bash\n",
    "#BATCH --job-name=seek_PPT__\n",
    "#SBATCH --qos=medium \n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=40\n",
    "#SBATCH --mem=90gb \n",
    "#SBATCH --time=2-00:00:00 \n",
    "#SBATCH --output=seek_PPT__%j.log \n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate HH-suite3\n",
    "\n",
    "python /home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/script_files/seek_betahelix.full.minibatch.py\n",
    "\n",
    "python /home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/script_files/missing_full.minibatch.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "path_project = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "path_pdb = f\"{path_project}/sword2_Minibatch_pt2\"\n",
    "path_db = \"/home/conchae/depolymerase/RefDepo_domains/RefDepo_domains_db\"\n",
    "path_tmp = f\"{path_project}/tmp\"\n",
    "\n",
    "def seek_beta_helix(path_in) :\n",
    "    with open(f\"{path_project}/scan_domains.minibatch.log\",\"a+\") as outfile : \n",
    "        dir_out = f\"{path_project}/seekfold_minibatch_domains\"\n",
    "        protein_id = path_in.split(\"/\")[-1].split(\".pdb\")[0]\n",
    "        path_out = f\"{dir_out}/{protein_id}.out\"\n",
    "        output_frmt = f\"query,target,pident,alnlen,gapopen,qstart,qend,tstart,tend,bits,prob\"\n",
    "        seek = f\"foldseek easy-search {path_in} {path_db} {path_out} {path_tmp} --format-output {output_frmt}\"\n",
    "        seek_process = subprocess.Popen(seek, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "        press_out, press_err = seek_process.communicate()\n",
    "        print (press_out, press_err)\n",
    "        outfile.write(f\"{protein_id}\\n\")\n",
    "\n",
    "    \n",
    "paths_domain = []\n",
    "for file in os.listdir(f\"{path_pdb}\") :\n",
    "    try : \n",
    "        for file_2 in os.listdir(f\"{path_pdb}/{file}/{file}_A/Protein_Units\") :\n",
    "            if file_2[-3:] == \"pdb\" :\n",
    "                file_2_name = file_2.split(\".pdb\")[0]\n",
    "                if os.path.isfile(f\"{path_project}/seekfold_minibatch_domains/{file_2_name}.out\") == False :\n",
    "                    path = f\"{path_pdb}/{file}/{file}_A/Protein_Units/{file_2}\"\n",
    "                    paths_domain.append(path)\n",
    "    except Exception as e:\n",
    "        print(file)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with ThreadPool(30) as p:\n",
    "        p.map(sword2_pred, paths_domain)\n",
    "        \n",
    "        \n",
    "# ******************************************************************************************\n",
    "#!/bin/bash\n",
    "#BATCH --job-name=seek_PPT__\n",
    "#SBATCH --qos=medium \n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=40\n",
    "#SBATCH --mem=100gb \n",
    "#SBATCH --time=1-00:00:00 \n",
    "#SBATCH --output=seek_PPT__%j.log \n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate HH-suite3\n",
    "\n",
    "python /home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/script_files/seek_betahelix.minibatch.py\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Missing SWORD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "/home/conchae/software/SWORD2/SWORD2.py \\\n",
    "-i 2009.pdb \\\n",
    "-o /home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/sword2_Minibatch_pt2/2099 \\\n",
    "-x 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Scan the results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Getting the proteins of interest :\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_project = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "\n",
    "# ***************************************\n",
    "# PPT :\n",
    "dir_out = f\"{path_project}/seekfold_PPT_full\"\n",
    "# ***************************************\n",
    "# Minibatch\n",
    "dir_out = f\"{path_project}/seekfold_minibatch_full\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "\n",
    "outputs = [f\"{dir_out}/{file}\" for file in os.listdir(dir_out) if file[-3:]==\"out\"]\n",
    "path_info = f\"/home/conchae/depolymerase/depolymerase_fold.csv\"\n",
    "info_df = pd.read_csv(path_info , sep = \"\\t\", header = 0)\n",
    "\n",
    "header_seekfold = [\"query\",\"target\",\"pident\",\"alnlen\",\"gapopen\",\"qstart\",\"qend\",\"tstart\",\"tend\",\"bits\",\"prob\",\"aln_score\"]\n",
    "dico_folds_ppt = {\"jelly-roll\" : [],\n",
    "              \"alpha/alpha toroid\" : [],\n",
    "              \"right-handed beta-helix\" : [] ,\n",
    "              \"TIM beta/alpha-barrel\" : [],\n",
    "              \"6-bladed beta-propeller\" : [] ,\n",
    "              \"Flavodoxin-like\" : [] ,\n",
    "              \"Alpha/Beta hydrolase fold\" : [] ,\n",
    "              \"Other\" : [],\n",
    "             }\n",
    "\n",
    "depo_results = {}\n",
    "for results in tqdm(outputs) :\n",
    "    results_df = pd.read_csv(f\"{results}\", sep = \"\\t\" , names = header_seekfold)\n",
    "    for _,row in results_df.iterrows() :\n",
    "        fold = info_df[info_df[\"ID\"] == row[\"target\"]][\"X_Group_Name\"].values[0]\n",
    "        if row[\"alnlen\"] > 200 :\n",
    "            if row[\"prob\"] >= 0.5 :\n",
    "                depo_results[row[\"query\"].split(\".pdb\")[0]] = (fold , row[\"prob\"])\n",
    "                break\n",
    "            elif fold == \"right-handed beta-helix\" and row[\"prob\"] >= 0.2 :\n",
    "                depo_results[row[\"query\"].split(\".pdb\")[0]] = (fold , row[\"prob\"])\n",
    "                \n",
    "for fold in dico_folds_ppt : \n",
    "    print(f\"The {fold} presented {len(dico_folds_ppt[fold])} depolymerases.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Writing the dico "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "import pandas as pd \n",
    "from Bio import SeqIO\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "\n",
    "path_project = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "\n",
    "# ********************************************************\n",
    "# PPT version : \n",
    "dir_out_full = f\"{path_project}/seekfold_PPT_full\"\n",
    "dir_out = f\"{path_project}/seekfold_PPT_domains\"\n",
    "path_swords_out = f\"{path_project}/sword2_DepoSeq_pt2\"\n",
    "# *****************************************************\n",
    "# Minibatch version :\n",
    "dir_out_full = f\"{path_project}/seekfold_minibatch_full\"\n",
    "dir_out = f\"{path_project}/seekfold_minibatch_domains\"\n",
    "path_swords_out = f\"{path_project}/sword2_Minibatch_pt2\"\n",
    "# *********************************************************\n",
    "\n",
    "path_info = f\"/home/conchae/depolymerase/depolymerase_fold.csv\"\n",
    "info_df = pd.read_csv(path_info , sep = \"\\t\", header = 0)\n",
    "\n",
    "header_seekfold = [\"query\",\"target\",\"pident\",\"alnlen\",\"gapopen\",\"qstart\",\"qend\",\"tstart\",\"tend\",\"bits\",\"prob\",\"aln_score\"]\n",
    "dico_folds_77 = {\"jelly-roll\" : [],\n",
    "              \"alpha/alpha toroid\" : [],\n",
    "              \"right-handed beta-helix\" : [] ,\n",
    "              \"TIM beta/alpha-barrel\" : [],\n",
    "              \"6-bladed beta-propeller\" : [] ,\n",
    "              \"Flavodoxin-like\" : [] ,\n",
    "              \"Alpha/Beta hydrolase fold\" : [] ,\n",
    "              \"Other\" : [],\n",
    "             }\n",
    "\n",
    "errors = {'A1l_00058_A_1_129_274.pdb',\n",
    " 'AF-A0A089GJA0-F1-model_v4.pdb',\n",
    " 'AF-A0A4V2M274-F1-model_v4.pdb',\n",
    " 'AF-A0A7W9JCS6-F1-model_v4.pdb','AF-A0A658Y395-F1-model_v4.pdb'}\n",
    "\n",
    "dico_out = {}\n",
    "for file in os.listdir(dir_out) :\n",
    "    protein = file.split(\"_A\")[0]\n",
    "    if protein not in dico_out : \n",
    "        tmp_list = []\n",
    "        tmp_list.append(f\"{dir_out}/{file}\")\n",
    "        dico_out[protein] = tmp_list\n",
    "    else :\n",
    "        dico_out[protein].append(f\"{dir_out}/{file}\")\n",
    "\n",
    "dico_domain_result = {}\n",
    "for protein in tqdm(dico_out) :\n",
    "    the_winner = (0,0,0)\n",
    "    len_protein = len(list(SeqIO.parse(f\"{path_swords_out}/{protein}/{protein}_A/SWORD/{protein}_A/{protein}_A.fasta\", \"fasta\"))[0])\n",
    "    # Collecting data for each proteins\n",
    "    results_full_prot = pd.read_csv(f\"{dir_out_full}/{protein}.out\" , sep = \"\\t\" , names = header_seekfold).fillna(\"wtf\")\n",
    "    results_full_prot = results_full_prot[~results_full_prot[\"target\"].isin(errors)]\n",
    "    for _,row in results_full_prot.iterrows():\n",
    "        fold = info_df[info_df[\"ID\"] == row[\"target\"]][\"X_Group_Name\"].values[0]\n",
    "        if fold != \"jelly-roll\" :\n",
    "            #full_score = int(row[\"bits\"])**1.2 / len_protein**0.40\n",
    "            full_score = int(row[\"bits\"])\n",
    "            target = row[\"target\"]\n",
    "            break\n",
    "    the_full_prot = (full_score , f\"len alignemnt : {row['alnlen']}\" ,f\"Full protein {protein}\")\n",
    "    for path in dico_out[protein] :\n",
    "        if os.path.getsize(path) > 0 :\n",
    "            results_df = pd.read_csv(f\"{path}\", sep = \"\\t\" , names = header_seekfold).fillna(\"wtf\")\n",
    "            results_df = results_df[results_df[\"target\"] == target]\n",
    "            if results_df.empty == False :\n",
    "                aa_end = results_df[\"query\"].values[0].split(\"_\")[-1].split(\".pdb\")[0]\n",
    "                aa_start = results_df[\"query\"].values[0].split(\"_\")[-2]\n",
    "                PU_length = int(aa_end) - int(aa_start)\n",
    "                #score = int(results_df[\"bits\"].values[0])**1.2 / PU_length**0.40\n",
    "                score = int(results_df[\"bits\"].values[0]) \n",
    "                contender = (score , PU_length ,f\"len alignemnt : {results_df['alnlen'].values[0]}\",results_df[\"query\"].values[0])\n",
    "                if contender[0] > the_winner[0] :\n",
    "                    the_winner = contender\n",
    "                elif contender[0] == the_winner[0] :\n",
    "                    if contender[1] < the_winner[1] :\n",
    "                        the_winner = contender\n",
    "                else :\n",
    "                    pass\n",
    "    if the_full_prot[0] > (the_winner[0] + 25) :\n",
    "    #if the_full_prot[0] > (the_winner[0] + 25) :\n",
    "        the_winner = the_full_prot \n",
    "    if the_winner[0] > 0 :\n",
    "        dico_domain_result[protein] = the_winner\n",
    "    \n",
    "# ********************************************************\n",
    "# PPT version : \n",
    "with open(f\"{path_project}/ppt.domains.fine.json\", \"w\") as outfile:\n",
    "    json.dump(dico_domain_result, outfile)\n",
    "    \n",
    "# *****************************************************\n",
    "# Minibatch version :\n",
    "with open(f\"{path_project}/minibatch.domains.json\", \"w\") as outfile:\n",
    "    json.dump(dico_domain_result, outfile)\n",
    "    \n",
    "with open(f\"{path_project}/minibatch.domains.fine.json\", \"w\") as outfile:\n",
    "    json.dump(dico_domain_result, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing : \n",
    "\n",
    "#dico_domain_result = {}\n",
    "full_prot_repeat = []\n",
    "missing_fold = set()\n",
    "for protein in tqdm(dico_out) :\n",
    "    the_winner = (0,0,0)\n",
    "    # Collecting data for each proteins\n",
    "    if os.path.isfile (f\"{dir_out_full}/{protein}.out\") :\n",
    "        results_full_prot = pd.read_csv(f\"{dir_out_full}/{protein}.out\" , sep = \"\\t\" , names = header_seekfold).fillna(\"nothing\")\n",
    "        results_full_prot = results_full_prot[~results_full_prot[\"target\"].isin(errors)]\n",
    "        #print(results_full_prot)\n",
    "        for _,row in results_full_prot.iterrows():\n",
    "            try : \n",
    "                fold = info_df[info_df[\"ID\"] == row[\"target\"]][\"X_Group_Name\"].values[0]\n",
    "            except IndexError :\n",
    "                missing_fold.add(row[\"target\"])\n",
    "                print(row[\"target\"])\n",
    "    else :\n",
    "        full_prot_repeat.append(protein)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Dealing with the ambiguous ones :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "import pandas as pd \n",
    "from Bio import SeqIO\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "\n",
    "path_project = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "\n",
    "# *****************************************************\n",
    "# PPT version :\n",
    "dico_ppt = json.load(open(f\"{path_project}/ppt.domains.json\"))\n",
    "dico_ppt_fine = json.load(open(f\"{path_project}/ppt.domains.fine.json\"))\n",
    "\n",
    "ppt_consensus = {}\n",
    "to_check = []\n",
    "for protein in dico_ppt : \n",
    "    if (len(dico_ppt[protein]) == len(dico_ppt_fine[protein])) and len(dico_ppt[protein]) == 4 :\n",
    "        if dico_ppt[protein][3] != dico_ppt_fine[protein][3] :\n",
    "            to_check.append((\"raw\",dico_ppt[protein],\"fine\",dico_ppt_fine[protein]))    \n",
    "        else :\n",
    "            ppt_consensus[protein] = dico_ppt_fine[protein][3]\n",
    "    elif len(dico_ppt[protein]) != len(dico_ppt_fine[protein]) :\n",
    "        to_check.append((\"raw\",dico_ppt[protein],\"fine\",dico_ppt_fine[protein]))\n",
    "    else :\n",
    "        ppt_consensus[protein] = \"full sequence\"\n",
    "        pass\n",
    "    \n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(width = 150, compact = True)\n",
    "pp.pprint(to_check)\n",
    "\n",
    "# quick check :\n",
    "to_discard = []\n",
    "for prot in ppt_consensus :\n",
    "    if prot not in depo_results :\n",
    "        to_discard.append(prot)\n",
    "        print(prot)\n",
    "        \n",
    "dico_ppt_clean = {}\n",
    "for prot in ppt_consensus :\n",
    "    if prot not in to_discard :\n",
    "        if ppt_consensus[prot] != \"full sequence\" : \n",
    "            len_domain = int(ppt_consensus[prot].split(\"_\")[-1].split(\".\")[0]) - int(ppt_consensus[prot].split(\"_\")[-2])\n",
    "            if len_domain >= 200 :\n",
    "                dico_ppt_clean[prot] = ppt_consensus[prot]\n",
    "            else :\n",
    "                dico_ppt_clean[prot] = \"full sequence\"\n",
    "        \n",
    "        \n",
    "# PPT version : \n",
    "with open(f\"{path_project}/ppt.domains.clean_final.json\", \"w\") as outfile:\n",
    "    json.dump(dico_ppt_clean, outfile)\n",
    "\n",
    "\n",
    "\n",
    "# *****************************************************\n",
    "# minibatch version :\n",
    "dico_mini = json.load(open(f\"{path_project}/minibatch.domains.json\"))\n",
    "dico_mini_fine = json.load(open(f\"{path_project}/minibatch.domains.fine.json\"))\n",
    "        \n",
    "minibatch_consensus = {}\n",
    "to_check = []\n",
    "for protein in dico_mini : \n",
    "    if (len(dico_mini[protein]) == len(dico_mini_fine[protein])) and len(dico_mini[protein]) == 4 :\n",
    "        if dico_mini[protein][3] != dico_mini_fine[protein][3] :\n",
    "            to_check.append((\"raw\",dico_mini[protein],\"fine\",dico_mini_fine[protein])) \n",
    "        else :\n",
    "            minibatch_consensus[protein] = dico_mini_fine[protein][3]\n",
    "    elif len(dico_mini[protein]) != len(dico_mini_fine[protein]) :\n",
    "        to_check.append((\"raw\",dico_mini[protein],\"fine\",dico_mini_fine[protein]))\n",
    "    else :\n",
    "        minibatch_consensus[protein] = \"full sequence\"\n",
    "        pass\n",
    "    \n",
    "#import pprint\n",
    "#pp = pprint.PrettyPrinter(width = 150, compact = True)\n",
    "\n",
    "pp.pprint(to_check)\n",
    "to_discard = []\n",
    "for prot in minibatch_consensus :\n",
    "    if prot not in depo_results :\n",
    "        to_discard.append(prot)\n",
    "        print(prot)\n",
    "        \n",
    "dico_mini_clean = {}\n",
    "for prot in minibatch_consensus :\n",
    "    if prot not in to_discard :\n",
    "        if minibatch_consensus[prot] != \"full sequence\" : \n",
    "            len_domain = int(minibatch_consensus[prot].split(\"_\")[-1].split(\".\")[0]) - int(minibatch_consensus[prot].split(\"_\")[-2])\n",
    "            if len_domain >= 200 :\n",
    "                dico_mini_clean[prot] = minibatch_consensus[prot]\n",
    "            else :\n",
    "                dico_mini_clean[prot] = \"full sequence\"\n",
    "        \n",
    "        \n",
    "\n",
    "# *****************************************************\n",
    "# Minibatch version :\n",
    "with open(f\"{path_project}/minibatch.domains.clean_final.json\", \"w\") as outfile:\n",
    "    json.dump(dico_mini_clean, outfile)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Saving the ambiguous ones :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "import pandas as pd \n",
    "from Bio import SeqIO\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "path_project = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "\n",
    "# *****************************************************\n",
    "# PPT version :\n",
    "dico_ppt = json.load(open(f\"{path_project}/ppt.domains.json\"))\n",
    "dico_ppt_fine = json.load(open(f\"{path_project}/ppt.domains.fine.json\"))\n",
    "\n",
    "ppt_consensus = {}\n",
    "to_check = []\n",
    "for protein in dico_ppt : \n",
    "    if (len(dico_ppt[protein]) == len(dico_ppt_fine[protein])) and len(dico_ppt[protein]) == 4 :\n",
    "        if dico_ppt[protein][3] != dico_ppt_fine[protein][3] :\n",
    "            to_check.append((\"raw\",dico_ppt[protein],\"fine\",dico_ppt_fine[protein]))    \n",
    "        else :\n",
    "            ppt_consensus[protein] = dico_ppt_fine[protein][3]\n",
    "    elif len(dico_ppt[protein]) != len(dico_ppt_fine[protein]) :\n",
    "        to_check.append((\"raw\",dico_ppt[protein],\"fine\",dico_ppt_fine[protein]))\n",
    "    else :\n",
    "        ppt_consensus[protein] = \"full sequence\"\n",
    "        pass\n",
    "    \n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(width = 150, compact = True)\n",
    "pp.pprint(to_check)\n",
    "\n",
    "folds = []\n",
    "good_guys = []\n",
    "for _,protein_info in enumerate(to_check) :\n",
    "    protein = protein_info[1][-1]\n",
    "    if protein.count(\"Full\") > 0 :\n",
    "        protein_name = protein.split()[-1]\n",
    "    else :\n",
    "        protein_name = protein.split(\"_\")[0]\n",
    "    try : \n",
    "        fold = depo_results[protein_name][0]\n",
    "        folds.append(fold)\n",
    "        if fold == \"right-handed beta-helix\" :\n",
    "            good_guys.append(protein_name)\n",
    "    except :\n",
    "        pass\n",
    "\n",
    "\n",
    "ppt_to_save = []\n",
    "for _,protein_info in enumerate(to_check) :\n",
    "    protein = protein_info[1][-1]\n",
    "    if protein.count(\"Full\") > 0 :\n",
    "        protein_name = protein.split()[-1]\n",
    "    else :\n",
    "        protein_name = protein.split(\"_\")[0]\n",
    "    if protein_name in good_guys :\n",
    "        ppt_to_save.append(protein_info)\n",
    "    \n",
    "    \n",
    "        \n",
    "with open(f\"{path_project}/ppt.domains.to_check.txt\" , \"w\") as outfile :\n",
    "    for _, tuple_protein in enumerate(ppt_to_save) :\n",
    "        outfile.write(f\"{tuple_protein[1]}\\t{tuple_protein[3]}\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_mini = json.load(open(f\"{path_project}/minibatch.domains.json\"))\n",
    "dico_mini_fine = json.load(open(f\"{path_project}/minibatch.domains.fine.json\"))\n",
    "        \n",
    "minibatch_consensus = {}\n",
    "to_check = []\n",
    "for protein in dico_mini : \n",
    "    if (len(dico_mini[protein]) == len(dico_mini_fine[protein])) and len(dico_mini[protein]) == 4 :\n",
    "        if dico_mini[protein][3] != dico_mini_fine[protein][3] :\n",
    "            to_check.append((\"raw\",dico_mini[protein],\"fine\",dico_mini_fine[protein])) \n",
    "        else :\n",
    "            minibatch_consensus[protein] = dico_mini_fine[protein][3]\n",
    "    elif len(dico_mini[protein]) != len(dico_mini_fine[protein]) :\n",
    "        to_check.append((\"raw\",dico_mini[protein],\"fine\",dico_mini_fine[protein]))\n",
    "    else :\n",
    "        minibatch_consensus[protein] = \"full sequence\"\n",
    "        pass\n",
    "    \n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(width = 150, compact = True)\n",
    "pp.pprint(to_check)\n",
    "\n",
    "\n",
    "folds = []\n",
    "good_guys = []\n",
    "for _,protein_info in enumerate(to_check) :\n",
    "    protein = protein_info[1][-1]\n",
    "    if protein.count(\"Full\") > 0 :\n",
    "        protein_name = protein.split()[-1]\n",
    "    else :\n",
    "        protein_name = protein.split(\"_\")[0]\n",
    "    try : \n",
    "        fold = depo_results[protein_name][0]\n",
    "        folds.append(fold)\n",
    "        if fold == \"right-handed beta-helix\" :\n",
    "            good_guys.append(protein_name)\n",
    "    except :\n",
    "        pass\n",
    "    \n",
    "mini_to_save = []\n",
    "for _,protein_info in enumerate(to_check) :\n",
    "    protein = protein_info[1][-1]\n",
    "    if protein.count(\"Full\") > 0 :\n",
    "        protein_name = protein.split()[-1]\n",
    "    else :\n",
    "        protein_name = protein.split(\"_\")[0]\n",
    "    if protein_name in good_guys :\n",
    "        mini_to_save.append(protein_info)\n",
    "        \n",
    "        \n",
    "with open(f\"{path_project}/minibatch.domains.to_check.txt\" , \"w\") as outfile :\n",
    "    for _, tuple_protein in enumerate(mini_to_save) :\n",
    "        outfile.write(f\"{tuple_protein[1]}\\t{tuple_protein[3]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Write the multifasta with the clean domains :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fold info :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_project = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "\n",
    "# ***************************************\n",
    "# PPT :\n",
    "dir_out = f\"{path_project}/seekfold_PPT_full\"\n",
    "# ***************************************\n",
    "# Minibatch\n",
    "dir_out = f\"{path_project}/seekfold_minibatch_full\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "outputs = [f\"{dir_out}/{file}\" for file in os.listdir(dir_out) if file[-3:]==\"out\"]\n",
    "path_info = f\"/home/conchae/depolymerase/depolymerase_fold.csv\"\n",
    "info_df = pd.read_csv(path_info , sep = \"\\t\", header = 0)\n",
    "\n",
    "header_seekfold = [\"query\",\"target\",\"pident\",\"alnlen\",\"gapopen\",\"qstart\",\"qend\",\"tstart\",\"tend\",\"bits\",\"prob\",\"aln_score\"]\n",
    "dico_folds_ppt = {\"jelly-roll\" : [],\n",
    "              \"alpha/alpha toroid\" : [],\n",
    "              \"right-handed beta-helix\" : [] ,\n",
    "              \"TIM beta/alpha-barrel\" : [],\n",
    "              \"6-bladed beta-propeller\" : [] ,\n",
    "              \"Flavodoxin-like\" : [] ,\n",
    "              \"Alpha/Beta hydrolase fold\" : [] ,\n",
    "              \"Other\" : [],\n",
    "             }\n",
    "\n",
    "depo_results = {}\n",
    "for results in tqdm(outputs) :\n",
    "    results_df = pd.read_csv(f\"{results}\", sep = \"\\t\" , names = header_seekfold)\n",
    "    for _,row in results_df.iterrows() :\n",
    "        fold = info_df[info_df[\"ID\"] == row[\"target\"]][\"X_Group_Name\"].values[0]\n",
    "        if row[\"alnlen\"] > 200 :\n",
    "            if row[\"prob\"] >= 0.5 :\n",
    "                depo_results[row[\"query\"].split(\".pdb\")[0]] = (fold , row[\"prob\"])\n",
    "                break\n",
    "            elif fold == \"right-handed beta-helix\" and row[\"prob\"] >= 0.2 :\n",
    "                depo_results[row[\"query\"].split(\".pdb\")[0]] = (fold , row[\"prob\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "import pandas as pd \n",
    "from Bio import SeqIO\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(width = 150, compact = True)\n",
    "\n",
    "\n",
    "path_project = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "\n",
    "dico_ppt_final = json.load(open(f\"{path_project}/ppt.domains.clean_final.json\"))\n",
    "dico_mini_final = json.load(open(f\"{path_project}/minibatch.domains.clean_final.json\"))\n",
    "\n",
    "\n",
    "# ********************************************************\n",
    "# PPT version : \n",
    "dir_out_full = f\"{path_project}/seekfold_PPT_full\"\n",
    "dir_out = f\"{path_project}/seekfold_PPT_domains\"\n",
    "path_swords_out = f\"{path_project}/sword2_DepoSeq_pt2\"\n",
    "# *****************************************************\n",
    "# Minibatch version :\n",
    "dir_out_full = f\"{path_project}/seekfold_minibatch_full\"\n",
    "dir_out = f\"{path_project}/seekfold_minibatch_domains\"\n",
    "path_swords_out = f\"{path_project}/sword2_Minibatch_pt2\"\n",
    "# *********************************************************\n",
    "\n",
    "# Write the PPT part :\n",
    "with open(f\"{path_project}/Dpo_domains.0805.final.tsv\",\"w\") as outfile :\n",
    "    outfile.write(f\"Seq_ID\\tFold\\tProb\\tBoundaries\\tDpo_seq\\tFull_seq\\n\")\n",
    "    for protein,domain in dico_ppt_final.items() :\n",
    "        fold = depo_results[protein][0]\n",
    "        prob = depo_results[protein][1]\n",
    "        aa_full = (list(SeqIO.parse(f\"{path_swords_out}/{protein}/{protein}_A/SWORD/{protein}_A/{protein}_A.fasta\", \"fasta\"))[0]).seq\n",
    "        if domain == \"full sequence\" :\n",
    "            outfile.write(f\"ppt__{protein}\\t{fold}\\t{prob}\\tfull_protein\\t{aa_full}\\t{aa_full}\\n\")\n",
    "        else :\n",
    "            dom_aa = (list(SeqIO.parse(f\"{path_swords_out}/{protein}/{protein}_A/Protein_Units/{domain.split('.pdb')[0]}.fasta\", \"fasta\"))[0]).seq\n",
    "            outfile.write(f\"ppt__{protein}\\t{fold}\\t{prob}\\t{domain.split('.pdb')[0]}\\t{dom_aa}\\t{aa_full}\\n\")\n",
    "\n",
    "# Write the minibatch part :\n",
    "with open(f\"{path_project}/Dpo_domains.0805.final.tsv\",\"a+\") as outfile :\n",
    "    try : \n",
    "        outfile.write(f\"Seq_ID\\tFold\\tProb\\tBoundaries\\tDpo_seq\\tFull_seq\\n\")\n",
    "        for protein,domain in dico_mini_final.items() :\n",
    "            fold = depo_results[protein][0]\n",
    "            prob = depo_results[protein][1]\n",
    "            aa_full = (list(SeqIO.parse(f\"{path_swords_out}/{protein}/{protein}_A/SWORD/{protein}_A/{protein}_A.fasta\", \"fasta\"))[0]).seq\n",
    "            if domain == \"full sequence\" :\n",
    "                outfile.write(f\"minibatch__{protein}\\t{fold}\\t{prob}\\tfull_protein\\t{aa_full}\\t{aa_full}\\n\")\n",
    "            else :\n",
    "                dom_aa = (list(SeqIO.parse(f\"{path_swords_out}/{protein}/{protein}_A/Protein_Units/{domain.split('.pdb')[0]}.fasta\", \"fasta\"))[0]).seq\n",
    "                outfile.write(f\"minibatch__{protein}\\t{fold}\\t{prob}\\t{domain.split('.pdb')[0]}\\t{dom_aa}\\t{aa_full}\\n\")\n",
    "    except Exception as e :\n",
    "        print(e , protein  ,domain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Back to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "import pandas as pd \n",
    "from Bio import SeqIO\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(width = 150, compact = True)\n",
    "\n",
    "\n",
    "#path_project = \"/media/concha-eloko/Linux/PPT_clean\"\n",
    "path_project = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "\n",
    "Dpo_final = pd.read_csv(f\"{path_project}/Dpo_domains.0805.final.tsv\", sep = \"\\t\", header = 0)\n",
    "good_helix = Dpo_final[~((Dpo_final[\"Fold\"] == \"right-handed beta-helix\") & (Dpo_final[\"Boundaries\"] == \"full_protein\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seq_ID</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Boundaries</th>\n",
       "      <th>Dpo_seq</th>\n",
       "      <th>Full_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppt__6942</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6942_A_1_1_466</td>\n",
       "      <td>MVDIYVDALGDFKNMQDGCTEAILKAVAHWGGRTDSAYVQGQKKYG...</td>\n",
       "      <td>MVDIYVDALGDFKNMQDGCTEAILKAVAHWGGRTDSAYVQGQKKYG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppt__898</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>0.795</td>\n",
       "      <td>898_A_5_201_576</td>\n",
       "      <td>DRSIYVNVNWFGADPSGAGWSSDAIYSAFQISNCVEFDGLYKYKGR...</td>\n",
       "      <td>MRFFSRRSIIKGFMPLPFFMFATSSHAERSRTNESPPTVAFNYEKD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ppt__4863</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4863_A_2_110_517</td>\n",
       "      <td>DFTLEDFGAISNPDVDSTAFIQAAFNSGLKLTSKTDGKYLLKDTIF...</td>\n",
       "      <td>MDFNKRNLIKAFMYTCASLPLTKVYSKPSIPRNEYFFPVDKLIYKA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ppt__5053</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5053_A_5_252_584</td>\n",
       "      <td>RRYFKVTDYPGGMPNSQVVRNSDGTLTIIKGANNTNAIKSAIADAQ...</td>\n",
       "      <td>MTVSTQVSRNEYTGNGATTQYDFTFRILDKSHLLVQTLDTSESIVT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ppt__499</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>499_A_4_170_653</td>\n",
       "      <td>REFYADAFPGIDPTGQTSSTQGILDAIAQINSQVDSTFNGDITTYP...</td>\n",
       "      <td>MAEVPLPTPTQALVPSTDIRNAVFAGAKLDEEVTGTGEFYTDRLGV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>minibatch__723</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>723_A_3_308_953</td>\n",
       "      <td>TFLSFDMFNIKNDASEDVTQAIIDVFNYSNDLGIPVVQKSGRYLIS...</td>\n",
       "      <td>MSQTVITSAFEQLKAQEAANGGVVILDEFVFANIPNLDITSPIDRG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>minibatch__1283</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1283_A_4_150_502</td>\n",
       "      <td>KFVTPLTKNGVENAEYNYQLVQSLLNKGLHVDLKMGDIYFSQPVQT...</td>\n",
       "      <td>MTNMIESPSWDDEIAIIARNERVSGGQDGVANRPLKTLANRTRYLK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>minibatch__1829</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1829_A_3_260_821</td>\n",
       "      <td>TWCDMNMYPELDRTGSTNMVSQINAIIESAKEKGFYTVKDTSPPGS...</td>\n",
       "      <td>MTVSTEVDHNDYTGNGVTTSFPYTFRIFKKSDLTVQVADLNENITV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>minibatch__496</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>496_A_5_254_593</td>\n",
       "      <td>RRTNFVMPEDFPGTDTEQLLAANSYAKANSVNFQLQPGKTYVLTGS...</td>\n",
       "      <td>MTVSTQVSRNEYTGNGATTQYDFTFRILDKSHLLVQTLDTSESIVT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>minibatch__1222</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>0.214</td>\n",
       "      <td>full_protein</td>\n",
       "      <td>MKINEISQWEGEIYLLRRNDRVLGGVDGVANMQARQLANRTQYLKA...</td>\n",
       "      <td>MKINEISQWEGEIYLLRRNDRVLGGVDGVANMQARQLANRTQYLKA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1810 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Seq_ID                     Fold   Prob        Boundaries  \\\n",
       "0           ppt__6942  right-handed beta-helix    1.0    6942_A_1_1_466   \n",
       "1            ppt__898  right-handed beta-helix  0.795   898_A_5_201_576   \n",
       "2           ppt__4863  right-handed beta-helix    1.0  4863_A_2_110_517   \n",
       "3           ppt__5053  right-handed beta-helix    1.0  5053_A_5_252_584   \n",
       "4            ppt__499  right-handed beta-helix    1.0   499_A_4_170_653   \n",
       "...               ...                      ...    ...               ...   \n",
       "1805   minibatch__723  right-handed beta-helix    1.0   723_A_3_308_953   \n",
       "1806  minibatch__1283  right-handed beta-helix    1.0  1283_A_4_150_502   \n",
       "1807  minibatch__1829  right-handed beta-helix    1.0  1829_A_3_260_821   \n",
       "1808   minibatch__496  right-handed beta-helix    1.0   496_A_5_254_593   \n",
       "1809  minibatch__1222  right-handed beta-helix  0.214      full_protein   \n",
       "\n",
       "                                                Dpo_seq  \\\n",
       "0     MVDIYVDALGDFKNMQDGCTEAILKAVAHWGGRTDSAYVQGQKKYG...   \n",
       "1     DRSIYVNVNWFGADPSGAGWSSDAIYSAFQISNCVEFDGLYKYKGR...   \n",
       "2     DFTLEDFGAISNPDVDSTAFIQAAFNSGLKLTSKTDGKYLLKDTIF...   \n",
       "3     RRYFKVTDYPGGMPNSQVVRNSDGTLTIIKGANNTNAIKSAIADAQ...   \n",
       "4     REFYADAFPGIDPTGQTSSTQGILDAIAQINSQVDSTFNGDITTYP...   \n",
       "...                                                 ...   \n",
       "1805  TFLSFDMFNIKNDASEDVTQAIIDVFNYSNDLGIPVVQKSGRYLIS...   \n",
       "1806  KFVTPLTKNGVENAEYNYQLVQSLLNKGLHVDLKMGDIYFSQPVQT...   \n",
       "1807  TWCDMNMYPELDRTGSTNMVSQINAIIESAKEKGFYTVKDTSPPGS...   \n",
       "1808  RRTNFVMPEDFPGTDTEQLLAANSYAKANSVNFQLQPGKTYVLTGS...   \n",
       "1809  MKINEISQWEGEIYLLRRNDRVLGGVDGVANMQARQLANRTQYLKA...   \n",
       "\n",
       "                                               Full_seq  \n",
       "0     MVDIYVDALGDFKNMQDGCTEAILKAVAHWGGRTDSAYVQGQKKYG...  \n",
       "1     MRFFSRRSIIKGFMPLPFFMFATSSHAERSRTNESPPTVAFNYEKD...  \n",
       "2     MDFNKRNLIKAFMYTCASLPLTKVYSKPSIPRNEYFFPVDKLIYKA...  \n",
       "3     MTVSTQVSRNEYTGNGATTQYDFTFRILDKSHLLVQTLDTSESIVT...  \n",
       "4     MAEVPLPTPTQALVPSTDIRNAVFAGAKLDEEVTGTGEFYTDRLGV...  \n",
       "...                                                 ...  \n",
       "1805  MSQTVITSAFEQLKAQEAANGGVVILDEFVFANIPNLDITSPIDRG...  \n",
       "1806  MTNMIESPSWDDEIAIIARNERVSGGQDGVANRPLKTLANRTRYLK...  \n",
       "1807  MTVSTEVDHNDYTGNGVTTSFPYTFRIFKKSDLTVQVADLNENITV...  \n",
       "1808  MTVSTQVSRNEYTGNGATTQYDFTFRILDKSHLLVQTLDTSESIVT...  \n",
       "1809  MKINEISQWEGEIYLLRRNDRVLGGVDGVANMQARQLANRTQYLKA...  \n",
       "\n",
       "[1810 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dpo_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{path_project}/Dpo_domains.0805.final.multi.fasta\",\"w\") as outfile :\n",
    "    for _,row in good_helix.iterrows() :\n",
    "        if row[\"Dpo_seq\"].count(\"_\") == 0 :\n",
    "            outfile.write(f\">{row['Seq_ID']}\\n{row['Dpo_seq']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_fasta = SeqIO.parse(f\"{path_project}/Dpo_domains.0805.final.multi.fasta\" , \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in check_fasta :\n",
    "    if record.seq.count(\"_\") > 0 :\n",
    "        print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# ESM2 predictions on the clean 0805 Dpo domains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#BATCH --job-name=ESM_2__\n",
    "#SBATCH --qos=medium\n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=40 \n",
    "#SBATCH --mem=80gb \n",
    "#SBATCH --time=3-00:00:00 \n",
    "#SBATCH --output=ESM_2__%j.log \n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate embeddings\n",
    "\n",
    "python /home/conchae/software/esm/scripts/extract.py \\\n",
    "esm2_t33_650M_UR50D \\\n",
    "/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/Dpo_domains.0805.final.multi.fasta \\\n",
    "/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/Dpo_domains.0805.final.multi.out \\\n",
    "--repr_layers 33 \\\n",
    "--include mean per_tok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Get the tensors :\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os \n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "path_project = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "path_esm = f\"{path_project}/Dpo_domains.0805.final.multi.out\"\n",
    "\n",
    "embeddings_esm = {}\n",
    "for file in tqdm(os.listdir(path_esm)) :\n",
    "    path_file = f\"{path_esm}/{file}\"\n",
    "    index = file.split(\".\")[0]\n",
    "    embb = torch.load(f\"{path_file}\")[\"mean_representations\"][33].tolist()\n",
    "    embeddings_esm[index] = embb\n",
    "    \n",
    "with open(f\"{path_project}/Dpo.0805.embeddings.csv\" , \"w\") as outfile :\n",
    "    for index in tqdm(embeddings_esm) :\n",
    "        outfile.write(f\"{index},\")\n",
    "        for _,  emb in enumerate(embeddings_esm[index]) :\n",
    "            outfile.write(f\"{emb},\")\n",
    "        outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsync -avzhe ssh \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/Dpo.0805.embeddings.csv \\\n",
    "/media/concha-eloko/Linux/PPT_clean\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "sklearn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
