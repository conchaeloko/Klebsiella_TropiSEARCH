{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"facebook/esm2_t12_35M_UR50D\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data : DF with the sequence and the KL type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dpo</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Domain_Boundaries</th>\n",
       "      <th>aa_domain</th>\n",
       "      <th>aa_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppt__6942</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6942_A_1_1_466</td>\n",
       "      <td>MVDIYVDALGDFKNMQDGCTEAILKAVAHWGGRTDSAYVQGQKKYG...</td>\n",
       "      <td>MVDIYVDALGDFKNMQDGCTEAILKAVAHWGGRTDSAYVQGQKKYG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppt__898</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>0.795</td>\n",
       "      <td>898_A_5_201_576</td>\n",
       "      <td>DRSIYVNVNWFGADPSGAGWSSDAIYSAFQISNCVEFDGLYKYKGR...</td>\n",
       "      <td>MRFFSRRSIIKGFMPLPFFMFATSSHAERSRTNESPPTVAFNYEKD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ppt__4863</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4863_A_2_110_517</td>\n",
       "      <td>DFTLEDFGAISNPDVDSTAFIQAAFNSGLKLTSKTDGKYLLKDTIF...</td>\n",
       "      <td>MDFNKRNLIKAFMYTCASLPLTKVYSKPSIPRNEYFFPVDKLIYKA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ppt__5053</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5053_A_5_252_584</td>\n",
       "      <td>RRYFKVTDYPGGMPNSQVVRNSDGTLTIIKGANNTNAIKSAIADAQ...</td>\n",
       "      <td>MTVSTQVSRNEYTGNGATTQYDFTFRILDKSHLLVQTLDTSESIVT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ppt__499</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>499_A_4_170_653</td>\n",
       "      <td>REFYADAFPGIDPTGQTSSTQGILDAIAQINSQVDSTFNGDITTYP...</td>\n",
       "      <td>MAEVPLPTPTQALVPSTDIRNAVFAGAKLDEEVTGTGEFYTDRLGV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>minibatch__248</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>248_A_2_533_928</td>\n",
       "      <td>YPNEYWLQDFSGTTDIEWIQNAMDWVHDAGGGWLILSSDYVKKQFL...</td>\n",
       "      <td>MSNLPEQTAWESGIHQLEEEDRAKAGPGGVLNIQATQLANRTRWLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>minibatch__1414</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1414_A_6_224_698</td>\n",
       "      <td>REFYADAFPGIDPTGQTSSTQGILDAIAQINSQVDSTFNGDITTYP...</td>\n",
       "      <td>MAITDTQQSAQFAASAAVSAAEAKQYALSIEKPIIDIAESVSEAKD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>minibatch__1805</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1805_A_1_1_460</td>\n",
       "      <td>MGDALLAVKQPYTGSVARTQHEKNWDSLNLLDFVYATDVVDGFVDY...</td>\n",
       "      <td>MGDALLAVKQPYTGSVARTQHEKNWDSLNLLDFVYATDVVDGFVDY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>minibatch__985</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>985_A_2_91_554</td>\n",
       "      <td>TDLINYLALNGASERTVLSRLRDNIYITDFYSENDGDDWHPAYQRA...</td>\n",
       "      <td>MYHLDNTSGVPEMPEPKETQTISTRWFGESVDQGGISWPGADWFNI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>minibatch__629</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>629_A_3_118_504</td>\n",
       "      <td>ILSVLDFDADPTGVKDSSYAFQRAILAAHEMGGGRVFIPTPGTRYR...</td>\n",
       "      <td>MYHLDNTSGVPEMPEPKDTQSISPRWFGESQEQGGISWPGADWFNI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1999 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Dpo                     Fold   Prob Domain_Boundaries  \\\n",
       "0           ppt__6942  right-handed beta-helix    1.0    6942_A_1_1_466   \n",
       "1            ppt__898  right-handed beta-helix  0.795   898_A_5_201_576   \n",
       "2           ppt__4863  right-handed beta-helix    1.0  4863_A_2_110_517   \n",
       "3           ppt__5053  right-handed beta-helix    1.0  5053_A_5_252_584   \n",
       "4            ppt__499  right-handed beta-helix    1.0   499_A_4_170_653   \n",
       "...               ...                      ...    ...               ...   \n",
       "1994   minibatch__248  right-handed beta-helix    1.0   248_A_2_533_928   \n",
       "1995  minibatch__1414  right-handed beta-helix    1.0  1414_A_6_224_698   \n",
       "1996  minibatch__1805  right-handed beta-helix    1.0    1805_A_1_1_460   \n",
       "1997   minibatch__985  right-handed beta-helix    1.0    985_A_2_91_554   \n",
       "1998   minibatch__629  right-handed beta-helix    1.0   629_A_3_118_504   \n",
       "\n",
       "                                              aa_domain  \\\n",
       "0     MVDIYVDALGDFKNMQDGCTEAILKAVAHWGGRTDSAYVQGQKKYG...   \n",
       "1     DRSIYVNVNWFGADPSGAGWSSDAIYSAFQISNCVEFDGLYKYKGR...   \n",
       "2     DFTLEDFGAISNPDVDSTAFIQAAFNSGLKLTSKTDGKYLLKDTIF...   \n",
       "3     RRYFKVTDYPGGMPNSQVVRNSDGTLTIIKGANNTNAIKSAIADAQ...   \n",
       "4     REFYADAFPGIDPTGQTSSTQGILDAIAQINSQVDSTFNGDITTYP...   \n",
       "...                                                 ...   \n",
       "1994  YPNEYWLQDFSGTTDIEWIQNAMDWVHDAGGGWLILSSDYVKKQFL...   \n",
       "1995  REFYADAFPGIDPTGQTSSTQGILDAIAQINSQVDSTFNGDITTYP...   \n",
       "1996  MGDALLAVKQPYTGSVARTQHEKNWDSLNLLDFVYATDVVDGFVDY...   \n",
       "1997  TDLINYLALNGASERTVLSRLRDNIYITDFYSENDGDDWHPAYQRA...   \n",
       "1998  ILSVLDFDADPTGVKDSSYAFQRAILAAHEMGGGRVFIPTPGTRYR...   \n",
       "\n",
       "                                                aa_full  \n",
       "0     MVDIYVDALGDFKNMQDGCTEAILKAVAHWGGRTDSAYVQGQKKYG...  \n",
       "1     MRFFSRRSIIKGFMPLPFFMFATSSHAERSRTNESPPTVAFNYEKD...  \n",
       "2     MDFNKRNLIKAFMYTCASLPLTKVYSKPSIPRNEYFFPVDKLIYKA...  \n",
       "3     MTVSTQVSRNEYTGNGATTQYDFTFRILDKSHLLVQTLDTSESIVT...  \n",
       "4     MAEVPLPTPTQALVPSTDIRNAVFAGAKLDEEVTGTGEFYTDRLGV...  \n",
       "...                                                 ...  \n",
       "1994  MSNLPEQTAWESGIHQLEEEDRAKAGPGGVLNIQATQLANRTRWLR...  \n",
       "1995  MAITDTQQSAQFAASAAVSAAEAKQYALSIEKPIIDIAESVSEAKD...  \n",
       "1996  MGDALLAVKQPYTGSVARTQHEKNWDSLNLLDFVYATDVVDGFVDY...  \n",
       "1997  MYHLDNTSGVPEMPEPKETQTISTRWFGESVDQGGISWPGADWFNI...  \n",
       "1998  MYHLDNTSGVPEMPEPKDTQSISPRWFGESQEQGGISWPGADWFNI...  \n",
       "\n",
       "[1999 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "import warnings\n",
    "import json\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# local :\n",
    "path_project = \"/media/concha-eloko/Linux/PPT_clean\"\n",
    "path_similarity = path_project\n",
    "\n",
    "dpo_final_info = pd.read_csv(f\"{path_project}/Dpo_domains.0805.final.ultimate.tsv\" , sep = \"\\t\", names = [\"0\",\"Dpo\",\"Fold\",\"Prob\",\"Domain_Boundaries\",\"aa_domain\",\"aa_full\"])\n",
    "dpo_final_info = dpo_final_info.drop([\"0\"] , axis = 1)\n",
    "dico_labels = json.load(open(f\"{path_project}/dico.dpo_label.1805.json\"))\n",
    "dpo_final_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Make DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "with open(f\"{path_project}/df_final.1805.tsv\",\"w\") as outfile :\n",
    "    for _,row in dpo_final_info.iterrows() :\n",
    "        aa_seq = row[\"aa_domain\"]\n",
    "        if row[\"Dpo\"] in dico_labels :\n",
    "            label = dico_labels[row[\"Dpo\"]]\n",
    "        else :\n",
    "            label = \"Other\"\n",
    "        outfile.write(f\"{row['Dpo']}\\t{aa_seq}\\t{label}\\n\")\n",
    "        \n",
    "df_model = pd.read_csv(f\"{path_project}/df_final.1805.tsv\" , sep = \"\\t\", names = [\"index\",\"domain_seq\",\"label\"], index_col = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.read_csv(f\"{path_project}/df_final.1805.tsv\" , sep = \"\\t\", names = [\"index\",\"domain_seq\",\"label\"], index_col = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "import warnings\n",
    "import json\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "path_project = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/fine_tuning\"\n",
    "\n",
    "df_model = pd.read_csv(f\"{path_project}/df_final.1805.tsv\" , sep = \"\\t\", names = [\"index\",\"domain_seq\",\"label\"], index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rsync -avzhe ssh \\\n",
    "/media/concha-eloko/Linux/PPT_clean/df_final.1805.tsv \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/fine_tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "with open(f\"{path_project}/df_final.1805.tsv\",\"w\") as outfile :\n",
    "    for dpo in dico_labels :\n",
    "        aa_seq = dpo_final_info[dpo_final_info[\"Dpo\"] == dpo][\"aa_domain\"].values[0]\n",
    "        outfile.write(f\"{dpo}\\t{aa_seq}\\t{dico_labels[dpo]}\\n\")\n",
    "        \n",
    "df_model = pd.read_csv(f\"{path_project}/df_final.1805.tsv\" , sep = \"\\t\", names = [\"index\",\"domain_seq\",\"label\"], index_col = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain_seq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ppt__6942</th>\n",
       "      <td>MVDIYVDALGDFKNMQDGCTEAILKAVAHWGGRTDSAYVQGQKKYG...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppt__898</th>\n",
       "      <td>DRSIYVNVNWFGADPSGAGWSSDAIYSAFQISNCVEFDGLYKYKGR...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppt__4863</th>\n",
       "      <td>DFTLEDFGAISNPDVDSTAFIQAAFNSGLKLTSKTDGKYLLKDTIF...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppt__5053</th>\n",
       "      <td>RRYFKVTDYPGGMPNSQVVRNSDGTLTIIKGANNTNAIKSAIADAQ...</td>\n",
       "      <td>KL116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppt__499</th>\n",
       "      <td>REFYADAFPGIDPTGQTSSTQGILDAIAQINSQVDSTFNGDITTYP...</td>\n",
       "      <td>KL81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minibatch__248</th>\n",
       "      <td>YPNEYWLQDFSGTTDIEWIQNAMDWVHDAGGGWLILSSDYVKKQFL...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minibatch__1414</th>\n",
       "      <td>REFYADAFPGIDPTGQTSSTQGILDAIAQINSQVDSTFNGDITTYP...</td>\n",
       "      <td>KL81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minibatch__1805</th>\n",
       "      <td>MGDALLAVKQPYTGSVARTQHEKNWDSLNLLDFVYATDVVDGFVDY...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minibatch__985</th>\n",
       "      <td>TDLINYLALNGASERTVLSRLRDNIYITDFYSENDGDDWHPAYQRA...</td>\n",
       "      <td>KL43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minibatch__629</th>\n",
       "      <td>ILSVLDFDADPTGVKDSSYAFQRAILAAHEMGGGRVFIPTPGTRYR...</td>\n",
       "      <td>KL57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        domain_seq  label\n",
       "index                                                                    \n",
       "ppt__6942        MVDIYVDALGDFKNMQDGCTEAILKAVAHWGGRTDSAYVQGQKKYG...  Other\n",
       "ppt__898         DRSIYVNVNWFGADPSGAGWSSDAIYSAFQISNCVEFDGLYKYKGR...  Other\n",
       "ppt__4863        DFTLEDFGAISNPDVDSTAFIQAAFNSGLKLTSKTDGKYLLKDTIF...  Other\n",
       "ppt__5053        RRYFKVTDYPGGMPNSQVVRNSDGTLTIIKGANNTNAIKSAIADAQ...  KL116\n",
       "ppt__499         REFYADAFPGIDPTGQTSSTQGILDAIAQINSQVDSTFNGDITTYP...   KL81\n",
       "...                                                            ...    ...\n",
       "minibatch__248   YPNEYWLQDFSGTTDIEWIQNAMDWVHDAGGGWLILSSDYVKKQFL...  Other\n",
       "minibatch__1414  REFYADAFPGIDPTGQTSSTQGILDAIAQINSQVDSTFNGDITTYP...   KL81\n",
       "minibatch__1805  MGDALLAVKQPYTGSVARTQHEKNWDSLNLLDFVYATDVVDGFVDY...  Other\n",
       "minibatch__985   TDLINYLALNGASERTVLSRLRDNIYITDFYSENDGDDWHPAYQRA...   KL43\n",
       "minibatch__629   ILSVLDFDADPTGVKDSSYAFQRAILAAHEMGGGRVFIPTPGTRYR...   KL57\n",
       "\n",
       "[1999 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Prepare label & seqeunces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_id = {i : value for i,value in enumerate(df_model[\"label\"].unique().tolist())}\n",
    "id_labels = {value : i for i,value in labels_id.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = df_model[\"domain_seq\"].tolist()\n",
    "labels = [id_labels[kl_type] for _,kl_type in enumerate(df_model[\"label\"].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick check to make sure we got it right\n",
    "len(sequences) == len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the train test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sequences, test_sequences, train_labels, test_labels = train_test_split(sequences, labels, test_size=0.25, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_checkpoint = \"facebook/esm2_t6_8M_UR50D\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "train_tokenized = tokenizer(train_sequences)\n",
    "test_tokenized = tokenizer(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_dict(train_tokenized)\n",
    "test_dataset = Dataset.from_dict(test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.add_column(\"labels\", train_labels)\n",
    "test_dataset = test_dataset.add_column(\"labels\", test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The finetuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/esm2_t6_8M_UR50D were not used when initializing EsmForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.bias', 'esm.contact_head.regression.bias', 'lm_head.layer_norm.bias', 'esm.contact_head.regression.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing EsmForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EsmForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "num_labels = max(train_labels + test_labels) + 1  # Add 1 since 0 can be a label\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Set the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "batch_size = 4\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-localization\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "import numpy as np\n",
    "\n",
    "metric = load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1499\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='1125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   7/1125 00:01 < 07:00, 2.66 it/s, Epoch 0.02/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 108.00 MiB (GPU 0; 1.96 GiB total capacity; 1.20 GiB already allocated; 100.38 MiB free; 1.33 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_197687/848285238.py\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m         )\n\u001b[0;32m-> 1500\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1501\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                 if (\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2502\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2504\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2506\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 108.00 MiB (GPU 0; 1.96 GiB total capacity; 1.20 GiB already allocated; 100.38 MiB free; 1.33 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#BATCH --job-name=ESM_2__\n",
    "#SBATCH --qos=short\n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=40 \n",
    "#SBATCH --mem=80gb \n",
    "#SBATCH --time=1-00:00:00 \n",
    "#SBATCH --output=ESM_2__%j.log \n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate embeddings\n",
    "\n",
    "python /home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/fine_tuning/script_files/fine_tuning.1805.py\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model :\n",
    "\n",
    "rsync -avzhe ssh \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/fine_tuning/script_files/esm2_t30_150M_UR50D-finetuned-dpo_tropism \\\n",
    "/media/concha-eloko/Linux/PPT_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading configuration file /media/concha-eloko/Linux/PPT_clean/esm2_t6_8M_UR50D-finetuned-dpo_tropism/checkpoint-564/config.json\n",
      "Model config EsmConfig {\n",
      "  \"_name_or_path\": \"/media/concha-eloko/Linux/PPT_clean/esm2_t6_8M_UR50D-finetuned-dpo_tropism/checkpoint-564\",\n",
      "  \"architectures\": [\n",
      "    \"EsmForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"emb_layer_norm_before\": false,\n",
      "  \"esmfold_config\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 320,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1280,\n",
      "  \"is_folding_model\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"mask_token_id\": 32,\n",
      "  \"max_position_embeddings\": 1026,\n",
      "  \"model_type\": \"esm\",\n",
      "  \"num_attention_heads\": 20,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"rotary\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"token_dropout\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_list\": null,\n",
      "  \"vocab_size\": 33\n",
      "}\n",
      "\n",
      "loading weights file /media/concha-eloko/Linux/PPT_clean/esm2_t6_8M_UR50D-finetuned-dpo_tropism/checkpoint-564/pytorch_model.bin\n",
      "Some weights of the model checkpoint at /media/concha-eloko/Linux/PPT_clean/esm2_t6_8M_UR50D-finetuned-dpo_tropism/checkpoint-564 were not used when initializing EsmForSequenceClassification: ['esm.contact_head.regression.weight', 'esm.contact_head.regression.bias']\n",
      "- This IS expected if you are initializing EsmForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EsmForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of EsmForSequenceClassification were initialized from the model checkpoint at /media/concha-eloko/Linux/PPT_clean/esm2_t6_8M_UR50D-finetuned-dpo_tropism/checkpoint-564.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use EsmForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "\n",
    "path_work = \"/media/concha-eloko/Linux/PPT_clean\"\n",
    "model_path = f\"{path_work}/esm2_t6_8M_UR50D-finetuned-dpo_tropism/checkpoint-564\"\n",
    "#model_path = \"/home/conchae/PhageDepo_pdb/script_files/esm2_t30_150M_UR50D-finetuned-depolymerase/checkpoint-198\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: Other, with score: 0.1561\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline for text classification\n",
    "classifier = pipeline('text-classification', model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Your input sequence\n",
    "sequence = \"TDLINYLALNGASERTVLSRLRDNIYITDFYSENDGDDWHPAYQRASLLAKNVWFPDNRVYTVRSTLIMPAGGGICGSGNAVIASPPATDASGSGLITVIRADNVNDVRLTGIIIDGGVREVMTEKNYTRPLRMINCKNIVWNNLTIINNADWSFSLESCAEISIQRYKQRSYVYQDPALTRLRAGGRDGGHLMDCINAVLIDSDIESGDDCIGITSKLSGTSNITVRGLRGSSVIASLVIYNEEKITGSNDYYAMPADKLVFEDIRVKKAGSSRNVVRIAKYNTLSTVKDCSVSGVSGEGYSHGALFQWVEGLNLADIDVSSSGAHGAYISNCTKVEGAVKGSTKASGFDGVNIFNGEAHNLDVESSNSASYGIQVNGLKNSVVRPKASNCGGVDFSLARGGGGRIVNTVGVHIPSGLFIGETSTSYYGLNAVPGSNTDLRVADDVKRSGLIPSTPLGKINYL\"\n",
    "\n",
    "# Get the prediction\n",
    "result = classifier(sequence)\n",
    "\n",
    "# The result is a list of dictionary. Each dictionary contains the 'label' and its 'score'\n",
    "for r in result:\n",
    "    print(f\"label: {labels_id[int(r['label'].split('_')[1])]}, with score: {r['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Other', 0.1676236242055893), ('KL25', 0.03480101004242897), ('KL64', 0.027835039421916008), ('KL111', 0.023746315389871597), ('KL106', 0.022435791790485382)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "sequence = 'NATVTELTEASILMFMTRADINTLLNTTGAEVAVDYALQAIINAGYKSVRFPHTVKGIYTLNGSVILPGGFTIYGECSKPYTITDDSSFVGKGTVIRKASGADYIFGPGSVFRIYGCILDGRDQQRPLINQTNQVRGGILFNCGIYRFLYGIGSYSYTSIQVGKSSICANQDGVYNLIDSRVIDCTINTQTRHGVNLQAGANNNLFSNVRNEWNEGIGYNISGSIGNIINGELVDRNGSTNFAITNGGGAVIGDLLSQRPGRNSSAGSSYNTHFYIEGSGSYIMLSNVKTRVGVDDDGGGNITPERVITTGGSSSNMSIQADNCDLTGYTISSLREITVSGTKLFGNNIGVNNIQTVGLYRFIAGRN'\n",
    "\n",
    "dico_final_label\n",
    "\n",
    "inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
    "\n",
    "# Get the model's output\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient computation\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# From this point on, you can continue as normal\n",
    "logits = outputs.logits.clone()\n",
    "probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "# Get the top 5 predictions\n",
    "top_5_probs, top_5_indices = probs.topk(5)\n",
    "\n",
    "# Convert to lists\n",
    "top_5_probs = top_5_probs.detach().numpy().tolist()[0]\n",
    "top_5_indices = [labels_id[ind] for ind in top_5_indices.detach().numpy().tolist()[0]]\n",
    "\n",
    "# Combine the probabilities and indices into tuples\n",
    "top_5_predictions = list(zip(top_5_indices, top_5_probs))\n",
    "\n",
    "print(top_5_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KL43'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "path_project = \"/media/concha-eloko/Linux/PPT_clean\"\n",
    "\n",
    "dico_final_label = json.load(open(f\"{path_project}/dico.dpo_label.1805.json\"))\n",
    "dico_final_label[\"minibatch__1305\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dpo</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Domain_Boundaries</th>\n",
       "      <th>aa_domain</th>\n",
       "      <th>aa_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppt__6942</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6942_A_1_1_466</td>\n",
       "      <td>MVDIYVDALGDFKNMQDGCTEAILKAVAHWGGRTDSAYVQGQKKYG...</td>\n",
       "      <td>MVDIYVDALGDFKNMQDGCTEAILKAVAHWGGRTDSAYVQGQKKYG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppt__898</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>0.795</td>\n",
       "      <td>898_A_5_201_576</td>\n",
       "      <td>DRSIYVNVNWFGADPSGAGWSSDAIYSAFQISNCVEFDGLYKYKGR...</td>\n",
       "      <td>MRFFSRRSIIKGFMPLPFFMFATSSHAERSRTNESPPTVAFNYEKD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ppt__4863</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4863_A_2_110_517</td>\n",
       "      <td>DFTLEDFGAISNPDVDSTAFIQAAFNSGLKLTSKTDGKYLLKDTIF...</td>\n",
       "      <td>MDFNKRNLIKAFMYTCASLPLTKVYSKPSIPRNEYFFPVDKLIYKA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ppt__5053</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5053_A_5_252_584</td>\n",
       "      <td>RRYFKVTDYPGGMPNSQVVRNSDGTLTIIKGANNTNAIKSAIADAQ...</td>\n",
       "      <td>MTVSTQVSRNEYTGNGATTQYDFTFRILDKSHLLVQTLDTSESIVT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ppt__499</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>499_A_4_170_653</td>\n",
       "      <td>REFYADAFPGIDPTGQTSSTQGILDAIAQINSQVDSTFNGDITTYP...</td>\n",
       "      <td>MAEVPLPTPTQALVPSTDIRNAVFAGAKLDEEVTGTGEFYTDRLGV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>minibatch__248</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>248_A_2_533_928</td>\n",
       "      <td>YPNEYWLQDFSGTTDIEWIQNAMDWVHDAGGGWLILSSDYVKKQFL...</td>\n",
       "      <td>MSNLPEQTAWESGIHQLEEEDRAKAGPGGVLNIQATQLANRTRWLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>minibatch__1414</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1414_A_6_224_698</td>\n",
       "      <td>REFYADAFPGIDPTGQTSSTQGILDAIAQINSQVDSTFNGDITTYP...</td>\n",
       "      <td>MAITDTQQSAQFAASAAVSAAEAKQYALSIEKPIIDIAESVSEAKD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>minibatch__1805</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1805_A_1_1_460</td>\n",
       "      <td>MGDALLAVKQPYTGSVARTQHEKNWDSLNLLDFVYATDVVDGFVDY...</td>\n",
       "      <td>MGDALLAVKQPYTGSVARTQHEKNWDSLNLLDFVYATDVVDGFVDY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>minibatch__985</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>985_A_2_91_554</td>\n",
       "      <td>TDLINYLALNGASERTVLSRLRDNIYITDFYSENDGDDWHPAYQRA...</td>\n",
       "      <td>MYHLDNTSGVPEMPEPKETQTISTRWFGESVDQGGISWPGADWFNI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>minibatch__629</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>629_A_3_118_504</td>\n",
       "      <td>ILSVLDFDADPTGVKDSSYAFQRAILAAHEMGGGRVFIPTPGTRYR...</td>\n",
       "      <td>MYHLDNTSGVPEMPEPKDTQSISPRWFGESQEQGGISWPGADWFNI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1999 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Dpo                     Fold   Prob Domain_Boundaries  \\\n",
       "0           ppt__6942  right-handed beta-helix    1.0    6942_A_1_1_466   \n",
       "1            ppt__898  right-handed beta-helix  0.795   898_A_5_201_576   \n",
       "2           ppt__4863  right-handed beta-helix    1.0  4863_A_2_110_517   \n",
       "3           ppt__5053  right-handed beta-helix    1.0  5053_A_5_252_584   \n",
       "4            ppt__499  right-handed beta-helix    1.0   499_A_4_170_653   \n",
       "...               ...                      ...    ...               ...   \n",
       "1994   minibatch__248  right-handed beta-helix    1.0   248_A_2_533_928   \n",
       "1995  minibatch__1414  right-handed beta-helix    1.0  1414_A_6_224_698   \n",
       "1996  minibatch__1805  right-handed beta-helix    1.0    1805_A_1_1_460   \n",
       "1997   minibatch__985  right-handed beta-helix    1.0    985_A_2_91_554   \n",
       "1998   minibatch__629  right-handed beta-helix    1.0   629_A_3_118_504   \n",
       "\n",
       "                                              aa_domain  \\\n",
       "0     MVDIYVDALGDFKNMQDGCTEAILKAVAHWGGRTDSAYVQGQKKYG...   \n",
       "1     DRSIYVNVNWFGADPSGAGWSSDAIYSAFQISNCVEFDGLYKYKGR...   \n",
       "2     DFTLEDFGAISNPDVDSTAFIQAAFNSGLKLTSKTDGKYLLKDTIF...   \n",
       "3     RRYFKVTDYPGGMPNSQVVRNSDGTLTIIKGANNTNAIKSAIADAQ...   \n",
       "4     REFYADAFPGIDPTGQTSSTQGILDAIAQINSQVDSTFNGDITTYP...   \n",
       "...                                                 ...   \n",
       "1994  YPNEYWLQDFSGTTDIEWIQNAMDWVHDAGGGWLILSSDYVKKQFL...   \n",
       "1995  REFYADAFPGIDPTGQTSSTQGILDAIAQINSQVDSTFNGDITTYP...   \n",
       "1996  MGDALLAVKQPYTGSVARTQHEKNWDSLNLLDFVYATDVVDGFVDY...   \n",
       "1997  TDLINYLALNGASERTVLSRLRDNIYITDFYSENDGDDWHPAYQRA...   \n",
       "1998  ILSVLDFDADPTGVKDSSYAFQRAILAAHEMGGGRVFIPTPGTRYR...   \n",
       "\n",
       "                                                aa_full  \n",
       "0     MVDIYVDALGDFKNMQDGCTEAILKAVAHWGGRTDSAYVQGQKKYG...  \n",
       "1     MRFFSRRSIIKGFMPLPFFMFATSSHAERSRTNESPPTVAFNYEKD...  \n",
       "2     MDFNKRNLIKAFMYTCASLPLTKVYSKPSIPRNEYFFPVDKLIYKA...  \n",
       "3     MTVSTQVSRNEYTGNGATTQYDFTFRILDKSHLLVQTLDTSESIVT...  \n",
       "4     MAEVPLPTPTQALVPSTDIRNAVFAGAKLDEEVTGTGEFYTDRLGV...  \n",
       "...                                                 ...  \n",
       "1994  MSNLPEQTAWESGIHQLEEEDRAKAGPGGVLNIQATQLANRTRWLR...  \n",
       "1995  MAITDTQQSAQFAASAAVSAAEAKQYALSIEKPIIDIAESVSEAKD...  \n",
       "1996  MGDALLAVKQPYTGSVARTQHEKNWDSLNLLDFVYATDVVDGFVDY...  \n",
       "1997  MYHLDNTSGVPEMPEPKETQTISTRWFGESVDQGGISWPGADWFNI...  \n",
       "1998  MYHLDNTSGVPEMPEPKDTQSISPRWFGESQEQGGISWPGADWFNI...  \n",
       "\n",
       "[1999 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_final_info = pd.read_csv(f\"{path_project}/Dpo_domains.0805.final.ultimate.tsv\" , sep = \"\\t\", names = [\"0\",\"Dpo\",\"Fold\",\"Prob\",\"Domain_Boundaries\",\"aa_domain\",\"aa_full\"])\n",
    "dpo_final_info = dpo_final_info.drop([\"0\"] , axis = 1)\n",
    "\n",
    "dpo_final_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NATVTELTEASILMFMTRADINTLLNTTGAEVAVDYALQAIINAGYKSVRFPHTVKGIYTLNGSVILPGGFTIYGECSKPYTITDDSSFVGKGTVIRKASGADYIFGPGSVFRIYGCILDGRDQQRPLINQTNQVRGGILFNCGIYRFLYGIGSYSYTSIQVGKSSICANQDGVYNLIDSRVIDCTINTQTRHGVNLQAGANNNLFSNVRNEWNEGIGYNISGSIGNIINGELVDRNGSTNFAITNGGGAVIGDLLSQRPGRNSSAGSSYNTHFYIEGSGSYIMLSNVKTRVGVDDDGGGNITPERVITTGGSSSNMSIQADNCDLTGYTISSLREITVSGTKLFGNNIGVNNIQTVGLYRFIAGRN'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_final_info[dpo_final_info[\"Dpo\"] == \"ppt__1090\"][\"aa_domain\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ppt__1': 'KL43',\n",
       " 'ppt__4': 'KL43',\n",
       " 'ppt__22': 'KL107',\n",
       " 'ppt__42': 'KL17',\n",
       " 'ppt__44': 'KL17',\n",
       " 'ppt__54': 'KL2',\n",
       " 'ppt__64': 'KL2',\n",
       " 'ppt__65': 'KL2',\n",
       " 'ppt__69': 'KL51',\n",
       " 'ppt__96': 'KL47',\n",
       " 'ppt__115': 'KL63',\n",
       " 'ppt__133': 'KL57',\n",
       " 'ppt__137': 'KL25',\n",
       " 'ppt__138': 'KL25',\n",
       " 'ppt__150': 'KL24',\n",
       " 'ppt__152': 'KL24',\n",
       " 'ppt__162': 'KL45',\n",
       " 'ppt__163': 'KL45',\n",
       " 'ppt__173': 'KL25',\n",
       " 'ppt__179': 'KL25',\n",
       " 'ppt__187': 'KL47',\n",
       " 'ppt__188': 'KL47',\n",
       " 'ppt__221': 'KL30',\n",
       " 'ppt__230': 'KL19',\n",
       " 'ppt__236': 'KL17',\n",
       " 'ppt__237': 'KL17',\n",
       " 'ppt__247': 'KL45',\n",
       " 'ppt__248': 'KL45',\n",
       " 'ppt__257': 'KL36',\n",
       " 'ppt__330': 'KL25',\n",
       " 'ppt__331': 'KL25',\n",
       " 'ppt__350': 'KL47',\n",
       " 'ppt__352': 'KL149',\n",
       " 'ppt__354': 'KL149',\n",
       " 'ppt__356': 'KL47',\n",
       " 'ppt__359': 'KL36',\n",
       " 'ppt__377': 'KL17',\n",
       " 'ppt__380': 'KL38',\n",
       " 'ppt__428': 'KL46',\n",
       " 'ppt__434': 'KL46',\n",
       " 'ppt__454': 'KL62',\n",
       " 'ppt__464': 'KL107',\n",
       " 'ppt__472': 'KL64',\n",
       " 'ppt__479': 'KL25',\n",
       " 'ppt__491': 'KL23',\n",
       " 'ppt__494': 'KL23',\n",
       " 'ppt__499': 'KL81',\n",
       " 'ppt__530': 'KL17',\n",
       " 'ppt__541': 'KL47',\n",
       " 'ppt__542': 'KL45',\n",
       " 'ppt__544': 'KL45',\n",
       " 'ppt__545': 'KL45',\n",
       " 'ppt__548': 'KL64',\n",
       " 'ppt__550': 'KL66',\n",
       " 'ppt__551': 'KL66',\n",
       " 'ppt__563': 'KL17',\n",
       " 'ppt__566': 'KL2',\n",
       " 'ppt__570': 'KL46',\n",
       " 'ppt__571': 'KL46',\n",
       " 'ppt__579': 'KL51',\n",
       " 'ppt__585': 'KL45',\n",
       " 'ppt__587': 'KL64',\n",
       " 'ppt__589': 'KL64',\n",
       " 'ppt__604': 'KL36',\n",
       " 'ppt__621': 'KL62',\n",
       " 'ppt__629': 'KL17',\n",
       " 'ppt__640': 'KL27',\n",
       " 'ppt__651': 'KL17',\n",
       " 'ppt__665': 'KL27',\n",
       " 'ppt__667': 'KL7',\n",
       " 'ppt__669': 'KL128',\n",
       " 'ppt__671': 'KL27',\n",
       " 'ppt__672': 'KL27',\n",
       " 'ppt__682': 'KL47',\n",
       " 'ppt__686': 'KL107',\n",
       " 'ppt__700': 'KL27',\n",
       " 'ppt__710': 'KL13',\n",
       " 'ppt__718': 'KL3',\n",
       " 'ppt__720': 'KL3',\n",
       " 'ppt__764': 'KL64',\n",
       " 'ppt__767': 'KL105',\n",
       " 'ppt__768': 'KL2',\n",
       " 'ppt__794': 'KL122',\n",
       " 'ppt__802': 'KL25',\n",
       " 'ppt__818': 'KL45',\n",
       " 'ppt__832': 'KL22',\n",
       " 'ppt__838': 'KL74',\n",
       " 'ppt__846': 'KL38',\n",
       " 'ppt__849': 'KL149',\n",
       " 'ppt__871': 'KL47',\n",
       " 'ppt__887': 'KL23',\n",
       " 'ppt__901': 'KL105',\n",
       " 'ppt__908': 'KL64',\n",
       " 'ppt__947': 'KL62',\n",
       " 'ppt__964': 'KL12',\n",
       " 'ppt__965': 'KL12',\n",
       " 'ppt__981': 'KL63',\n",
       " 'ppt__988': 'KL111',\n",
       " 'ppt__1008': 'KL64',\n",
       " 'ppt__1013': 'KL64',\n",
       " 'ppt__1015': 'KL108',\n",
       " 'ppt__1033': 'KL45',\n",
       " 'ppt__1035': 'KL45',\n",
       " 'ppt__1043': 'KL64',\n",
       " 'ppt__1055': 'KL12',\n",
       " 'ppt__1073': 'KL107',\n",
       " 'ppt__1090': 'KL111',\n",
       " 'ppt__1094': 'KL3',\n",
       " 'ppt__1096': 'KL24',\n",
       " 'ppt__1104': 'KL64',\n",
       " 'ppt__1123': 'KL107',\n",
       " 'ppt__1124': 'KL107',\n",
       " 'ppt__1127': 'KL2',\n",
       " 'ppt__1131': 'KL34',\n",
       " 'ppt__1146': 'KL47',\n",
       " 'ppt__1162': 'KL18',\n",
       " 'ppt__1165': 'KL27',\n",
       " 'ppt__1168': 'KL27',\n",
       " 'ppt__1182': 'KL64',\n",
       " 'ppt__1191': 'KL46',\n",
       " 'ppt__1195': 'KL105',\n",
       " 'ppt__1203': 'KL105',\n",
       " 'ppt__1220': 'KL23',\n",
       " 'ppt__1223': 'KL17',\n",
       " 'ppt__1230': 'KL52',\n",
       " 'ppt__1259': 'KL62',\n",
       " 'ppt__1278': 'KL25',\n",
       " 'ppt__1279': 'KL25',\n",
       " 'ppt__1280': 'KL25',\n",
       " 'ppt__1287': 'KL27',\n",
       " 'ppt__1294': 'KL17',\n",
       " 'ppt__1295': 'KL17',\n",
       " 'ppt__1303': 'KL36',\n",
       " 'ppt__1304': 'KL36',\n",
       " 'ppt__1318': 'KL46',\n",
       " 'ppt__1320': 'KL46',\n",
       " 'ppt__1327': 'KL27',\n",
       " 'ppt__1329': 'KL27',\n",
       " 'ppt__1334': 'KL17',\n",
       " 'ppt__1343': 'KL17',\n",
       " 'ppt__1346': 'KL64',\n",
       " 'ppt__1348': 'KL62',\n",
       " 'ppt__1349': 'KL62',\n",
       " 'ppt__1360': 'KL64',\n",
       " 'ppt__1393': 'KL52',\n",
       " 'ppt__1397': 'KL52',\n",
       " 'ppt__1417': 'KL25',\n",
       " 'ppt__1418': 'KL25',\n",
       " 'ppt__1420': 'KL25',\n",
       " 'ppt__1427': 'KL63',\n",
       " 'ppt__1435': 'KL23',\n",
       " 'ppt__1452': 'KL64',\n",
       " 'ppt__1458': 'KL25',\n",
       " 'ppt__1483': 'KL105',\n",
       " 'ppt__1492': 'KL64',\n",
       " 'ppt__1493': 'KL64',\n",
       " 'ppt__1495': 'KL27',\n",
       " 'ppt__1498': 'KL46',\n",
       " 'ppt__1507': 'KL23',\n",
       " 'ppt__1513': 'KL64',\n",
       " 'ppt__1514': 'KL64',\n",
       " 'ppt__1518': 'KL23',\n",
       " 'ppt__1528': 'KL149',\n",
       " 'ppt__1561': 'KL22',\n",
       " 'ppt__1567': 'KL74',\n",
       " 'ppt__1569': 'KL17',\n",
       " 'ppt__1576': 'KL149',\n",
       " 'ppt__1639': 'KL46',\n",
       " 'ppt__1643': 'KL17',\n",
       " 'ppt__1647': 'KL17',\n",
       " 'ppt__1653': 'KL54',\n",
       " 'ppt__1655': 'KL139',\n",
       " 'ppt__1664': 'KL116',\n",
       " 'ppt__1669': 'KL116',\n",
       " 'ppt__1670': 'KL116',\n",
       " 'ppt__1684': 'KL46',\n",
       " 'ppt__1689': 'KL46',\n",
       " 'ppt__1698': 'KL25',\n",
       " 'ppt__1702': 'KL2',\n",
       " 'ppt__1717': 'KL25',\n",
       " 'ppt__1720': 'KL3',\n",
       " 'ppt__1741': 'KL36',\n",
       " 'ppt__1745': 'KL106',\n",
       " 'ppt__1765': 'KL64',\n",
       " 'ppt__1781': 'KL27',\n",
       " 'ppt__1789': 'KL3',\n",
       " 'ppt__1793': 'KL81',\n",
       " 'ppt__1797': 'KL145',\n",
       " 'ppt__1798': 'KL145',\n",
       " 'ppt__1802': 'KL123',\n",
       " 'ppt__1803': 'KL123',\n",
       " 'ppt__1812': 'KL43',\n",
       " 'ppt__1815': 'KL43',\n",
       " 'ppt__1820': 'KL118',\n",
       " 'ppt__1826': 'KL36',\n",
       " 'ppt__1830': 'KL25',\n",
       " 'ppt__1840': 'KL27',\n",
       " 'ppt__1860': 'KL108',\n",
       " 'ppt__1875': 'KL47',\n",
       " 'ppt__1897': 'KL151',\n",
       " 'ppt__1953': 'KL47',\n",
       " 'ppt__1954': 'KL17',\n",
       " 'ppt__1963': 'KL7',\n",
       " 'ppt__1966': 'KL19',\n",
       " 'ppt__1022': 'KL22',\n",
       " 'ppt__1976': 'KL106',\n",
       " 'ppt__1977': 'KL106',\n",
       " 'ppt__1978': 'KL105',\n",
       " 'ppt__1988': 'KL19',\n",
       " 'ppt__1996': 'KL2',\n",
       " 'ppt__1999': 'KL38',\n",
       " 'ppt__2018': 'KL27',\n",
       " 'ppt__2034': 'KL3',\n",
       " 'ppt__2036': 'KL29',\n",
       " 'ppt__2050': 'KL47',\n",
       " 'ppt__2051': 'KL47',\n",
       " 'ppt__2055': 'KL3',\n",
       " 'ppt__2056': 'KL3',\n",
       " 'ppt__2075': 'KL3',\n",
       " 'ppt__2102': 'KL22',\n",
       " 'ppt__2113': 'KL149',\n",
       " 'ppt__2131': 'KL107',\n",
       " 'ppt__2135': 'KL25',\n",
       " 'ppt__2139': 'KL24',\n",
       " 'ppt__2145': 'KL17',\n",
       " 'ppt__2166': 'KL13',\n",
       " 'ppt__2187': 'KL63',\n",
       " 'ppt__2196': 'KL47',\n",
       " 'ppt__2219': 'KL18',\n",
       " 'ppt__2220': 'KL118',\n",
       " 'ppt__2229': 'KL63',\n",
       " 'ppt__2235': 'KL23',\n",
       " 'ppt__2237': 'KL117',\n",
       " 'ppt__2244': 'KL34',\n",
       " 'ppt__2246': 'KL34',\n",
       " 'ppt__2252': 'KL74',\n",
       " 'ppt__2253': 'KL74',\n",
       " 'ppt__2265': 'KL64',\n",
       " 'ppt__2271': 'KL12',\n",
       " 'ppt__2276': 'KL12',\n",
       " 'ppt__2287': 'KL17',\n",
       " 'ppt__2313': 'KL107',\n",
       " 'ppt__2315': 'KL107',\n",
       " 'ppt__2324': 'KL16',\n",
       " 'ppt__2332': 'KL19',\n",
       " 'ppt__2333': 'KL19',\n",
       " 'ppt__2336': 'KL45',\n",
       " 'ppt__2341': 'KL17',\n",
       " 'ppt__2358': 'KL128',\n",
       " 'ppt__2360': 'KL128',\n",
       " 'ppt__2365': 'KL149',\n",
       " 'ppt__2368': 'KL64',\n",
       " 'ppt__2377': 'KL17',\n",
       " 'ppt__2382': 'KL38',\n",
       " 'ppt__2396': 'KL64',\n",
       " 'ppt__2402': 'KL17',\n",
       " 'ppt__2408': 'KL116',\n",
       " 'ppt__2419': 'KL105',\n",
       " 'ppt__2432': 'KL105',\n",
       " 'ppt__2441': 'KL106',\n",
       " 'ppt__2445': 'KL24',\n",
       " 'ppt__2463': 'KL25',\n",
       " 'ppt__2471': 'KL25',\n",
       " 'ppt__2509': 'KL25',\n",
       " 'ppt__2522': 'KL13',\n",
       " 'ppt__2525': 'KL46',\n",
       " 'ppt__2526': 'KL46',\n",
       " 'ppt__2531': 'KL128',\n",
       " 'ppt__2532': 'KL128',\n",
       " 'ppt__2552': 'KL106',\n",
       " 'ppt__2564': 'KL34',\n",
       " 'ppt__2568': 'KL63',\n",
       " 'ppt__2572': 'KL63',\n",
       " 'ppt__2575': 'KL81',\n",
       " 'ppt__2594': 'KL3',\n",
       " 'ppt__2596': 'KL64',\n",
       " 'ppt__2598': 'KL64',\n",
       " 'ppt__2600': 'KL64',\n",
       " 'ppt__2601': 'KL64',\n",
       " 'ppt__2602': 'KL24',\n",
       " 'ppt__2603': 'KL2',\n",
       " 'ppt__2627': 'KL64',\n",
       " 'ppt__2633': 'KL70',\n",
       " 'ppt__2642': 'KL111',\n",
       " 'ppt__2645': 'KL107',\n",
       " 'ppt__2661': 'KL17',\n",
       " 'ppt__2663': 'KL64',\n",
       " 'ppt__2671': 'KL25',\n",
       " 'ppt__2672': 'KL25',\n",
       " 'ppt__2682': 'KL3',\n",
       " 'ppt__2737': 'KL57',\n",
       " 'ppt__2738': 'KL24',\n",
       " 'ppt__2744': 'KL74',\n",
       " 'ppt__2746': 'KL74',\n",
       " 'ppt__2749': 'KL74',\n",
       " 'ppt__2750': 'KL36',\n",
       " 'ppt__2752': 'KL64',\n",
       " 'ppt__2753': 'KL64',\n",
       " 'ppt__2755': 'KL127',\n",
       " 'ppt__2756': 'KL127',\n",
       " 'ppt__2757': 'KL127',\n",
       " 'ppt__2758': 'KL23',\n",
       " 'ppt__2765': 'KL43',\n",
       " 'ppt__2766': 'KL43',\n",
       " 'ppt__2776': 'KL139',\n",
       " 'ppt__2777': 'KL139',\n",
       " 'ppt__2783': 'KL7',\n",
       " 'ppt__2784': 'KL7',\n",
       " 'ppt__2790': 'KL23',\n",
       " 'ppt__2793': 'KL23',\n",
       " 'ppt__1312': 'KL35',\n",
       " 'ppt__2796': 'KL64',\n",
       " 'ppt__2799': 'KL24',\n",
       " 'ppt__2806': 'KL30',\n",
       " 'ppt__2815': 'KL17',\n",
       " 'ppt__2816': 'KL17',\n",
       " 'ppt__2823': 'KL12',\n",
       " 'ppt__2825': 'KL25',\n",
       " 'ppt__2826': 'KL25',\n",
       " 'ppt__2827': 'KL74',\n",
       " 'ppt__2830': 'KL51',\n",
       " 'ppt__2831': 'KL51',\n",
       " 'ppt__2833': 'KL112',\n",
       " 'ppt__2857': 'KL43',\n",
       " 'ppt__2861': 'KL57',\n",
       " 'ppt__2864': 'KL81',\n",
       " 'ppt__2887': 'KL64',\n",
       " 'ppt__2891': 'KL64',\n",
       " 'ppt__2892': 'KL64',\n",
       " 'ppt__2893': 'KL64',\n",
       " 'ppt__2894': 'KL64',\n",
       " 'ppt__2895': 'KL64',\n",
       " 'ppt__2906': 'KL17',\n",
       " 'ppt__2916': 'KL2',\n",
       " 'ppt__2920': 'KL111',\n",
       " 'ppt__2922': 'KL25',\n",
       " 'ppt__2930': 'KL150',\n",
       " 'ppt__2933': 'KL117',\n",
       " 'ppt__2936': 'KL25',\n",
       " 'ppt__2941': 'KL63',\n",
       " 'ppt__1882': 'KL63',\n",
       " 'ppt__2948': 'KL12',\n",
       " 'ppt__2949': 'KL47',\n",
       " 'ppt__2952': 'KL47',\n",
       " 'ppt__2954': 'KL47',\n",
       " 'ppt__2970': 'KL47',\n",
       " 'ppt__2971': 'KL47',\n",
       " 'ppt__2973': 'KL25',\n",
       " 'ppt__2974': 'KL25',\n",
       " 'ppt__2976': 'KL25',\n",
       " 'ppt__2977': 'KL158',\n",
       " 'ppt__1469': 'KL111',\n",
       " 'ppt__2989': 'KL123',\n",
       " 'ppt__1529': 'KL52',\n",
       " 'ppt__3001': 'KL2',\n",
       " 'ppt__3003': 'KL2',\n",
       " 'ppt__3004': 'KL2',\n",
       " 'ppt__3006': 'KL2',\n",
       " 'ppt__3012': 'KL16',\n",
       " 'ppt__3016': 'KL12',\n",
       " 'ppt__3018': 'KL151',\n",
       " 'ppt__3024': 'KL106',\n",
       " 'ppt__3028': 'KL17',\n",
       " 'ppt__3032': 'KL62',\n",
       " 'ppt__3040': 'KL107',\n",
       " 'ppt__3042': 'KL107',\n",
       " 'ppt__3053': 'KL3',\n",
       " 'ppt__3055': 'KL3',\n",
       " 'ppt__3062': 'KL17',\n",
       " 'ppt__3066': 'KL46',\n",
       " 'ppt__3071': 'KL46',\n",
       " 'ppt__3072': 'KL46',\n",
       " 'ppt__3080': 'KL17',\n",
       " 'ppt__3081': 'KL17',\n",
       " 'ppt__3088': 'KL43',\n",
       " 'ppt__3092': 'KL25',\n",
       " 'ppt__3102': 'KL27',\n",
       " 'ppt__3107': 'KL30',\n",
       " 'ppt__3109': 'KL30',\n",
       " 'ppt__1351': 'KL30',\n",
       " 'ppt__3124': 'KL24',\n",
       " 'ppt__3131': 'KL35',\n",
       " 'ppt__3143': 'KL3',\n",
       " 'ppt__3144': 'KL3',\n",
       " 'ppt__3145': 'KL116',\n",
       " 'ppt__3150': 'KL2',\n",
       " 'ppt__3151': 'KL118',\n",
       " 'ppt__3162': 'KL25',\n",
       " 'ppt__3168': 'KL51',\n",
       " 'ppt__3187': 'KL23',\n",
       " 'ppt__3191': 'KL17',\n",
       " 'ppt__3198': 'KL19',\n",
       " 'ppt__3213': 'KL35',\n",
       " 'ppt__3234': 'KL12',\n",
       " 'ppt__3235': 'KL12',\n",
       " 'ppt__3244': 'KL70',\n",
       " 'ppt__3246': 'KL70',\n",
       " 'ppt__3247': 'KL70',\n",
       " 'ppt__3271': 'KL128',\n",
       " 'ppt__3272': 'KL128',\n",
       " 'ppt__3274': 'KL128',\n",
       " 'ppt__3287': 'KL30',\n",
       " 'ppt__3300': 'KL17',\n",
       " 'ppt__3310': 'KL16',\n",
       " 'ppt__3312': 'KL116',\n",
       " 'ppt__3314': 'KL116',\n",
       " 'ppt__3336': 'KL27',\n",
       " 'ppt__3338': 'KL27',\n",
       " 'ppt__3339': 'KL19',\n",
       " 'ppt__3344': 'KL25',\n",
       " 'ppt__3346': 'KL7',\n",
       " 'ppt__3358': 'KL17',\n",
       " 'ppt__3372': 'KL43',\n",
       " 'ppt__3373': 'KL43',\n",
       " 'ppt__3380': 'KL43',\n",
       " 'ppt__3387': 'KL111',\n",
       " 'ppt__3389': 'KL111',\n",
       " 'ppt__3402': 'KL62',\n",
       " 'ppt__3440': 'KL57',\n",
       " 'ppt__3445': 'KL63',\n",
       " 'ppt__3451': 'KL81',\n",
       " 'ppt__3466': 'KL17',\n",
       " 'ppt__3468': 'KL127',\n",
       " 'ppt__3471': 'KL105',\n",
       " 'ppt__3484': 'KL18',\n",
       " 'ppt__3486': 'KL63',\n",
       " 'ppt__3490': 'KL23',\n",
       " 'ppt__3501': 'KL25',\n",
       " 'ppt__3503': 'KL64',\n",
       " 'ppt__3512': 'KL122',\n",
       " 'ppt__3516': 'KL27',\n",
       " 'ppt__3518': 'KL17',\n",
       " 'ppt__3523': 'KL3',\n",
       " 'ppt__3524': 'KL34',\n",
       " 'ppt__3536': 'KL62',\n",
       " 'ppt__3539': 'KL62',\n",
       " 'ppt__3540': 'KL62',\n",
       " 'ppt__3543': 'KL2',\n",
       " 'ppt__3547': 'KL105',\n",
       " 'ppt__3567': 'KL46',\n",
       " 'ppt__3574': 'KL107',\n",
       " 'ppt__3589': 'KL27',\n",
       " 'ppt__3590': 'KL27',\n",
       " 'ppt__3592': 'KL47',\n",
       " 'ppt__3597': 'KL145',\n",
       " 'ppt__3598': 'KL145',\n",
       " 'ppt__3602': 'KL17',\n",
       " 'ppt__3604': 'KL24',\n",
       " 'ppt__3623': 'KL17',\n",
       " 'ppt__3632': 'KL63',\n",
       " 'ppt__3640': 'KL38',\n",
       " 'ppt__3649': 'KL17',\n",
       " 'ppt__3651': 'KL17',\n",
       " 'ppt__3652': 'KL17',\n",
       " 'ppt__3664': 'KL2',\n",
       " 'ppt__3667': 'KL24',\n",
       " 'ppt__3675': 'KL81',\n",
       " 'ppt__3677': 'KL17',\n",
       " 'ppt__3680': 'KL22',\n",
       " 'ppt__3692': 'KL17',\n",
       " 'ppt__3706': 'KL122',\n",
       " 'ppt__3727': 'KL106',\n",
       " 'ppt__3730': 'KL25',\n",
       " 'ppt__3735': 'KL27',\n",
       " 'ppt__3738': 'KL27',\n",
       " 'ppt__3444': 'KL63',\n",
       " 'ppt__3751': 'KL63',\n",
       " 'ppt__3762': 'KL25',\n",
       " 'ppt__3777': 'KL81',\n",
       " 'ppt__3791': 'KL38',\n",
       " 'ppt__3797': 'KL106',\n",
       " 'ppt__3811': 'KL12',\n",
       " 'ppt__3819': 'KL24',\n",
       " 'ppt__3826': 'KL24',\n",
       " 'ppt__3828': 'KL105',\n",
       " 'ppt__3837': 'KL22',\n",
       " 'ppt__3843': 'KL113',\n",
       " 'ppt__3865': 'KL127',\n",
       " 'ppt__3867': 'KL127',\n",
       " 'ppt__3868': 'KL127',\n",
       " 'ppt__3898': 'KL25',\n",
       " 'ppt__3916': 'KL70',\n",
       " 'ppt__3918': 'KL70',\n",
       " 'ppt__3924': 'KL22',\n",
       " 'ppt__3925': 'KL24',\n",
       " 'ppt__3930': 'KL23',\n",
       " 'ppt__3932': 'KL46',\n",
       " 'ppt__3935': 'KL46',\n",
       " 'ppt__3937': 'KL46',\n",
       " 'ppt__3938': 'KL46',\n",
       " 'ppt__3943': 'KL46',\n",
       " 'ppt__3961': 'KL46',\n",
       " 'ppt__3962': 'KL46',\n",
       " 'ppt__3968': 'KL64',\n",
       " 'ppt__3972': 'KL43',\n",
       " 'ppt__3988': 'KL3',\n",
       " 'ppt__3995': 'KL46',\n",
       " 'ppt__3999': 'KL63',\n",
       " 'ppt__4001': 'KL63',\n",
       " 'ppt__4003': 'KL17',\n",
       " 'ppt__4006': 'KL27',\n",
       " 'ppt__4010': 'KL81',\n",
       " 'ppt__4013': 'KL81',\n",
       " 'ppt__4015': 'KL38',\n",
       " 'ppt__4016': 'KL38',\n",
       " 'ppt__4031': 'KL46',\n",
       " 'ppt__4038': 'KL24',\n",
       " 'ppt__4060': 'KL111',\n",
       " 'ppt__4061': 'KL111',\n",
       " 'ppt__4063': 'KL81',\n",
       " 'ppt__4066': 'KL123',\n",
       " 'ppt__4067': 'KL62',\n",
       " 'ppt__4068': 'KL62',\n",
       " 'ppt__4074': 'KL47',\n",
       " 'ppt__4095': 'KL17',\n",
       " 'ppt__4100': 'KL111',\n",
       " 'ppt__4101': 'KL111',\n",
       " 'ppt__4127': 'KL46',\n",
       " 'ppt__4132': 'KL64',\n",
       " 'ppt__4135': 'KL105',\n",
       " 'ppt__4158': 'KL3',\n",
       " 'ppt__4183': 'KL64',\n",
       " 'ppt__4187': 'KL36',\n",
       " 'ppt__4194': 'KL63',\n",
       " 'ppt__4209': 'KL46',\n",
       " 'ppt__4213': 'KL46',\n",
       " 'ppt__4254': 'KL64',\n",
       " 'ppt__4256': 'KL7',\n",
       " 'ppt__4269': 'KL157',\n",
       " 'ppt__4272': 'KL157',\n",
       " 'ppt__4273': 'KL66',\n",
       " 'ppt__4284': 'KL62',\n",
       " 'ppt__4286': 'KL62',\n",
       " 'ppt__4287': 'KL62',\n",
       " 'ppt__4303': 'KL3',\n",
       " 'ppt__4313': 'KL36',\n",
       " 'ppt__4317': 'KL23',\n",
       " 'ppt__4318': 'KL23',\n",
       " 'ppt__4326': 'KL81',\n",
       " 'ppt__4330': 'KL81',\n",
       " 'ppt__4352': 'KL24',\n",
       " 'ppt__4354': 'KL74',\n",
       " 'ppt__4360': 'KL62',\n",
       " 'ppt__4362': 'KL62',\n",
       " 'ppt__4363': 'KL62',\n",
       " 'ppt__4366': 'KL51',\n",
       " 'ppt__4376': 'KL123',\n",
       " 'ppt__4388': 'KL128',\n",
       " 'ppt__4394': 'KL27',\n",
       " 'ppt__4399': 'KL43',\n",
       " 'ppt__4440': 'KL45',\n",
       " 'ppt__4444': 'KL2',\n",
       " 'ppt__4450': 'KL30',\n",
       " 'ppt__4477': 'KL118',\n",
       " 'ppt__4480': 'KL81',\n",
       " 'ppt__4483': 'KL81',\n",
       " 'ppt__4484': 'KL149',\n",
       " 'ppt__4486': 'KL25',\n",
       " 'ppt__4488': 'KL17',\n",
       " 'ppt__4498': 'KL64',\n",
       " 'ppt__4506': 'KL51',\n",
       " 'ppt__4512': 'KL23',\n",
       " 'ppt__4514': 'KL17',\n",
       " 'ppt__4518': 'KL25',\n",
       " 'ppt__4519': 'KL25',\n",
       " 'ppt__4532': 'KL149',\n",
       " 'ppt__4533': 'KL149',\n",
       " 'ppt__1086': 'KL46',\n",
       " 'ppt__4540': 'KL62',\n",
       " 'ppt__4544': 'KL23',\n",
       " 'ppt__4557': 'KL27',\n",
       " 'ppt__4559': 'KL27',\n",
       " 'ppt__4565': 'KL111',\n",
       " 'ppt__4577': 'KL7',\n",
       " 'ppt__4589': 'KL145',\n",
       " 'ppt__4618': 'KL9',\n",
       " 'ppt__4628': 'KL47',\n",
       " 'ppt__4633': 'KL64',\n",
       " 'ppt__4638': 'KL70',\n",
       " 'ppt__4641': 'KL17',\n",
       " 'ppt__4668': 'KL12',\n",
       " 'ppt__4697': 'KL7',\n",
       " 'ppt__4699': 'KL7',\n",
       " 'ppt__4703': 'KL23',\n",
       " 'ppt__4704': 'KL23',\n",
       " 'ppt__4712': 'KL19',\n",
       " 'ppt__4713': 'KL19',\n",
       " 'ppt__4715': 'KL19',\n",
       " 'ppt__4718': 'KL19',\n",
       " 'ppt__4730': 'KL123',\n",
       " 'ppt__4733': 'KL43',\n",
       " 'ppt__4738': 'KL16',\n",
       " 'ppt__4739': 'KL17',\n",
       " 'ppt__4744': 'KL122',\n",
       " 'ppt__4750': 'KL123',\n",
       " 'ppt__4764': 'KL111',\n",
       " 'ppt__4765': 'KL111',\n",
       " 'ppt__4774': 'KL149',\n",
       " 'ppt__4777': 'KL17',\n",
       " 'ppt__4778': 'KL62',\n",
       " 'ppt__4779': 'KL62',\n",
       " 'ppt__4787': 'KL62',\n",
       " 'ppt__4790': 'KL64',\n",
       " 'ppt__4791': 'KL52',\n",
       " 'ppt__4810': 'KL24',\n",
       " 'ppt__4827': 'KL107',\n",
       " 'ppt__4829': 'KL52',\n",
       " 'ppt__4835': 'KL47',\n",
       " 'ppt__4852': 'KL81',\n",
       " 'ppt__4864': 'KL27',\n",
       " 'ppt__4873': 'KL62',\n",
       " 'ppt__4881': 'KL57',\n",
       " 'ppt__4882': 'KL57',\n",
       " 'ppt__4899': 'KL47',\n",
       " 'ppt__4908': 'KL118',\n",
       " 'ppt__4917': 'KL7',\n",
       " 'ppt__4920': 'KL30',\n",
       " 'ppt__4923': 'KL62',\n",
       " 'ppt__4924': 'KL23',\n",
       " 'ppt__4934': 'KL64',\n",
       " 'ppt__4964': 'KL23',\n",
       " 'ppt__4970': 'KL52',\n",
       " 'ppt__4978': 'KL7',\n",
       " 'ppt__4980': 'KL7',\n",
       " 'ppt__4988': 'KL57',\n",
       " 'ppt__4990': 'KL3',\n",
       " 'ppt__4996': 'KL74',\n",
       " 'ppt__5000': 'KL74',\n",
       " 'ppt__5002': 'KL29',\n",
       " 'ppt__5013': 'KL29',\n",
       " 'ppt__5015': 'KL29',\n",
       " 'ppt__5029': 'KL127',\n",
       " 'ppt__5035': 'KL128',\n",
       " 'ppt__5043': 'KL62',\n",
       " 'ppt__5045': 'KL105',\n",
       " 'ppt__5047': 'KL105',\n",
       " 'ppt__5053': 'KL116',\n",
       " 'ppt__5058': 'KL23',\n",
       " 'ppt__5062': 'KL24',\n",
       " 'ppt__5067': 'KL25',\n",
       " 'ppt__5069': 'KL23',\n",
       " 'ppt__5070': 'KL45',\n",
       " 'ppt__5071': 'KL45',\n",
       " 'ppt__5076': 'KL70',\n",
       " 'ppt__5083': 'KL70',\n",
       " 'ppt__5089': 'KL62',\n",
       " 'ppt__5097': 'KL70',\n",
       " 'ppt__5101': 'KL70',\n",
       " 'ppt__5130': 'KL23',\n",
       " 'ppt__5166': 'KL64',\n",
       " 'ppt__5182': 'KL43',\n",
       " 'ppt__5184': 'KL43',\n",
       " 'ppt__5186': 'KL111',\n",
       " 'ppt__5196': 'KL17',\n",
       " 'ppt__5201': 'KL25',\n",
       " 'ppt__5204': 'KL25',\n",
       " 'ppt__5205': 'KL24',\n",
       " 'ppt__5219': 'KL23',\n",
       " 'ppt__5233': 'KL150',\n",
       " 'ppt__5237': 'KL17',\n",
       " 'ppt__5240': 'KL117',\n",
       " 'ppt__5243': 'KL62',\n",
       " 'ppt__5252': 'KL3',\n",
       " 'ppt__5259': 'KL17',\n",
       " 'ppt__5279': 'KL105',\n",
       " 'ppt__5281': 'KL29',\n",
       " 'ppt__5287': 'KL29',\n",
       " 'ppt__5288': 'KL29',\n",
       " 'ppt__5289': 'KL29',\n",
       " 'ppt__5290': 'KL29',\n",
       " 'ppt__5293': 'KL29',\n",
       " 'ppt__5298': 'KL29',\n",
       " 'ppt__5306': 'KL35',\n",
       " 'ppt__5314': 'KL107',\n",
       " 'ppt__5329': 'KL18',\n",
       " 'ppt__5331': 'KL9',\n",
       " 'ppt__5337': 'KL25',\n",
       " 'ppt__5338': 'KL25',\n",
       " 'ppt__5343': 'KL25',\n",
       " 'ppt__5345': 'KL64',\n",
       " 'ppt__5353': 'KL25',\n",
       " 'ppt__5359': 'KL64',\n",
       " 'ppt__5364': 'KL149',\n",
       " 'ppt__5366': 'KL149',\n",
       " 'ppt__5370': 'KL24',\n",
       " 'ppt__5373': 'KL24',\n",
       " 'ppt__5380': 'KL122',\n",
       " 'ppt__5387': 'KL38',\n",
       " 'ppt__5445': 'KL62',\n",
       " 'ppt__5456': 'KL18',\n",
       " 'ppt__5463': 'KL24',\n",
       " 'ppt__5467': 'KL3',\n",
       " 'ppt__5471': 'KL29',\n",
       " 'ppt__5472': 'KL29',\n",
       " 'ppt__5495': 'KL145',\n",
       " 'ppt__5498': 'KL30',\n",
       " 'ppt__5511': 'KL27',\n",
       " 'ppt__5512': 'KL27',\n",
       " 'ppt__5515': 'KL123',\n",
       " 'ppt__5516': 'KL123',\n",
       " 'ppt__5520': 'KL128',\n",
       " 'ppt__5528': 'KL23',\n",
       " 'ppt__5532': 'KL17',\n",
       " 'ppt__5535': 'KL24',\n",
       " 'ppt__5536': 'KL24',\n",
       " 'ppt__5538': 'KL12',\n",
       " 'ppt__5546': 'KL24',\n",
       " 'ppt__5548': 'KL17',\n",
       " 'ppt__5554': 'KL35',\n",
       " 'ppt__5562': 'KL23',\n",
       " 'ppt__5567': 'KL62',\n",
       " 'ppt__5568': 'KL62',\n",
       " 'ppt__5571': 'KL36',\n",
       " 'ppt__5575': 'KL128',\n",
       " 'ppt__5578': 'KL128',\n",
       " 'ppt__5579': 'KL128',\n",
       " 'ppt__5581': 'KL128',\n",
       " 'ppt__5582': 'KL128',\n",
       " 'ppt__5604': 'KL3',\n",
       " 'ppt__5605': 'KL64',\n",
       " 'ppt__5606': 'KL64',\n",
       " 'ppt__5610': 'KL47',\n",
       " 'ppt__5611': 'KL23',\n",
       " 'ppt__5612': 'KL23',\n",
       " 'ppt__5633': 'KL106',\n",
       " 'ppt__5635': 'KL24',\n",
       " 'ppt__5646': 'KL27',\n",
       " 'ppt__5648': 'KL17',\n",
       " 'ppt__5650': 'KL151',\n",
       " 'ppt__5655': 'KL19',\n",
       " 'ppt__5656': 'KL19',\n",
       " 'ppt__5663': 'KL38',\n",
       " 'ppt__5674': 'KL63',\n",
       " 'ppt__5677': 'KL25',\n",
       " 'ppt__5678': 'KL25',\n",
       " 'ppt__5689': 'KL27',\n",
       " 'ppt__5692': 'KL24',\n",
       " 'ppt__5710': 'KL38',\n",
       " 'ppt__5712': 'KL106',\n",
       " 'ppt__5719': 'KL25',\n",
       " 'ppt__5720': 'KL107',\n",
       " 'ppt__5735': 'KL157',\n",
       " 'ppt__5736': 'KL157',\n",
       " 'ppt__5738': 'KL52',\n",
       " 'ppt__5762': 'KL27',\n",
       " 'ppt__5773': 'KL62',\n",
       " 'ppt__5789': 'KL27',\n",
       " 'ppt__5793': 'KL64',\n",
       " 'ppt__5796': 'KL64',\n",
       " 'ppt__5805': 'KL2',\n",
       " 'ppt__5810': 'KL52',\n",
       " 'ppt__5813': 'KL145',\n",
       " 'ppt__5814': 'KL145',\n",
       " 'ppt__5823': 'KL25',\n",
       " 'ppt__5826': 'KL24',\n",
       " 'ppt__5852': 'KL23',\n",
       " 'ppt__5858': 'KL25',\n",
       " 'ppt__5868': 'KL2',\n",
       " 'ppt__5886': 'KL66',\n",
       " 'ppt__5889': 'KL66',\n",
       " 'ppt__5901': 'KL149',\n",
       " 'ppt__5908': 'KL2',\n",
       " 'ppt__5916': 'KL17',\n",
       " 'ppt__5929': 'KL2',\n",
       " 'ppt__5931': 'KL2',\n",
       " 'ppt__5947': 'KL38',\n",
       " 'ppt__5952': 'KL17',\n",
       " 'ppt__5955': 'KL25',\n",
       " 'ppt__5956': 'KL25',\n",
       " 'ppt__5964': 'KL3',\n",
       " 'ppt__5969': 'KL17',\n",
       " 'ppt__5972': 'KL63',\n",
       " 'ppt__5973': 'KL63',\n",
       " 'ppt__5982': 'KL117',\n",
       " 'ppt__5985': 'KL19',\n",
       " 'ppt__5999': 'KL27',\n",
       " 'ppt__6003': 'KL25',\n",
       " 'ppt__6013': 'KL17',\n",
       " 'ppt__6014': 'KL17',\n",
       " 'ppt__6015': 'KL17',\n",
       " 'ppt__6022': 'KL108',\n",
       " 'ppt__6023': 'KL24',\n",
       " 'ppt__6031': 'KL17',\n",
       " 'ppt__6038': 'KL2',\n",
       " 'ppt__6040': 'KL25',\n",
       " 'ppt__6046': 'KL81',\n",
       " 'ppt__6051': 'KL51',\n",
       " 'ppt__6059': 'KL64',\n",
       " 'ppt__6068': 'KL17',\n",
       " 'ppt__6080': 'KL64',\n",
       " 'ppt__6085': 'KL113',\n",
       " 'ppt__6093': 'KL34',\n",
       " 'ppt__6098': 'KL29',\n",
       " 'ppt__6111': 'KL45',\n",
       " 'ppt__6118': 'KL12',\n",
       " 'ppt__6119': 'KL23',\n",
       " 'ppt__6127': 'KL7',\n",
       " 'ppt__6131': 'KL107',\n",
       " 'ppt__6133': 'KL107',\n",
       " 'ppt__6135': 'KL107',\n",
       " 'ppt__6144': 'KL24',\n",
       " 'ppt__6145': 'KL47',\n",
       " 'ppt__6149': 'KL57',\n",
       " 'ppt__6155': 'KL62',\n",
       " 'ppt__6156': 'KL62',\n",
       " 'ppt__6169': 'KL45',\n",
       " 'ppt__6170': 'KL45',\n",
       " 'ppt__6198': 'KL74',\n",
       " 'ppt__6200': 'KL74',\n",
       " 'ppt__6202': 'KL105',\n",
       " 'ppt__6204': 'KL105',\n",
       " 'ppt__6205': 'KL27',\n",
       " 'ppt__6211': 'KL25',\n",
       " 'ppt__6213': 'KL17',\n",
       " 'ppt__6214': 'KL17',\n",
       " 'ppt__6217': 'KL17',\n",
       " 'ppt__6228': 'KL23',\n",
       " 'ppt__6236': 'KL107',\n",
       " 'ppt__6246': 'KL63',\n",
       " 'ppt__6258': 'KL111',\n",
       " 'ppt__6259': 'KL27',\n",
       " 'ppt__6261': 'KL111',\n",
       " 'ppt__6263': 'KL111',\n",
       " 'ppt__6265': 'KL111',\n",
       " 'ppt__6267': 'KL111',\n",
       " 'ppt__6268': 'KL111',\n",
       " 'ppt__6271': 'KL52',\n",
       " 'ppt__6280': 'KL12',\n",
       " 'ppt__6299': 'KL145',\n",
       " 'ppt__6304': 'KL74',\n",
       " 'ppt__6307': 'KL127',\n",
       " 'ppt__6322': 'KL27',\n",
       " 'ppt__6323': 'KL27',\n",
       " 'ppt__6341': 'KL46',\n",
       " 'ppt__6342': 'KL17',\n",
       " 'ppt__6372': 'KL57',\n",
       " 'ppt__6373': 'KL17',\n",
       " 'ppt__6375': 'KL25',\n",
       " 'ppt__6376': 'KL25',\n",
       " 'ppt__6379': 'KL145',\n",
       " 'ppt__6389': 'KL25',\n",
       " 'ppt__6392': 'KL43',\n",
       " 'ppt__6393': 'KL66',\n",
       " 'ppt__6401': 'KL64',\n",
       " 'ppt__6405': 'KL38',\n",
       " 'ppt__6406': 'KL111',\n",
       " 'ppt__6408': 'KL111',\n",
       " 'ppt__6424': 'KL111',\n",
       " 'ppt__6436': 'KL64',\n",
       " 'ppt__6438': 'KL24',\n",
       " 'ppt__6441': 'KL63',\n",
       " 'ppt__6443': 'KL63',\n",
       " 'ppt__6446': 'KL2',\n",
       " 'ppt__6462': 'KL118',\n",
       " 'ppt__6453': 'KL24',\n",
       " 'ppt__6466': 'KL29',\n",
       " 'ppt__6469': 'KL29',\n",
       " 'ppt__6471': 'KL24',\n",
       " 'ppt__6510': 'KL52',\n",
       " 'ppt__6528': 'KL63',\n",
       " 'ppt__6529': 'KL16',\n",
       " 'ppt__6543': 'KL107',\n",
       " 'ppt__6592': 'KL151',\n",
       " 'ppt__6594': 'KL149',\n",
       " 'ppt__6595': 'KL149',\n",
       " 'ppt__6604': 'KL45',\n",
       " 'ppt__6606': 'KL106',\n",
       " 'ppt__6616': 'KL107',\n",
       " 'ppt__6617': 'KL25',\n",
       " 'ppt__6618': 'KL25',\n",
       " 'ppt__6629': 'KL64',\n",
       " 'ppt__6631': 'KL149',\n",
       " 'ppt__6646': 'KL74',\n",
       " 'ppt__6654': 'KL24',\n",
       " 'ppt__6664': 'KL74',\n",
       " 'ppt__6668': 'KL43',\n",
       " 'ppt__6669': 'KL107',\n",
       " 'ppt__6672': 'KL70',\n",
       " 'ppt__6674': 'KL70',\n",
       " 'ppt__6677': 'KL70',\n",
       " 'ppt__6678': 'KL70',\n",
       " 'ppt__6687': 'KL145',\n",
       " 'ppt__6688': 'KL145',\n",
       " 'ppt__6689': 'KL145',\n",
       " 'ppt__6699': 'KL30',\n",
       " 'ppt__6702': 'KL74',\n",
       " 'ppt__6717': 'KL2',\n",
       " 'ppt__6723': 'KL17',\n",
       " 'ppt__6725': 'KL123',\n",
       " 'ppt__6726': 'KL112',\n",
       " 'ppt__5446': 'KL106',\n",
       " 'ppt__6754': 'KL81',\n",
       " 'ppt__6764': 'KL38',\n",
       " 'ppt__6765': 'KL38',\n",
       " 'ppt__6782': 'KL25',\n",
       " 'ppt__6789': 'KL13',\n",
       " 'ppt__6813': 'KL38',\n",
       " 'ppt__6817': 'KL30',\n",
       " 'ppt__6822': 'KL62',\n",
       " 'ppt__6831': 'KL17',\n",
       " 'ppt__6832': 'KL17',\n",
       " 'ppt__6848': 'KL45',\n",
       " 'ppt__6874': 'KL74',\n",
       " 'ppt__6882': 'KL74',\n",
       " 'ppt__6884': 'KL23',\n",
       " 'ppt__6887': 'KL27',\n",
       " 'ppt__6894': 'KL106',\n",
       " 'ppt__6908': 'KL12',\n",
       " 'ppt__6910': 'KL62',\n",
       " 'ppt__6911': 'KL62',\n",
       " 'ppt__6932': 'KL12',\n",
       " 'ppt__6941': 'KL47',\n",
       " 'ppt__6969': 'KL25',\n",
       " 'ppt__6972': 'KL81',\n",
       " 'ppt__6980': 'KL2',\n",
       " 'ppt__6983': 'KL127',\n",
       " 'ppt__6984': 'KL127',\n",
       " 'ppt__6985': 'KL127',\n",
       " 'ppt__6995': 'KL17',\n",
       " 'ppt__7010': 'KL123',\n",
       " 'ppt__7011': 'KL123',\n",
       " 'ppt__7017': 'KL57',\n",
       " 'ppt__7026': 'KL139',\n",
       " 'ppt__7033': 'KL117',\n",
       " 'ppt__7050': 'KL25',\n",
       " 'ppt__7053': 'KL127',\n",
       " 'ppt__7070': 'KL13',\n",
       " 'ppt__7080': 'KL107',\n",
       " 'ppt__7081': 'KL107',\n",
       " 'ppt__7083': 'KL107',\n",
       " 'ppt__7089': 'KL111',\n",
       " 'ppt__7092': 'KL24',\n",
       " 'ppt__7095': 'KL122',\n",
       " 'ppt__7098': 'KL34',\n",
       " 'ppt__7104': 'KL128',\n",
       " 'ppt__7105': 'KL128',\n",
       " 'ppt__7109': 'KL112',\n",
       " 'ppt__7122': 'KL29',\n",
       " 'ppt__7124': 'KL2',\n",
       " 'ppt__7130': 'KL64',\n",
       " 'ppt__7138': 'KL18',\n",
       " 'ppt__7140': 'KL18',\n",
       " 'ppt__7145': 'KL145',\n",
       " 'ppt__7146': 'KL145',\n",
       " 'ppt__7147': 'KL145',\n",
       " 'ppt__7149': 'KL145',\n",
       " 'minibatch__0': 'KL47',\n",
       " 'minibatch__7': 'KL105',\n",
       " 'minibatch__18': 'KL64',\n",
       " 'minibatch__31': 'KL17',\n",
       " 'minibatch__36': 'KL24',\n",
       " 'minibatch__38': 'KL17',\n",
       " 'minibatch__64': 'KL47',\n",
       " 'minibatch__73': 'KL43',\n",
       " 'minibatch__75': 'KL64',\n",
       " 'minibatch__77': 'KL17',\n",
       " 'minibatch__85': 'KL111',\n",
       " 'minibatch__98': 'KL107',\n",
       " 'minibatch__109': 'KL36',\n",
       " 'minibatch__113': 'KL25',\n",
       " 'minibatch__115': 'KL47',\n",
       " 'minibatch__127': 'KL70',\n",
       " 'minibatch__133': 'KL27',\n",
       " 'minibatch__144': 'KL105',\n",
       " 'minibatch__157': 'KL107',\n",
       " 'minibatch__190': 'KL17',\n",
       " 'minibatch__191': 'KL81',\n",
       " 'minibatch__192': 'KL17',\n",
       " 'minibatch__209': 'KL64',\n",
       " 'minibatch__214': 'KL17',\n",
       " 'minibatch__222': 'KL145',\n",
       " 'minibatch__229': 'KL64',\n",
       " 'minibatch__232': 'KL25',\n",
       " 'minibatch__236': 'KL64',\n",
       " 'minibatch__237': 'KL62',\n",
       " 'minibatch__239': 'KL25',\n",
       " 'minibatch__247': 'KL107',\n",
       " 'minibatch__253': 'KL149',\n",
       " 'minibatch__261': 'KL106',\n",
       " 'minibatch__268': 'KL25',\n",
       " 'minibatch__275': 'KL17',\n",
       " 'minibatch__280': 'KL47',\n",
       " 'minibatch__285': 'KL24',\n",
       " 'minibatch__292': 'KL25',\n",
       " 'minibatch__294': 'KL36',\n",
       " 'minibatch__296': 'KL111',\n",
       " 'minibatch__300': 'KL47',\n",
       " 'minibatch__306': 'KL25',\n",
       " 'minibatch__312': 'KL25',\n",
       " 'minibatch__321': 'KL64',\n",
       " 'minibatch__323': 'KL145',\n",
       " 'minibatch__339': 'KL112',\n",
       " 'minibatch__341': 'KL64',\n",
       " 'minibatch__342': 'KL23',\n",
       " 'minibatch__364': 'KL64',\n",
       " 'minibatch__365': 'KL23',\n",
       " 'minibatch__372': 'KL145',\n",
       " 'minibatch__378': 'KL111',\n",
       " 'minibatch__379': 'KL64',\n",
       " 'minibatch__380': 'KL17',\n",
       " ...}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dico_final_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Other',\n",
       " 1: 'KL116',\n",
       " 2: 'KL81',\n",
       " 3: 'KL17',\n",
       " 4: 'KL64',\n",
       " 5: 'KL127',\n",
       " 6: 'KL19',\n",
       " 7: 'KL27',\n",
       " 8: 'KL34',\n",
       " 9: 'KL74',\n",
       " 10: 'KL46',\n",
       " 11: 'KL149',\n",
       " 12: 'KL106',\n",
       " 13: 'KL38',\n",
       " 14: 'KL25',\n",
       " 15: 'KL51',\n",
       " 16: 'KL23',\n",
       " 17: 'KL107',\n",
       " 18: 'KL30',\n",
       " 19: 'KL2',\n",
       " 20: 'KL150',\n",
       " 21: 'KL62',\n",
       " 22: 'KL63',\n",
       " 23: 'KL139',\n",
       " 24: 'KL43',\n",
       " 25: 'KL128',\n",
       " 26: 'KL108',\n",
       " 27: 'KL18',\n",
       " 28: 'KL145',\n",
       " 29: 'KL70',\n",
       " 30: 'KL117',\n",
       " 31: 'KL47',\n",
       " 32: 'KL29',\n",
       " 33: 'KL3',\n",
       " 34: 'KL45',\n",
       " 35: 'KL111',\n",
       " 36: 'KL35',\n",
       " 37: 'KL123',\n",
       " 38: 'KL12',\n",
       " 39: 'KL24',\n",
       " 40: 'KL7',\n",
       " 41: 'KL16',\n",
       " 42: 'KL22',\n",
       " 43: 'KL36',\n",
       " 44: 'KL118',\n",
       " 45: 'KL105',\n",
       " 46: 'KL57',\n",
       " 47: 'KL52',\n",
       " 48: 'KL9',\n",
       " 49: 'KL151',\n",
       " 50: 'KL66',\n",
       " 51: 'KL13',\n",
       " 52: 'KL122',\n",
       " 53: 'KL157',\n",
       " 54: 'KL54',\n",
       " 55: 'KL113',\n",
       " 56: 'KL158',\n",
       " 57: 'KL112',\n",
       " 58: 'KL28'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_id = {i : value for i,value in enumerate(df_model[\"label\"].unique().tolist())}\n",
    "labels_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode input text\n",
    "input_text = \"MTTYKTGNPLGSAAVKDLFDNAENLDHFENDRSNETWENRFGVPGKTRYGMEQEHDRQISSQEARFQQFLLSSGYVFLGDYQDGPFQFGARNQYIRYDNQYYRLNAATDVGFTTTGTDATSFANDVTHFVLMDGDTLRQNLSSGDGFKWVGQVSSAAALSALPGSEGDRVLLLGYQDGWAATNSDLSGGGEFHYVSSLASVNNGVTVFNGWVRKFTRSVITTFDAGLSPGEDTDHFPQIQKLLEVVPDGFTVEIHGEHRLSSQLIMEVKRNITIVGVAAKLTTKPYKSTIKVVRLASDGITYMGGILSAINCPGLRLDGDLEIEGTRMYPNVLRSDQTAAGEEHGLHFRYCDDLYIGKDIYVHDVFGYGALGVYCNRAFAYRSMLTDTVRESGLNLFGGSVGGRAVGVRTRRTALYGVEIEDTWYGGARDIKVTNCDVEDAFWGIPTINNCSDVEVSGCNIRRARFGAQALQSSAGAYDTRNIRYHDNTYTGCPVGFRTAHPRNVRITRENIDQSEVMPYGYTYPFNNLLFVDNTDRRIFWGPTSSRFLTMVGQTIYIDDVAYTITAAATDATKTGYWKDFATDPDSLVKVTLDKVLPENTDIQTVKSKDWGTAVRGMLTEGRSVNLTIWNNDLTGDSLDSIGIYHNSYNMDGVNTVNESIRGNTFRAHGIWLRMNDAVNTRDVSDNKYADGSQIGISAANLTAAVLSQIKMGNNIRVALPARTSVAAGAVTKYFHANQRYWAVGLRISFTGLSGTGEMRVAIDGTQTHSATSYSTGTAVVEIYGVATFTKGNHQIAINTANSDIVFTSCDIELLIP\"  # Replace this with your input text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt', truncation= True)\n",
    "\n",
    "# Get token classifications\n",
    "outputs = model(input_ids)\n",
    "\n",
    "# The model returns logits which can be turned into probabilities using softmax\n",
    "import torch\n",
    "probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "# the order of labels in model.config.id2label should match the order of probabilities in probs\n",
    "labels = model.config.id2label\n",
    "\n",
    "tokens = []\n",
    "for token_id, token_probs in zip(input_ids[0], probs[0]):\n",
    "    top_label_id = token_probs.argmax().item()\n",
    "    tokens.append(int(labels[top_label_id].split(\"_\")[1]))\n",
    "    #print(f\"{tokenizer.decode([token_id])}: {labels[top_label_id]}\")\n",
    "    \n",
    "\"\"\"with open(f\"{path_work}/output.token.txt\", \"w\") as outfile :\n",
    "    outfile.write(str(tokens))\"\"\"\n",
    "dict(Counter(tokens))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "sklearn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
