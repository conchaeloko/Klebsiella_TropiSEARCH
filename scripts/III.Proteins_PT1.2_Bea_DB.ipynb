{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make blast\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *******************************************************************************************************************************************\n",
    "# 2. The Blastp analysis : preparation step \n",
    "# *******************************************************************************************************************************************\n",
    "\n",
    "    # The makeblastdb command : \n",
    "makeblastdb -in /home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/bea_all_depolymerase.db/bead_depo/bea_depo.DB.fasta \\\n",
    "-dbtype prot  \\\n",
    "-title depolymerase_db \\\n",
    "-out /home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/bea_all_depolymerase.db/bead_depo/bea_depo.DB\n",
    "\n",
    "\n",
    "    # The command for the multifasta faa for the congruent and the loners :\n",
    "import os\n",
    "import subprocess\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "path_70=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "path_db = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/bea_all_depolymerase.db/bead_depo/bea_depo.DB\"\n",
    "path_out = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/blast_out_phageboost_70_80\"\n",
    "\n",
    "path_fasta = [f\"{path_70}/{strain}/tmp/{phage}/{fasta}\" \n",
    "              for strain in os.listdir(f\"{path_70}\") \n",
    "              for phage in os.listdir(f\"{path_70}/{strain}/tmp\") \n",
    "              for fasta in os.listdir(f\"{path_70}/{strain}/tmp/{phage}\")]\n",
    "\n",
    "def blast_bea(path) :\n",
    "    #path_out = \"/\".join(path.split(\"/\")[0:-1])\n",
    "    file_name = path.split(\"/\")[-1].split(\".fasta\")[0]\n",
    "    blastp = f\"blastp -query {path}  -db {path_db} -out {path_out}/{file_name}.out -outfmt 6\"\n",
    "    sub_blastp = subprocess.Popen(blastp, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    press_out, press_err = sub_blastp.communicate()\n",
    "    print(press_out)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    with ThreadPool(10) as p:\n",
    "        p.map(blast_bea, path_fasta)\n",
    "        \n",
    "        \n",
    "def show_result(protein) :\n",
    "    outfmt = [\"qseqid\", \"sseqid\", \"pident\", \"length\", \"mismatch\", \"gapopen\", \"qstart\", \"qend\", \"sstart\" ,\"send\", \"evalue\", \"bitscore\"]\n",
    "    strain = protein.split(\"__\")[0]\n",
    "    prophage = protein.split(\"__\")[1]\n",
    "    results = pd.read_csv(f\"{path_out}/{protein}.out\", names = outfmt, sep = \"\\t\")\n",
    "    return results\n",
    "        \n",
    "        \n",
    "\n",
    "# ****************************************************************************************************\n",
    "#!/bin/bash\n",
    "#BATCH --job-name=blast_depo\n",
    "#SBATCH --qos=medium \n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=40\n",
    "#SBATCH --mem=50gb \n",
    "#SBATCH --time=2-00:00:00 \n",
    "#SBATCH --output=blast_depo%j.log \n",
    "\n",
    "module restore la_base\n",
    "conda activate blast_life\n",
    "\n",
    "python /home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/bea_all_depolymerase.db/script_files/blast.full_phageboost.py \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "path_70=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "path_db = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/bea_all_depolymerase.db/bead_depo/bea_depo.DB\"\n",
    "path_out = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/blast_out_phageboost_70_80\"\n",
    "\n",
    "n = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Scan the results :\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "path_70=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "path_db = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/bea_all_depolymerase.db/bead_depo/bea_depo.DB\"\n",
    "path_out = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/blast_out_phageboost_70_80\"\n",
    "path_write = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/bea_all_depolymerase.db\"\n",
    "path_work = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher\"\n",
    "\n",
    "\n",
    "outfmt = [\"qseqid\", \"sseqid\", \"pident\", \"length\", \"mismatch\", \"gapopen\", \"qstart\", \"qend\", \"sstart\" ,\"send\", \"evalue\", \"bitscore\"]\n",
    "depo_prot = set()\n",
    "def scan_blast(path_results) :\n",
    "    with open(f\"{path_work}/full_prediction.vsBeaDB.txt\", \"a+\") as outfile :\n",
    "        if os.path.getsize(path_results) >0 :\n",
    "            results = pd.read_csv(f\"{path_results}\", names = outfmt, sep = \"\\t\")\n",
    "            if results.iloc[0][\"bitscore\"] > 20 :\n",
    "                depo_prot.add(results.iloc[0][\"qseqid\"])\n",
    "                outfile.write(f\"{results.iloc[0]['qseqid']}\\t{results.iloc[0]['bitscore']}\\n\")\n",
    "            \n",
    "            \n",
    "paths = [f\"{path_out}/{file}\" for file in os.listdir(path_out)]        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    with ThreadPool(30) as p:\n",
    "        p.map(scan_blast, paths)\n",
    "        \n",
    "    \n",
    "# ****************************************************************************************************\n",
    "#!/bin/bash\n",
    "#BATCH --job-name=blast_depo_scan__\n",
    "#SBATCH --qos=medium \n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=30\n",
    "#SBATCH --mem=10gb \n",
    "#SBATCH --time=2-00:00:00 \n",
    "#SBATCH --output=blast_depo_scan__%j.log \n",
    "\n",
    "module restore la_base\n",
    "conda activate blast_life\n",
    "\n",
    "python /home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/script_file/py_files/blastp_scan.py\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "path_70=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "path_out = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/blast_out_phageboost_70_80\"\n",
    "path_write = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/bea_all_depolymerase.db\"\n",
    "path_work = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher\"\n",
    "\n",
    "path_db = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/15122022_session\"\n",
    "path_phageboost = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "path_store = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/15122022_session/Phrogs_prediction_20042023\"\n",
    "\n",
    "path_fastani=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_similarity/phageboost/fastANI_20102022_out\"\n",
    "path_phages = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_similarity/phageboost/fastANI_20102022\"\n",
    "path_ktype=\"/home/conchae/prediction_depolymerase_tropism\"\n",
    "\n",
    "\n",
    "cluster_df = pd.read_csv(f\"{path_fastani}/clusters_99_80.clean.2004.tsv\", header = 0, sep=\"\\t\")\n",
    "\n",
    "desirable_df = pd.read_csv(f\"{path_db}/Results_III_DataFrame.v3.final.desired_ipr.csv\", sep=\"\\t\", header= 0)\n",
    "desirable_df = desirable_df.drop_duplicates(subset = [\"protein_name\"], keep = \"first\")\n",
    "\n",
    "results_df = pd.read_csv(f\"{path_db}/Results_III_DataFrame.v3.final.csv\", sep=\"\\t\", header= 0)\n",
    "results_df = results_df.drop_duplicates(subset = [\"protein_name\"], keep = \"first\")\n",
    "\n",
    "\n",
    "hits_blast = pd.read_csv(f\"{path_work}/full_prediction.vsBeaDB.txt\", sep = \"\\t\", names = [\"protein\", \"bitscore\"])\n",
    "hits_blast_75 = hits_blast[hits_blast[\"bitscore\"] >=75]\n",
    "hits_blast_100 = hits_blast[hits_blast[\"bitscore\"] >=100]\n",
    "\n",
    "to_decipher = set()\n",
    "inside = set()\n",
    "for _,row in tqdm(hits_blast_75.iterrows()) :\n",
    "    if row[\"protein\"] not in results_df[\"protein_name\"].values :\n",
    "        to_decipher.add(row[\"protein\"])\n",
    "    else :\n",
    "        inside.add(row[\"protein\"])\n",
    "\n",
    "# Check how many passed that wouldnt have :       \n",
    "got_range = set()\n",
    "for _,row in tqdm(desirable_df.iterrows()) :\n",
    "    if row[\"protein_name\"] not in hits_blast_75[\"protein\"].values :\n",
    "        got_range.add(row[\"protein_name\"])\n",
    "\n",
    "dico_done = {}\n",
    "for protein in tqdm(got_range) :\n",
    "    dico_done[protein] = get_seq(protein)\n",
    "\n",
    "ranged_sequences = set()\n",
    "for protein in tqdm(dico_done) :\n",
    "    ranged_sequences.add(dico_done[protein])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Little parameters and generate the new mini batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq(protein) :\n",
    "    strain = protein.split(\"__\")[0]\n",
    "    prophage = protein.split(\"__\")[1]\n",
    "    seq = open(f\"{path_70}/{strain}/tmp/{prophage}/{protein}.fasta\").read().split(\"\\n\")[1]\n",
    "    return seq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_sequences = {}\n",
    "for protein in tqdm(to_decipher) :\n",
    "    dico_sequences[protein] = get_seq(protein)\n",
    "    \n",
    "seq_to_prot = {}\n",
    "for protein in dico_sequences :\n",
    "    if dico_sequences[protein] not in seq_to_prot :\n",
    "        tmp = []\n",
    "        tmp.append(protein)\n",
    "        seq_to_prot[dico_sequences[protein]] = tmp\n",
    "    else :\n",
    "        seq_to_prot[dico_sequences[protein]].append(protein)\n",
    "                \n",
    "with open(f\"{path_db}/new_mini_batch.prophage_raw.json\", \"w\") as outfile:\n",
    "    json.dump(seq_to_prot, outfile)\n",
    "\n",
    "mini_batch_dico = json.load(open(f\"{path_db}/new_mini_batch.prophage_raw.json\"))\n",
    "\n",
    "mini_batch_clean = {}\n",
    "for seq in mini_batch_dico :\n",
    "    if len(seq) <= 1500 :\n",
    "        mini_batch_clean[seq] = mini_batch_dico[seq]\n",
    "        \n",
    "# Write the new_mini batch : \n",
    "with open(f\"{path_db}/minibatch_index.csv\", \"w\") as outfile :\n",
    "    for index,seq in enumerate(list(mini_batch_clean.keys())) :\n",
    "        outfile.write(f\"{index}\\t{seq}\\n\")\n",
    "        \n",
    "# ==> Make prediction !\n",
    "rsync -avzhe ssh \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/15122022_session/minibatch_index.csv \\\n",
    "/media/concha-eloko/Linux/PPT_clean/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Interesting lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Interesting lengths : \n",
    "    \n",
    "lengths = []\n",
    "for seq in seq_to_prot :\n",
    "    lengths.append(len(seq))\n",
    "\n",
    "b_1500 = []\n",
    "for seq in seq_to_prot :\n",
    "    if len(seq) < 1500 :\n",
    "        b_1500.append(len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dico with prophage ID : index new batch : \n",
    "obs_dico = {}\n",
    "for seq,list_pro in tqdm(seq_to_prot.items()):\n",
    "    prophages_obs = set()\n",
    "    for protein in list_pro :\n",
    "        prophage = f\"{'__'.join(protein.split('__')[0:-1])}.fasta\"\n",
    "        print(prophage)\n",
    "        for index, row in cluster_df.iterrows() :\n",
    "            if prophage in row[\"Members\"].split(\",\") :\n",
    "                prophages_obs.add(f\"prophage_{index}\")\n",
    "                break\n",
    "        continue\n",
    "    obs_dico[seq] = prophages_obs             \n",
    "            \n",
    "for key in obs_dico:\n",
    "    obs_dico[key] = list(obs_dico[key])\n",
    "       \n",
    "with open(f\"{path_db}/new_mini_batch.prophage_indices.json\", \"w\") as outfile:\n",
    "    json.dump(obs_dico, outfile)\n",
    "    \n",
    "mini_batch_dico = json.load(open(f\"{path_db}/new_mini_batch.prophage_indices.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the new_mini batch : \n",
    "with open(f\"{path_db}/minibatch_index.fasta\", \"w\") as outfile :\n",
    "    for seq in mini_batch_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(f\"{path_db}/prophages.strain_depo.matrix.csv\", header = 0 , sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(width = 50)\n",
    "\n",
    "pp.pprint(seq_to_prot)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_decipher = set()\n",
    "inside = set()\n",
    "for _,row in tqdm(desirable_df.iterrows()) :\n",
    "    if row[\"protein_name\"] not in hits_blast[\"protein\"].values :\n",
    "        to_decipher.add(row[\"protein_name\"])\n",
    "    else :\n",
    "        inside.add(row[\"protein_name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many different sequences ? :\n",
    "\n",
    "\n",
    "def get_seq(protein) :\n",
    "    strain = protein.split(\"__\")[0]\n",
    "    prophage = protein.split(\"__\")[1]\n",
    "    seq = open(f\"{path_70}/{strain}/tmp/{prophage}/{protein}.fasta\").read().split(\"\\n\")[1]\n",
    "    return seq \n",
    "\n",
    "sequences = set()\n",
    "for protein in to_decipher : \n",
    "    sequences.add(get_seq(protein))\n",
    "    \n",
    "    GCF_900176555.1__phage4__1078\n",
    "\n",
    "to_predict = set()\n",
    "to_check = set()\n",
    "for protein in to_decipher :\n",
    "    strain = protein.split(\"__\")[0]\n",
    "    prophage = protein.split(\"__\")[1]\n",
    "    if os.path.isfile(f\"{path_70}/{strain}/DBsuite_depo_v3/{prophage}/{protein}.suite.hhr\") == False :\n",
    "        to_predict.add(protein)\n",
    "    else :\n",
    "        to_check.add(protein)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
