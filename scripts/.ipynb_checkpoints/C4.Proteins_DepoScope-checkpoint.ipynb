{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decipher the proteins with B helix that were missed by our methods\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO\n",
    "from collections import Counter, defaultdict\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "path_fasta = f\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/15122022_session/part_III_ptA/input_db/all_prophage_proteins.db.fasta\"\n",
    "path_current = f\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "path_model = f\"/home/conchae/PhageDepo_pdb/script_files/esm2_t30_150M_UR50D-finetuned-depolymerase/checkpoint-198\"\n",
    "path_work = f\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "path_task = f\"{path_work}/Rafa_task\"\n",
    "path_labels = f\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_labeling/phageboost/info\"\n",
    "\n",
    "\n",
    "df_labels = pd.read_csv(f\"{path_labels}/prophage_data.clusters_80.phageboost_70.2504.tsv\", sep = \"\\t\" , skiprows=1)\n",
    "df_labels.columns = [\"Prophage_name\",\"KL_type\",\"Infected_ancestor\",\"n_clades\",\"siblings\",\"n_ancestors\",\"n_KL_swaps\",\"old_KL_types\",\"all_old_KL_types\"]\n",
    "\n",
    "df_current = pd.read_csv(f\"{path_current}/DF_Dpo.final.1005.tsv\", sep = \"\\t\", header = 0)\n",
    "fasta_seqs = SeqIO.parse(path_fasta , \"fasta\")\n",
    "\n",
    "dico_seq = defaultdict(list)\n",
    "for record in fasta_seqs:\n",
    "    tmp_prot_name = record.id\n",
    "    sequence = str(record.seq)\n",
    "    dico_seq[sequence].append(tmp_prot_name)\n",
    "        \n",
    "seq_set = dict(zip(df_current[\"seq\"], df_current[\"index\"]))\n",
    "\n",
    "# Load the model : \n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(path_model)\n",
    "model = AutoModelForTokenClassification.from_pretrained(path_model)\n",
    "\n",
    "def model_out(sequence) :\n",
    "    input_ids = tokenizer.encode(sequence, return_tensors='pt', truncation= True, max_length = 1024)\n",
    "    outputs = model(input_ids)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    labels = model.config.id2label\n",
    "    tokens = []\n",
    "    for token_id, token_probs in zip(input_ids[0], probs[0]):\n",
    "        top_label_id = token_probs.argmax().item()\n",
    "        tokens.append(int(labels[top_label_id].split(\"_\")[1]))\n",
    "    return tokens\n",
    "\n",
    "def longest_run_of_ones(tokens):\n",
    "    str_lst = ''.join(map(str, tokens))\n",
    "    runs = list(map(len, str_lst.split('0')))\n",
    "    longest_run = max(runs)\n",
    "    start_pos = runs.index(longest_run)\n",
    "    end_pos = start_pos + longest_run - 1\n",
    "    return longest_run, start_pos, end_pos\n",
    "\n",
    "\n",
    "def beta_helix_assess(sequence):\n",
    "    tokens = model_out(sequence)\n",
    "    longest_run, start_pos, end_pos = longest_run_of_ones(tokens)\n",
    "    if int(longest_run) > 180 :\n",
    "        if sequence in seq_set:\n",
    "            with open(f\"{path_work}/Double_caught_Dpos.LLM.tsv\" , \"a+\") as outfile:\n",
    "                outfile.write(f\"{seq_set[sequence]}\")\n",
    "        else :\n",
    "            pass\n",
    "            #protein_names = dico_seq[sequence]\n",
    "            #with open(f\"{path_work}/Dpo_from_the_dead.tsv\" , \"a+\") as outfile:\n",
    "            #    for protein_name in protein_names:\n",
    "            #        outfile.write(f\"{protein_name}\\t{start_pos}\\t{end_pos}\\t{sequence}\\n\")\n",
    "\n",
    "                   \n",
    "                    \n",
    "if __name__ == '__main__':\n",
    "    results = map(beta_helix_assess, list(dico_seq.keys()))\n",
    "    # If you want to force computation and get a list of results:\n",
    "    results = list(results)\n",
    "    \n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    with ThreadPool(20) as p:\n",
    "        p.map(beta_helix_assess, list(dico_seq.keys()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#BATCH --job-name=Anubis_caught_\n",
    "#SBATCH --qos=short \n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=30\n",
    "#SBATCH --mem=80gb \n",
    "#SBATCH --time=1-00:00:00 \n",
    "#SBATCH --output=Anubis_caught_%j.log \n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate embeddings\n",
    "\n",
    "python /home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/script_files/catch_hands.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "\n",
    "path_fasta = f\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/15122022_session/part_III_ptA/input_db/all_prophage_proteins.db.fasta\"\n",
    "path_current = f\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "path_model = f\"/home/conchae/PhageDepo_pdb/script_files/esm2_t30_150M_UR50D-finetuned-depolymerase/checkpoint-198\"\n",
    "path_work = f\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "\n",
    "df_anubis = pd.read_csv(f\"{path_work}/Dpo_from_the_dead.tsv\", sep = \"\\t\", names = [\"prot_name\", \"start\", \"end\",\"sequence\"])\n",
    "\n",
    "df_seq = df_anubis.drop_duplicates(subset = [\"sequence\"], keep = \"first\")\n",
    "df_seq.to_csv(f\"{path_work}/Anubis_Dpo.index.csv\" , sep = \"\\t\", index = False)\n",
    "\n",
    "df_seq = pd.read_csv(f\"{path_work}/Anubis_Dpo.index.csv\" , sep = \"\\t\", header = 0)\n",
    "\n",
    "with open(f\"{path_work}/Anubis_Dpo.fasta\", \"w\") as outfile :\n",
    "    n = 0\n",
    "    for _,row in df_seq.iterrows() :\n",
    "        outfile.write(f\">{n}\\n{row['sequence']}\\n\")\n",
    "        n += 1 \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "rsync -avzhe ssh \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/Anubis_Dpo.fasta \\\n",
    "/media/concha-eloko/Linux/PPT_clean/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# ESM2 embeddings on the dpo domains of Anubis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "from Bio import SeqIO\n",
    "\n",
    "path_work = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "\n",
    "\n",
    "dico = {str(dpo.seq):dpo.id for dpo in SeqIO.parse(f\"{path_work}/Anubis_Dpo.fasta\" , \"fasta\")}\n",
    "df_info_anubis = pd.read_csv(f\"{path_work}/Anubis_Dpo.index.csv\", sep = \"\\t\", header = 0)\n",
    "\n",
    "with open(f\"{path_work}/anubis_Dpo_domains.multi.fasta\",\"w\") as outfile :\n",
    "    for seq,index in dico.items() :\n",
    "        start = df_info_anubis[df_info_anubis[\"sequence\"] == seq][\"start\"].values[0]\n",
    "        end = df_info_anubis[df_info_anubis[\"sequence\"] == seq][\"end\"].values[0]\n",
    "        domain_aa = seq[start:end]\n",
    "        outfile.write(f\">anubis__{index}\\n{domain_aa}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#BATCH --job-name=ESM_2__\n",
    "#SBATCH --qos=short\n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=40 \n",
    "#SBATCH --mem=100gb \n",
    "#SBATCH --time=1-00:00:00 \n",
    "#SBATCH --output=ESM_2__%j.log \n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate embeddings\n",
    "\n",
    "python /home/conchae/software/esm/scripts/extract.py \\\n",
    "esm2_t33_650M_UR50D \\\n",
    "/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/anubis_Dpo_domains.multi.fasta \\\n",
    "/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/anubis_Dpo_domains.multi.fasta.esm_out \\\n",
    "--repr_layers 33 \\\n",
    "--include mean per_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os \n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "path_esm = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/anubis_Dpo_domains.multi.fasta.esm_out\"\n",
    "\n",
    "embeddings_esm = {}\n",
    "for file in tqdm(os.listdir(path_esm)) :\n",
    "    if os.path.isdir(f\"{path_esm}/{file}\") == True :\n",
    "        for file_2 in os.listdir(f\"{path_esm}/{file}\") :\n",
    "            path_file = f\"{path_esm}/{file}/{file_2}\"\n",
    "        continue\n",
    "    else :\n",
    "        path_file = f\"{path_esm}/{file}\"\n",
    "    #index = file.split(\" \")[0] # VC version\n",
    "    #index = \"__\".join(\"\".join(file.split(\",\")[0]).split(\" \")) # 77 phages version\n",
    "    #print(index)\n",
    "    index = file.split(\".\")[0]\n",
    "    embb = torch.load(f\"{path_file}\")[\"mean_representations\"][33].tolist()\n",
    "    embeddings_esm[index] = embb\n",
    "    \n",
    "#with open(f\"/home/conchae/77_strains_phage_project/vConTACT2_77_phages_04102022/VCs_proteins.esm2.embedding.csv\" , \"w\") as outfile :\n",
    "with open(f\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/anubis.esm2.embedding.csv\" , \"w\") as outfile :\n",
    "    for index in tqdm(embeddings_esm) :\n",
    "        outfile.write(f\"{index},\")\n",
    "        for _,  emb in enumerate(embeddings_esm[index]) :\n",
    "            outfile.write(f\"{emb},\")\n",
    "        outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsync -avzhe ssh \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/anubis.esm2.embedding.csv  \\\n",
    "/media/concha-eloko/Linux/PPT_clean/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Feed the DF_Dpo.final.1005.tsv into DF_Dpo.final.2605.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "from Bio import SeqIO\n",
    "\n",
    "path_work = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "path_labels = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_labeling/phageboost/info\"\n",
    "\n",
    "dico_anubis = {str(dpo.seq):dpo.id for dpo in SeqIO.parse(f\"{path_work}/Anubis_Dpo.fasta\" , \"fasta\")}\n",
    "df_info_anubis = pd.read_csv(f\"{path_work}/Anubis_Dpo.index.csv\", sep = \"\\t\", header = 0)\n",
    "df_labels = pd.read_csv(f\"{path_labels}/prophage_data.clusters_80.phageboost_70.2504.tsv\", sep = \"\\t\", skiprows=1)\n",
    "df_labels.columns = [\"Prophage_name\",\"KL_type\",\"Infected_ancestor\",\"n_clades\",\"siblings\",\"n_ancestors\",\"n_KL_swaps\",\"old_KL_types\",\"all_old_KL_types\"]\n",
    "df_anubis = pd.read_csv(f\"{path_work}/Dpo_from_the_dead.tsv\", sep = \"\\t\", names = [\"prot_name\", \"start\", \"end\",\"sequence\"])\n",
    "\n",
    "df_info = pd.read_csv(f\"{path_work}/DF_Dpo.final.1005.tsv\" , sep = \"\\t\", header =0)\n",
    "\n",
    "\n",
    "df_anubis[\"Prophage_name\"] = df_anubis[\"prot_name\"].apply(lambda x : \"__\".join(x.split(\"__\")[0:-1]) + \".fasta\")\n",
    "df_anubis[\"index\"] = df_anubis[\"sequence\"].apply(lambda x : f\"anubis__{dico_anubis[x]}\")\n",
    "df_anubis[\"Dataset\"] = \"anubis\"\n",
    "\n",
    "\n",
    "df_labels_matters = df_labels[[\"Prophage_name\",\"KL_type\",\"Infected_ancestor\"]]\n",
    "merged = pd.merge(df_anubis ,df_labels_matters, on =\"Prophage_name\" ,left_index=True)\n",
    "merged = merged.drop([\"start\",\"end\"], axis = 1)\n",
    "\n",
    "clean_anubis = merged[[\"Prophage_name\",\"KL_type\",\"Infected_ancestor\",\"prot_name\",\"Dataset\",\"index\",\"sequence\"]]\n",
    "clean_anubis[\"Prophage_name\"] = clean_anubis[\"Prophage_name\"].apply(lambda x : x.split(\".fasta\")[0])\n",
    "clean_anubis.columns = ['Phage', 'KL_type_LCA', 'Infected_ancestor', 'Protein_name', 'Dataset', 'index', 'seq']\n",
    "\n",
    "DF = pd.concat([df_info, clean_anubis] , axis = 0)\n",
    "\n",
    "DF.to_csv(f\"{path_work}/DF_Dpo.final.2605.tsv\" , sep = \"\\t\", header =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The Venn diagram first step : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "\n",
    "path_work = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "path_labels = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_labeling/phageboost/info\"\n",
    "\n",
    "df_caught = pd.read_csv(f\"{path_work}/Double_caught_Dpos.LLM.tsv\", header = None)\n",
    "DF_penultimate = pd.read_csv(f\"{path_work}/DF_Dpo.final.2605.tsv\" , sep = \"\\t\", header = None, index_col = 0)\n",
    "DF_penultimate.columns = ['Phage', 'KL_type_LCA', 'Infected_ancestor', 'Protein_name', 'Dataset', 'index', 'seq']\n",
    "# len = 978"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsync -avzhe ssh \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/DF_Dpo.final.2605.tsv  \\\n",
    "/media/concha-eloko/Linux/PPT_clean/ \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Local "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "\n",
    "path_work = \"/media/concha-eloko/Linux/PPT_clean\"\n",
    "\n",
    "DF_penultimate = pd.read_csv(f\"{path_work}/DF_Dpo.final.2605.tsv\" , sep = \"\\t\", header = None, index_col = 0)\n",
    "DF_penultimate.columns = ['Phage', 'KL_type_LCA', 'Infected_ancestor', 'Protein_name', 'Dataset', 'index', 'seq']\n",
    "# len = 978"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38419"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DF_penultimate[\"Phage\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the phage with the most Dpo :\n",
    "from collections import Counter\n",
    "\n",
    "dico_count = dict(Counter(DF[\"Phage\"]))\n",
    "Dpos = set(value for key,value in dico_count.items())\n",
    "# {1, 2, 3, 4, 5, 6, 7, 11, 13}\n",
    "\n",
    "for phage , dpos in dico_count.items() :\n",
    "    if dpos == 11 :\n",
    "        print(phage)\n",
    "        \n",
    "# GCF_003037395.1__phage28\n",
    "\n",
    "DF[DF[\"Phage\"] == \"GCF_002850635.1__phage1\"]\n",
    "DF[DF[\"Infected_ancestor\"] == \"n2542\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Verify the presence of the Dpo domain with foldseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "path_project = \"/media/concha-eloko/Linux/PPT_clean/ficheros_28032023\"\n",
    "path_pdb = f\"{path_project}/Anubis_out\"\n",
    "path_db = f\"/media/concha-eloko/Linux/depolymerase_building/RefDepo_domains/RefDepo_domains_db\"\n",
    "path_tmp = f\"{path_project}/tmp_anubis\"\n",
    "\n",
    "def seek_beta_helix(path_in) :\n",
    "    dir_out = f\"{path_project}/seekfold_anubis\"\n",
    "    protein_id = path_in.split(\"/\")[-1].split(\".pdb\")[0]\n",
    "    path_out = f\"{dir_out}/{protein_id}.out\"\n",
    "    if os.path.isfile(path_out) == False :\n",
    "        output_frmt = f\"query,target,pident,alnlen,gapopen,qstart,qend,tstart,tend,bits,prob\"\n",
    "        seek = f\"foldseek easy-search {path_in} {path_db} {path_out} {path_tmp} --format-output {output_frmt}\"\n",
    "        #seek = f\"foldseek easy-search {path_in} {path_db} {path_out}.html {path_tmp} --format-mode 3\"\n",
    "        seek_process = subprocess.Popen(seek, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "        press_out, press_err = seek_process.communicate()\n",
    "        print (press_out, press_err)\n",
    "\n",
    "paths = [f\"{path_pdb}/{file}\" for file in os.listdir(f\"{path_pdb}\")]\n",
    "\n",
    "for path in paths :\n",
    "    seek_beta_helix(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jelly-roll presented 0 depolymerases.\n",
      "\n",
      "The alpha/alpha toroid presented 0 depolymerases.\n",
      "\n",
      "The right-handed beta-helix presented 767 depolymerases.\n",
      "\n",
      "The TIM beta/alpha-barrel presented 0 depolymerases.\n",
      "\n",
      "The 6-bladed beta-propeller presented 230 depolymerases.\n",
      "\n",
      "The Flavodoxin-like presented 0 depolymerases.\n",
      "\n",
      "The Alpha/Beta hydrolase fold presented 0 depolymerases.\n",
      "\n",
      "The Other presented 0 depolymerases.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_project = \"/media/concha-eloko/Linux/PPT_clean/ficheros_28032023\"\n",
    "dir_out = f\"{path_project}/seekfold_anubis\"\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "outputs = [f\"{dir_out}/{file}\" for file in os.listdir(dir_out) if file[-3:]==\"out\"]\n",
    "\n",
    "\n",
    "path_info = f\"/media/concha-eloko/Linux/depolymerase_building/depolymerase_fold.csv\"\n",
    "info_df = pd.read_csv(path_info , sep = \"\\t\", header = 0)\n",
    "dico_folds_ppt = {\"jelly-roll\" : [],\n",
    "              \"alpha/alpha toroid\" : [],\n",
    "              \"right-handed beta-helix\" : [] ,\n",
    "              \"TIM beta/alpha-barrel\" : [],\n",
    "              \"6-bladed beta-propeller\" : [] ,\n",
    "              \"Flavodoxin-like\" : [] ,\n",
    "              \"Alpha/Beta hydrolase fold\" : [] ,\n",
    "              \"Other\" : [],\n",
    "             }\n",
    "\n",
    "outputs = [f\"{dir_out}/{file}\" for file in os.listdir(dir_out) if file[-3:]==\"out\"]\n",
    "header_seekfold = [\"query\",\"target\",\"pident\",\"alnlen\",\"gapopen\",\"qstart\",\"qend\",\"tstart\",\"tend\",\"bits\",\"prob\"]\n",
    "depo_results = {}\n",
    "no_fold = []\n",
    "for results in outputs :\n",
    "    results_df = pd.read_csv(f\"{results}\", sep = \"\\t\" , names = header_seekfold)\n",
    "    for _,row in results_df.iterrows() :\n",
    "        fold = info_df[info_df[\"ID\"] == row[\"target\"]][\"X_Group_Name\"].values[0]\n",
    "        if fold != \"jelly-roll\" :\n",
    "            if row[\"prob\"] >= 0.5 :\n",
    "                if row[\"query\"] not in dico_folds_ppt[fold] :\n",
    "                    dico_folds_ppt[fold].append(row[\"query\"])\n",
    "                    break\n",
    "            elif fold == \"right-handed beta-helix\" and row[\"prob\"] >= 0.2 :\n",
    "                if row[\"query\"] not in dico_folds_ppt[fold] :\n",
    "                    dico_folds_ppt[fold].append(row[\"query\"])\n",
    "                    break\n",
    "    else :\n",
    "        no_fold.append(row[\"query\"])\n",
    "                \n",
    "for fold in dico_folds_ppt : \n",
    "    print(f\"The {fold} presented {len(dico_folds_ppt[fold])} depolymerases.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "639"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/Anubis_Dpo.fasta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f5e9288b038f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpath_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_labeling/phageboost/info\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdico_anubis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdpo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdpo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdpo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSeqIO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path_work}/Anubis_Dpo.fasta\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"fasta\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdf_info_anubis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path_work}/Anubis_Dpo.index.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdf_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path_labels}/prophage_data.clusters_80.phageboost_70.2504.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/Bio/SeqIO/__init__.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(handle, format, alphabet)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0miterator_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FormatToIterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0miterator_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mAlignIO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FormatToIterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;31m# Use Bio.AlignIO to read in the alignments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/Bio/SeqIO/FastaIO.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source, alphabet, title2ids)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The alphabet argument is no longer supported\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle2ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitle2ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Fasta\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/Bio/SeqIO/Interfaces.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source, alphabet, mode, fmt)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The alphabet argument is no longer supported\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_close_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# not a path, assume we received a stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/Anubis_Dpo.fasta'"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "from Bio import SeqIO\n",
    "\n",
    "path_work = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "path_labels = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_labeling/phageboost/info\"\n",
    "\n",
    "dico_anubis = {str(dpo.seq):dpo.id for dpo in SeqIO.parse(f\"{path_work}/Anubis_Dpo.fasta\" , \"fasta\")}\n",
    "df_info_anubis = pd.read_csv(f\"{path_work}/Anubis_Dpo.index.csv\", sep = \"\\t\", header = 0)\n",
    "df_labels = pd.read_csv(f\"{path_labels}/prophage_data.clusters_80.phageboost_70.2504.tsv\", sep = \"\\t\", skiprows=1)\n",
    "df_labels.columns = [\"Prophage_name\",\"KL_type\",\"Infected_ancestor\",\"n_clades\",\"siblings\",\"n_ancestors\",\"n_KL_swaps\",\"old_KL_types\",\"all_old_KL_types\"]\n",
    "df_anubis = pd.read_csv(f\"{path_work}/Dpo_from_the_dead.tsv\", sep = \"\\t\", names = [\"prot_name\", \"start\", \"end\",\"sequence\"])\n",
    "\n",
    "df_info = pd.read_csv(f\"{path_work}/DF_Dpo.final.1005.tsv\" , sep = \"\\t\", header =0)\n",
    "\n",
    "\n",
    "df_anubis[\"Prophage_name\"] = df_anubis[\"prot_name\"].apply(lambda x : \"__\".join(x.split(\"__\")[0:-1]) + \".fasta\")\n",
    "df_anubis[\"index\"] = df_anubis[\"sequence\"].apply(lambda x : f\"anubis__{dico_anubis[x]}\")\n",
    "df_anubis[\"Dataset\"] = \"anubis\"\n",
    "\n",
    "\n",
    "df_labels_matters = df_labels[[\"Prophage_name\",\"KL_type\",\"Infected_ancestor\"]]\n",
    "\n",
    "df_anubis[df_anubis[\"index\"] == \"anubis__80\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['80.pdb', '921.pdb', '877.pdb', '1183.pdb', '1405.pdb', '644.pdb', '738.pdb', '1342.pdb', '98.pdb',\n",
      " '838.pdb', '843.pdb', '1320.pdb', '1343.pdb', '59.pdb', '224.pdb', '202.pdb', '1258.pdb',\n",
      " '1149.pdb', '12.pdb', '1398.pdb', '352.pdb', '1171.pdb', '581.pdb', '1030.pdb', '284.pdb',\n",
      " '326.pdb', '1325.pdb', '1168.pdb', '1093.pdb', '397.pdb', '1122.pdb', '321.pdb', '765.pdb',\n",
      " '1182.pdb', '629.pdb', '613.pdb', '518.pdb', '285.pdb', '949.pdb', '1593.pdb', '1153.pdb',\n",
      " '68.pdb', '1220.pdb', '364.pdb', '1316.pdb', '1371.pdb', '1104.pdb', '118.pdb', '881.pdb',\n",
      " '157.pdb', '1194.pdb', '505.pdb', '57.pdb', '1625.pdb', '45.pdb', '960.pdb', '955.pdb', '969.pdb',\n",
      " '988.pdb', '305.pdb', '1062.pdb', '571.pdb', '194.pdb', '1086.pdb', '1378.pdb', '545.pdb',\n",
      " '241.pdb', '658.pdb', '850.pdb', '643.pdb', '354.pdb', '1524.pdb', '852.pdb', '859.pdb', '440.pdb',\n",
      " '1424.pdb', '1139.pdb', '1613.pdb', '288.pdb', '544.pdb', '53.pdb', '54.pdb', '543.pdb', '496.pdb',\n",
      " '856.pdb', '593.pdb', '366.pdb', '1092.pdb', '201.pdb', '1465.pdb', '1602.pdb', '156.pdb',\n",
      " '176.pdb', '569.pdb', '1069.pdb', '301.pdb', '913.pdb', '793.pdb', '1535.pdb', '351.pdb', '81.pdb',\n",
      " '1354.pdb', '158.pdb', '951.pdb', '417.pdb', '1119.pdb', '722.pdb', '692.pdb', '893.pdb',\n",
      " '116.pdb', '1053.pdb', '703.pdb', '154.pdb', '1233.pdb', '902.pdb', '808.pdb', '974.pdb',\n",
      " '1192.pdb', '1551.pdb', '651.pdb', '503.pdb', '391.pdb', '62.pdb', '175.pdb', '1397.pdb',\n",
      " '713.pdb', '888.pdb', '1050.pdb', '694.pdb', '238.pdb', '100.pdb', '143.pdb', '1381.pdb',\n",
      " '993.pdb', '622.pdb', '1088.pdb', '1314.pdb', '591.pdb', '1388.pdb', '117.pdb', '456.pdb',\n",
      " '552.pdb', '318.pdb', '298.pdb', '268.pdb', '641.pdb', '826.pdb', '1126.pdb', '961.pdb', '803.pdb',\n",
      " '1636.pdb', '82.pdb', '1423.pdb', '463.pdb', '1248.pdb', '402.pdb', '22.pdb', '769.pdb', '346.pdb',\n",
      " '1257.pdb', '379.pdb', '945.pdb', '1453.pdb', '1399.pdb', '200.pdb', '1612.pdb', '189.pdb',\n",
      " '774.pdb', '208.pdb', '1517.pdb', '1154.pdb', '327.pdb', '657.pdb', '734.pdb', '1152.pdb',\n",
      " '299.pdb', '1420.pdb', '747.pdb', '729.pdb', '693.pdb', '400.pdb', '1456.pdb', '322.pdb',\n",
      " '800.pdb', '325.pdb', '359.pdb', '23.pdb', '169.pdb', '145.pdb', '1162.pdb', '1653.pdb',\n",
      " '1471.pdb', '203.pdb', '1640.pdb', '19.pdb', '1473.pdb', '1534.pdb', '863.pdb', '534.pdb',\n",
      " '409.pdb', '486.pdb', '277.pdb', '209.pdb', '1129.pdb', '1438.pdb', '1014.pdb', '245.pdb',\n",
      " '1496.pdb', '858.pdb', '474.pdb', '521.pdb', '410.pdb', '918.pdb', '775.pdb', '1545.pdb',\n",
      " '334.pdb', '1627.pdb', '904.pdb', '1647.pdb', '541.pdb', '398.pdb', '1231.pdb', '1006.pdb',\n",
      " '1308.pdb', '735.pdb', '121.pdb', '730.pdb', '1554.pdb', '1618.pdb', '1531.pdb', '667.pdb',\n",
      " '522.pdb', '968.pdb', '319.pdb', '887.pdb', '915.pdb', '578.pdb', '1648.pdb', '1596.pdb',\n",
      " '570.pdb', '137.pdb', '1260.pdb', '551.pdb', '875.pdb', '106.pdb', '587.pdb', '805.pdb',\n",
      " '1227.pdb', '142.pdb', '789.pdb', '212.pdb', '1594.pdb', '148.pdb', '589.pdb', '1544.pdb',\n",
      " '1046.pdb', '1332.pdb', '987.pdb', '30.pdb', '830.pdb', '1276.pdb', '612.pdb', '492.pdb',\n",
      " '355.pdb', '983.pdb', '1555.pdb', '744.pdb', '1291.pdb', '682.pdb', '766.pdb', '1041.pdb',\n",
      " '1078.pdb', '342.pdb', '1275.pdb', '600.pdb', '286.pdb', '1079.pdb', '442.pdb', '1189.pdb',\n",
      " '75.pdb', '710.pdb', '836.pdb', '213.pdb', '1466.pdb', '755.pdb', '1439.pdb', '560.pdb', '312.pdb',\n",
      " '430.pdb', '554.pdb', '511.pdb', '1654.pdb', '49.pdb', '840.pdb', '732.pdb', '661.pdb', '985.pdb',\n",
      " '431.pdb', '1530.pdb', '896.pdb', '350.pdb', '533.pdb', '1598.pdb', '812.pdb', '380.pdb',\n",
      " '792.pdb', '232.pdb', '394.pdb', '1148.pdb', '1181.pdb', '72.pdb', '311.pdb', '1015.pdb',\n",
      " '708.pdb', '784.pdb', '753.pdb', '907.pdb', '300.pdb', '477.pdb', '427.pdb', '84.pdb', '414.pdb',\n",
      " '294.pdb', '1365.pdb', '71.pdb', '395.pdb', '343.pdb', '39.pdb', '278.pdb', '745.pdb', '107.pdb',\n",
      " '1098.pdb', '1204.pdb', '314.pdb', '339.pdb', '296.pdb', '542.pdb', '1161.pdb', '134.pdb',\n",
      " '509.pdb', '1115.pdb', '266.pdb', '155.pdb', '679.pdb', '526.pdb', '167.pdb', '781.pdb',\n",
      " '1000.pdb', '1367.pdb', '471.pdb', '966.pdb', '564.pdb', '847.pdb', '603.pdb', '1081.pdb',\n",
      " '1443.pdb', '2.pdb', '130.pdb', '997.pdb', '597.pdb', '1271.pdb', '385.pdb', '367.pdb', '1452.pdb',\n",
      " '1230.pdb', '837.pdb', '316.pdb', '20.pdb', '1333.pdb', '1377.pdb', '1068.pdb', '872.pdb',\n",
      " '1370.pdb', '702.pdb', '1145.pdb', '1198.pdb', '1213.pdb', '818.pdb', '1319.pdb', '304.pdb',\n",
      " '358.pdb', '452.pdb', '1067.pdb', '940.pdb', '24.pdb', '1538.pdb', '77.pdb', '691.pdb', '715.pdb',\n",
      " '559.pdb', '550.pdb', '1103.pdb', '697.pdb', '1392.pdb', '684.pdb', '760.pdb', '297.pdb',\n",
      " '970.pdb', '1458.pdb', '1606.pdb', '623.pdb', '631.pdb', '248.pdb', '825.pdb', '1278.pdb',\n",
      " '1288.pdb', '749.pdb', '1511.pdb', '903.pdb', '780.pdb', '482.pdb', '436.pdb', '625.pdb',\n",
      " '524.pdb', '1287.pdb', '112.pdb', '1087.pdb', '1623.pdb', '510.pdb', '240.pdb', '1421.pdb',\n",
      " '315.pdb', '239.pdb', '204.pdb', '822.pdb', '537.pdb', '889.pdb', '1011.pdb', '36.pdb', '1566.pdb',\n",
      " '357.pdb', '1536.pdb', '1633.pdb', '1411.pdb', '957.pdb', '1128.pdb', '1639.pdb', '1073.pdb',\n",
      " '361.pdb', '670.pdb', '1284.pdb', '1048.pdb', '3.pdb', '309.pdb', '293.pdb', '97.pdb', '583.pdb',\n",
      " '1480.pdb', '756.pdb', '422.pdb', '938.pdb', '421.pdb', '1509.pdb', '1383.pdb', '972.pdb',\n",
      " '487.pdb', '873.pdb', '1451.pdb', '608.pdb', '52.pdb', '1644.pdb', '1286.pdb', '386.pdb',\n",
      " '1004.pdb', '1058.pdb', '113.pdb', '1638.pdb', '435.pdb', '645.pdb', '1232.pdb', '1226.pdb',\n",
      " '1481.pdb', '1469.pdb', '1358.pdb', '216.pdb', '1346.pdb', '1028.pdb', '1345.pdb', '413.pdb',\n",
      " '133.pdb', '573.pdb', '1010.pdb', '1042.pdb', '508.pdb', '78.pdb', '1590.pdb', '677.pdb',\n",
      " '1520.pdb', '453.pdb', '897.pdb', '699.pdb', '85.pdb', '1574.pdb', '144.pdb', '984.pdb',\n",
      " '1289.pdb', '685.pdb', '791.pdb', '222.pdb', '1117.pdb', '50.pdb', '101.pdb', '1095.pdb',\n",
      " '340.pdb', '917.pdb', '1401.pdb', '1169.pdb', '1324.pdb', '958.pdb', '839.pdb', '783.pdb',\n",
      " '546.pdb', '247.pdb', '310.pdb', '1097.pdb', '1387.pdb', '1246.pdb', '574.pdb', '700.pdb',\n",
      " '586.pdb', '819.pdb', '341.pdb', '1175.pdb', '590.pdb', '669.pdb', '146.pdb', '392.pdb', '673.pdb',\n",
      " '1137.pdb', '253.pdb', '821.pdb', '206.pdb', '1290.pdb', '1060.pdb', '779.pdb', '1074.pdb',\n",
      " '1125.pdb', '577.pdb', '910.pdb', '727.pdb', '184.pdb', '87.pdb', '1542.pdb', '46.pdb', '1595.pdb',\n",
      " '689.pdb', '1256.pdb', '557.pdb', '890.pdb', '48.pdb', '56.pdb', '1219.pdb', '820.pdb', '14.pdb',\n",
      " '1299.pdb', '978.pdb', '602.pdb', '17.pdb', '246.pdb', '1483.pdb', '38.pdb', '621.pdb', '1174.pdb',\n",
      " '163.pdb', '18.pdb', '347.pdb', '466.pdb', '895.pdb', '217.pdb', '853.pdb', '627.pdb', '139.pdb',\n",
      " '882.pdb', '408.pdb', '609.pdb', '173.pdb', '719.pdb', '776.pdb', '1292.pdb', '1172.pdb', '41.pdb',\n",
      " '1552.pdb', '855.pdb', '423.pdb', '1268.pdb', '1650.pdb', '1652.pdb', '40.pdb', '372.pdb',\n",
      " '1322.pdb', '849.pdb', '454.pdb', '930.pdb', '192.pdb', '1070.pdb', '1235.pdb', '790.pdb',\n",
      " '1261.pdb', '244.pdb', '963.pdb', '1510.pdb', '1547.pdb', '416.pdb', '754.pdb', '478.pdb',\n",
      " '1277.pdb', '1461.pdb', '147.pdb', '1270.pdb', '483.pdb', '664.pdb', '520.pdb', '35.pdb',\n",
      " '1486.pdb', '272.pdb', '1018.pdb', '726.pdb', '716.pdb', '539.pdb', '135.pdb', '465.pdb',\n",
      " '1229.pdb', '480.pdb', '720.pdb', '28.pdb', '1094.pdb', '1579.pdb', '1615.pdb', '1435.pdb',\n",
      " '861.pdb', '93.pdb', '806.pdb', '1029.pdb', '1025.pdb', '1472.pdb', '70.pdb', '1158.pdb',\n",
      " '1364.pdb', '225.pdb']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(width = 100, compact = True)\n",
    "pp.pprint(no_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
