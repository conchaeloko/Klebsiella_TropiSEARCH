{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make blast\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *******************************************************************************************************************************************\n",
    "# 2. The Blastp analysis : preparation step \n",
    "# *******************************************************************************************************************************************\n",
    "\n",
    "    # The makeblastdb command : \n",
    "makeblastdb -in /home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/bea_all_depolymerase.db/bead_depo/bea_depo.DB.fasta \\\n",
    "-dbtype prot  \\\n",
    "-title depolymerase_db \\\n",
    "-out /home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/bea_all_depolymerase.db/bead_depo/bea_depo.DB\n",
    "\n",
    "\n",
    "    # The command for the multifasta faa for the congruent and the loners :\n",
    "import os\n",
    "import subprocess\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "path_70=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "path_db = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/bea_all_depolymerase.db/bead_depo/bea_depo.DB\"\n",
    "path_out = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/blast_out_phageboost_70_80\"\n",
    "\n",
    "path_fasta = [f\"{path_70}/{strain}/tmp/{phage}/{fasta}\" \n",
    "              for strain in os.listdir(f\"{path_70}\") \n",
    "              for phage in os.listdir(f\"{path_70}/{strain}/tmp\") \n",
    "              for fasta in os.listdir(f\"{path_70}/{strain}/tmp/{phage}\")]\n",
    "\n",
    "def blast_bea(path) :\n",
    "    #path_out = \"/\".join(path.split(\"/\")[0:-1])\n",
    "    file_name = path.split(\"/\")[-1].split(\".fasta\")[0]\n",
    "    blastp = f\"blastp -query {path}  -db {path_db} -out {path_out}/{file_name}.out -outfmt 6\"\n",
    "    sub_blastp = subprocess.Popen(blastp, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    press_out, press_err = sub_blastp.communicate()\n",
    "    print(press_out)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    with ThreadPool(10) as p:\n",
    "        p.map(blast_bea, path_fasta)\n",
    "        \n",
    "        \n",
    "def show_result(protein) :\n",
    "    outfmt = [\"qseqid\", \"sseqid\", \"pident\", \"length\", \"mismatch\", \"gapopen\", \"qstart\", \"qend\", \"sstart\" ,\"send\", \"evalue\", \"bitscore\"]\n",
    "    strain = protein.split(\"__\")[0]\n",
    "    prophage = protein.split(\"__\")[1]\n",
    "    results = pd.read_csv(f\"{path_out}/{protein}.out\", names = outfmt, sep = \"\\t\")\n",
    "    return results\n",
    "        \n",
    "        \n",
    "\n",
    "# ****************************************************************************************************\n",
    "#!/bin/bash\n",
    "#BATCH --job-name=blast_depo\n",
    "#SBATCH --qos=medium \n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=40\n",
    "#SBATCH --mem=50gb \n",
    "#SBATCH --time=2-00:00:00 \n",
    "#SBATCH --output=blast_depo%j.log \n",
    "\n",
    "module restore la_base\n",
    "conda activate blast_life\n",
    "\n",
    "python /home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/bea_all_depolymerase.db/script_files/blast.full_phageboost.py \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Scan the results :\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "path_70=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "path_db = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/bea_all_depolymerase.db/bead_depo/bea_depo.DB\"\n",
    "path_out = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/blast_out_phageboost_70_80\"\n",
    "path_write = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/bea_all_depolymerase.db\"\n",
    "path_work = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher\"\n",
    "\n",
    "\n",
    "outfmt = [\"qseqid\", \"sseqid\", \"pident\", \"length\", \"mismatch\", \"gapopen\", \"qstart\", \"qend\", \"sstart\" ,\"send\", \"evalue\", \"bitscore\"]\n",
    "depo_prot = set()\n",
    "def scan_blast(path_results) :\n",
    "    with open(f\"{path_work}/full_prediction.vsBeaDB.txt\", \"a+\") as outfile :\n",
    "        if os.path.getsize(path_results) >0 :\n",
    "            results = pd.read_csv(f\"{path_results}\", names = outfmt, sep = \"\\t\")\n",
    "            if results.iloc[0][\"bitscore\"] > 20 :\n",
    "                depo_prot.add(results.iloc[0][\"qseqid\"])\n",
    "                outfile.write(f\"{results.iloc[0]['qseqid']}\\t{results.iloc[0]['bitscore']}\\n\")\n",
    "            \n",
    "            \n",
    "paths = [f\"{path_out}/{file}\" for file in os.listdir(path_out)]        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    with ThreadPool(30) as p:\n",
    "        p.map(scan_blast, paths)\n",
    "        \n",
    "    \n",
    "# ****************************************************************************************************\n",
    "#!/bin/bash\n",
    "#BATCH --job-name=blast_depo_scan__\n",
    "#SBATCH --qos=medium \n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=30\n",
    "#SBATCH --mem=10gb \n",
    "#SBATCH --time=2-00:00:00 \n",
    "#SBATCH --output=blast_depo_scan__%j.log \n",
    "\n",
    "module restore la_base\n",
    "conda activate blast_life\n",
    "\n",
    "python /home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/script_file/py_files/blastp_scan.py\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "path_70=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "path_out = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/blast_out_phageboost_70_80\"\n",
    "path_write = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/bea_all_depolymerase.db\"\n",
    "path_work = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher\"\n",
    "\n",
    "path_db = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/15122022_session\"\n",
    "path_phageboost = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "path_store = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/15122022_session/Phrogs_prediction_20042023\"\n",
    "\n",
    "path_fastani=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_similarity/phageboost/fastANI_20102022_out\"\n",
    "path_phages = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_similarity/phageboost/fastANI_20102022\"\n",
    "path_ktype=\"/home/conchae/prediction_depolymerase_tropism\"\n",
    "\n",
    "\n",
    "cluster_df = pd.read_csv(f\"{path_fastani}/clusters_99_80.clean.2004.tsv\", header = 0, sep=\"\\t\")\n",
    "\n",
    "desirable_df = pd.read_csv(f\"{path_db}/Results_III_DataFrame.v3.final.desired_ipr.csv\", sep=\"\\t\", header= 0)\n",
    "desirable_df = desirable_df.drop_duplicates(subset = [\"index_seq\"], keep = \"first\")\n",
    "\n",
    "results_df = pd.read_csv(f\"{path_db}/Results_III_DataFrame.v3.final.csv\", sep=\"\\t\", header= 0)\n",
    "results_df = results_df.drop_duplicates(subset = [\"protein_name\"], keep = \"first\")\n",
    "\n",
    "\n",
    "hits_blast = pd.read_csv(f\"{path_work}/full_prediction.vsBeaDB.txt\", sep = \"\\t\", names = [\"protein\", \"bitscore\"])\n",
    "hits_blast_75 = hits_blast[hits_blast[\"bitscore\"] >=75]\n",
    "#hits_blast_100 = hits_blast[hits_blast[\"bitscore\"] >=100]\n",
    "\n",
    "to_decipher = set()\n",
    "inside = set()\n",
    "for _,row in tqdm(hits_blast_75.iterrows()) :\n",
    "    if row[\"protein\"] not in results_df[\"protein_name\"].values :\n",
    "        to_decipher.add(row[\"protein\"])\n",
    "    else :\n",
    "        inside.add(row[\"protein\"])\n",
    "\n",
    "# Check how many passed that wouldnt have :       \n",
    "got_range = set()\n",
    "for _,row in tqdm(desirable_df.iterrows()) :\n",
    "    if row[\"protein_name\"] not in hits_blast_75[\"protein\"].values :\n",
    "        got_range.add(row[\"protein_name\"])\n",
    "\n",
    "dico_done = {}\n",
    "for protein in tqdm(got_range) :\n",
    "    dico_done[protein] = get_seq(protein)\n",
    "\n",
    "ranged_sequences = set()\n",
    "for protein in tqdm(dico_sequences) :\n",
    "    ranged_sequences.add(dico_sequences[protein])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Little parameters and generate the new mini batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq(protein) :\n",
    "    strain = protein.split(\"__\")[0]\n",
    "    prophage = protein.split(\"__\")[1]\n",
    "    seq = open(f\"{path_70}/{strain}/tmp/{prophage}/{protein}.fasta\").read().split(\"\\n\")[1]\n",
    "    return seq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_sequences_decipher = {}\n",
    "for protein in tqdm(to_decipher) :\n",
    "    dico_sequences_decipher[protein] = get_seq(protein)\n",
    "\n",
    "decipher_sequences = set()\n",
    "for protein in tqdm(dico_sequences_decipher) :\n",
    "    decipher_sequences.add(dico_sequences_decipher[protein])\n",
    "    \n",
    "\n",
    "good_L_decipher = set()\n",
    "for protein in tqdm(decipher_sequences) :\n",
    "    if len(protein) < 1501 :\n",
    "        good_L_decipher.add(protein)\n",
    "        \n",
    "dico_sequences_inside = {}\n",
    "for protein in tqdm(inside) :\n",
    "    dico_sequences_inside[protein] = get_seq(protein)\n",
    "\n",
    "inside_sequences = set()\n",
    "for protein in tqdm(dico_sequences_inside) :\n",
    "    inside_sequences.add(dico_sequences_inside[protein])\n",
    "    \n",
    "\n",
    "good_L_decipher = set()\n",
    "for protein in tqdm(decipher_sequences) :\n",
    "    if len(protein) < 1501 :\n",
    "        good_L_decipher.add(protein)\n",
    "    \n",
    "#**************************************************\n",
    "    \n",
    "seq_to_prot = {}\n",
    "for protein in dico_sequences :\n",
    "    if dico_sequences[protein] not in seq_to_prot :\n",
    "        tmp = []\n",
    "        tmp.append(protein)\n",
    "        seq_to_prot[dico_sequences[protein]] = tmp\n",
    "    else :\n",
    "        seq_to_prot[dico_sequences[protein]].append(protein)\n",
    "                \n",
    "with open(f\"{path_db}/new_mini_batch.prophage_raw.json\", \"w\") as outfile:\n",
    "    json.dump(seq_to_prot, outfile)\n",
    "\n",
    "mini_batch_dico = json.load(open(f\"{path_db}/new_mini_batch.prophage_raw.json\"))\n",
    "\n",
    "mini_batch_clean = {}\n",
    "for seq in mini_batch_dico :\n",
    "    if len(seq) <= 1500 :\n",
    "        mini_batch_clean[seq] = mini_batch_dico[seq]\n",
    "        \n",
    "# Write the new_mini batch : \n",
    "with open(f\"{path_db}/minibatch_index.csv\", \"w\") as outfile :\n",
    "    for index,seq in enumerate(list(mini_batch_clean.keys())) :\n",
    "        outfile.write(f\"{index}\\t{seq}\\n\")\n",
    "        \n",
    "# ==> Make prediction !\n",
    "rsync -avzhe ssh \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/15122022_session/minibatch_index.csv \\\n",
    "/media/concha-eloko/Linux/PPT_clean/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Interesting lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interesting lengths : \n",
    "    \n",
    "lengths = []\n",
    "for seq in seq_to_prot :\n",
    "    lengths.append(len(seq))\n",
    "\n",
    "b_1500 = []\n",
    "for seq in seq_to_prot :\n",
    "    if len(seq) < 1500 :\n",
    "        b_1500.append(len(seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Make matrix :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json \n",
    "\n",
    "path_70=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "path_out = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/blast_out_phageboost_70_80\"\n",
    "path_write = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/bea_all_depolymerase.db\"\n",
    "path_work = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher\"\n",
    "\n",
    "path_db = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/15122022_session\"\n",
    "path_phageboost = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "path_store = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/15122022_session/Phrogs_prediction_20042023\"\n",
    "\n",
    "path_fastani=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_similarity/phageboost/fastANI_20102022_out\"\n",
    "path_phages = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_similarity/phageboost/fastANI_20102022\"\n",
    "path_ktype=\"/home/conchae/prediction_depolymerase_tropism\"\n",
    "\n",
    "mini_batch_dico = json.load(open(f\"{path_db}/new_mini_batch.prophage_raw.json\"))\n",
    "cluster_df = pd.read_csv(f\"{path_fastani}/clusters_99_80.clean.2004.v2.tsv\", header = 0, sep=\"\\t\")\n",
    "df_minibatch = pd.read_csv(f\"{path_db}/minibatch_index.csv\", sep = \"\\t\", names = [\"id\", \"sequence\"])\n",
    "\n",
    "mini_batch_clean = {}\n",
    "for _, row in tqdm(df_minibatch.iterrows()) :\n",
    "    prophage_list = [f\"{'__'.join(phage.split('__')[0:2])}\" for phage in mini_batch_dico[row[\"sequence\"]]]\n",
    "    for prophage_raw in prophage_list :\n",
    "        for prophage_indice, cluster in cluster_df.iterrows() :\n",
    "            if prophage_raw in [member.split(\".fasta\")[0] for member in cluster[\"Members\"].split(\",\")] :\n",
    "                prophage_fam = f\"prophage_{prophage_indice}\"\n",
    "                minibatch_name = f\"minibatch_depo__{row['id']}\"\n",
    "                if minibatch_name not in mini_batch_clean :\n",
    "                    tmp_set = set()\n",
    "                    tmp_set.add(prophage_fam)\n",
    "                    mini_batch_clean[minibatch_name] = tmp_set\n",
    "                else :\n",
    "                    mini_batch_clean[minibatch_name].add(prophage_fam)\n",
    "                break\n",
    "        continue\n",
    "\n",
    "for key in mini_batch_clean:\n",
    "    mini_batch_clean[key] = list(mini_batch_clean[key])\n",
    "\n",
    "with open(f\"{path_db}/minibatchdepo_prophageFAM.dico.json\", \"w\") as outfile:\n",
    "    json.dump(mini_batch_clean, outfile)\n",
    "\n",
    "# ************************************************\n",
    "#!/bin/bash\n",
    "#BATCH --job-name=write_dicomini__\n",
    "#SBATCH --qos=short\n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=5 \n",
    "#SBATCH --mem=5gb \n",
    "#SBATCH --time=1-00:00:00 \n",
    "#SBATCH --output=write_dicomini__%j.log \n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate ScaleAP\n",
    "\n",
    "python /home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/15122022_session/script_files/part_III/minibatch_dico.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
