{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=esmfold_ppt_\n",
    "#SBATCH --partition=gpu\n",
    "#SBATCH --time=7:00:00\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH --mem=40G\n",
    "#SBATCH --output=ppt_out_%j.out\n",
    "#SBATCH --error=ppt_out_err__%j.err\n",
    "\n",
    "\n",
    "source /opt/sci-soft/software/Anaconda3/5.3.0/etc/profile.d/conda.sh\n",
    "module load Anaconda3/5.3.0\n",
    "conda create -n transformers_2\n",
    "conda activate transformers\n",
    "\n",
    "python /home/rsanjuan/Robby/test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source /clinicfs/userhomes/home/rsanjuan/.bashrc\n",
    "source home/rsanjuan/.bashrc\n",
    "source home/rsanjuan/.bashrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, EsmForProteinFolding\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_memory_allocated=12884901888'\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "from transformers.models.esm.openfold_utils.protein import to_pdb, Protein as OFProtein\n",
    "from transformers.models.esm.openfold_utils.feats import atom14_to_atom37\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esmfold_v1\")\n",
    "model = EsmForProteinFolding.from_pretrained(\"facebook/esmfold_v1\")\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = model.cuda()\n",
    "model.esm = model.esm.half()\n",
    "\n",
    "model.trunk.set_chunk_size(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_sequences(sequences, fasta_or_csv) :\n",
    "    \"\"\"\n",
    "    The function takes as an input a either a multifasta file or a dataframe with two columns.\n",
    "    If the input is a dataframe, the shape would consist of two columns with :\n",
    "    - 'id', which corresponds to the protein name\n",
    "    - 'sequence', which corresponds to the aa sequence\n",
    "    The function returns a list of tuples (a,b) with a as the id and b as the tokenized inputs\n",
    "    \"\"\"\n",
    "    starting = 0\n",
    "    if fasta_or_csv == \"csv\" :\n",
    "        dico_seq = {}\n",
    "        for i, row in sequences.iterrows():\n",
    "            if row[\"id\"] >= starting and row[\"id\"] not in not_processed :\n",
    "                dico_seq[row[\"id\"]] =  row[\"sequence\"]\n",
    "    elif fasta_or_csv == \"fasta\" :\n",
    "        from Bio import SeqIO\n",
    "        dico_seq = {\"__\".join(record.description.split(\",\")) : str(record.seq) for record in SeqIO.parse(sequences, \"fasta\")}\n",
    "    tokenized_sequences = []\n",
    "    for idd in dico_seq :\n",
    "        if int(idd) >= starting :\n",
    "            tokenized_input = tokenizer(dico_seq[idd], return_tensors=\"pt\", add_special_tokens=False)['input_ids']\n",
    "            a = (idd , tokenized_input)\n",
    "            tokenized_sequences.append(a)\n",
    "    return tokenized_sequences\n",
    "\n",
    "def convert_outputs_to_pdb(outputs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    final_atom_positions = atom14_to_atom37(outputs[\"positions\"][-1], outputs)\n",
    "    outputs = {k: v.to(device).numpy() for k, v in outputs.items()}\n",
    "    final_atom_positions = final_atom_positions.to(device).numpy()\n",
    "    final_atom_mask = outputs[\"atom37_atom_exists\"]\n",
    "    pdbs = []\n",
    "    for i in range(outputs[\"aatype\"].shape[0]):\n",
    "        aa = outputs[\"aatype\"][i]\n",
    "        pred_pos = final_atom_positions[i]\n",
    "        mask = final_atom_mask[i]\n",
    "        resid = outputs[\"residue_index\"][i] + 1\n",
    "        pred = OFProtein(\n",
    "            aatype=aa,\n",
    "            atom_positions=pred_pos,\n",
    "            atom_mask=mask,\n",
    "            residue_index=resid,\n",
    "            b_factors=outputs[\"plddt\"][i],\n",
    "            chain_index=outputs[\"chain_index\"][i] if \"chain_index\" in outputs else None,\n",
    "        )\n",
    "        pdbs.append(to_pdb(pred))\n",
    "    return pdbs\n",
    "\n",
    "def esmfold_prediction(tokenized_sequences , path_out) :\n",
    "    \"\"\"\n",
    "    The function takes as an input :\n",
    "    - 'tokenized_sequences', the output of the function tokenize_fasta\n",
    "    - 'path_out', the path of the directory when the pdb files are to be written\n",
    "    The function generates the pdb files in the path_out\n",
    "    \"\"\"\n",
    "    for protein in tokenized_sequences :\n",
    "        pdb_files = []\n",
    "        output = \"\"\n",
    "        try :\n",
    "            with torch.no_grad():\n",
    "                output = model(protein[1].cuda())\n",
    "            pdb_txt = convert_outputs_to_pdb(output)\n",
    "            with open(f\"{path_out}/{protein[0]}.pdb\" ,\"w\") as outfile :\n",
    "                outfile.write(pdb_txt[0])\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        except Exception as e :\n",
    "            with open(\"/home/rsanjuan/Robby/anubis.log\" , \"a+\") as outfile :\n",
    "                outfile.write(f\"{protein[0]} ; {e}\\n\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"/home/rsanjuan/Robby/PhageDEPOdetection/data\"\n",
    "eg_tokenized = tokenized_sequences( f\"{path_data}/anubis.indices.fasta\" , \"fasta\")\n",
    "esmfold_prediction(eg_tokenized, \"/home/rsanjuan/Robby/phagedepo_out\" )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
