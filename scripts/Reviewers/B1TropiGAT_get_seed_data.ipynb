{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3db8b5-c138-4582-89a5-b172d577f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch geometric modules\n",
    "from torch_geometric.data import HeteroData, DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import to_hetero , HeteroConv , GATv2Conv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "# Torch modules\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# SKlearn modules\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder , label_binarize , OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score , matthews_corrcoef\n",
    "\n",
    "# Ground modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import random\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import logging\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import joblib\n",
    "\n",
    "# TropiGAT modules\n",
    "import TropiGAT_graph\n",
    "import TropiGAT_models\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# *****************************************************************************\n",
    "# Load the Dataframes :\n",
    "path_work = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "DF_info = pd.read_csv(f\"{path_work}/train_nn/TropiGATv2.final_df_v2.tsv\", sep = \"\\t\" ,  header = 0)\n",
    "\n",
    "DF_info = DF_info.drop_duplicates(subset = [\"Protein_name\"])\n",
    "\n",
    "df_prophages = DF_info.drop_duplicates(subset = [\"Phage\"], keep = \"first\")\n",
    "dico_prophage_info = {row[\"Phage\"] : {\"prophage_strain\" : row[\"prophage_id\"] , \"ancestor\" : row[\"Infected_ancestor\"]} for _,row in df_prophages.iterrows()}\n",
    "\n",
    "def get_filtered_prophages(prophage) :\n",
    "    combinations = []\n",
    "    to_exclude = set()\n",
    "    to_keep = set()\n",
    "    to_keep.add(prophage)\n",
    "    df_prophage_group = DF_info[(DF_info[\"prophage_id\"] == dico_prophage_info[prophage][\"prophage_strain\"]) & (DF_info[\"Infected_ancestor\"] == dico_prophage_info[prophage][\"ancestor\"])]\n",
    "    if len(df_prophage_group) == 1 :\n",
    "        pass\n",
    "    else :\n",
    "        depo_set = set(df_prophage_group[df_prophage_group[\"Phage\"] == prophage][\"domain_seq\"].values)\n",
    "        for prophage_tmp in df_prophage_group[\"Phage\"].unique().tolist() :\n",
    "            if prophage_tmp != prophage :\n",
    "                tmp_depo_set = set(df_prophage_group[df_prophage_group[\"Phage\"] == prophage_tmp][\"domain_seq\"].values)\n",
    "                if depo_set == tmp_depo_set :\n",
    "                    to_exclude.add(prophage_tmp)\n",
    "                else :\n",
    "                    if tmp_depo_set not in combinations :\n",
    "                        to_keep.add(prophage_tmp)\n",
    "                        combinations.append(tmp_depo_set)\n",
    "                    else :\n",
    "                        to_exclude.add(prophage_tmp)\n",
    "    return df_prophage_group , to_exclude , to_keep\n",
    "\n",
    "good_prophages = set()\n",
    "excluded_prophages = set()\n",
    "\n",
    "for prophage, info_prophage in tqdm(dico_prophage_info.items()) :\n",
    "    if prophage not in excluded_prophages and prophage not in good_prophages:\n",
    "        _, excluded_members , kept_members = get_filtered_prophages(prophage)\n",
    "        good_prophages.update(kept_members)\n",
    "        excluded_prophages.update(excluded_members)\n",
    "\n",
    "DF_info_lvl_0_filtered = DF_info[DF_info[\"Phage\"].isin(good_prophages)]\n",
    "DF_info_lvl_0_final = DF_info_lvl_0_filtered[~DF_info_lvl_0_filtered[\"KL_type_LCA\"].str.contains(\"\\\\|\")]\n",
    "\n",
    "DF_info_lvl_0 = DF_info_lvl_0_final.copy()\n",
    "\n",
    "\n",
    "\n",
    "# Log file :\n",
    "path_ensemble = f\"{path_work}/train_nn/ensemble_0702\"\n",
    "\n",
    "df_prophages = DF_info_lvl_0.drop_duplicates(subset = [\"Phage\"])\n",
    "dico_prophage_count = dict(Counter(df_prophages[\"KL_type_LCA\"]))\n",
    "\n",
    "KLtypes = [kltype for kltype in dico_prophage_count if dico_prophage_count[kltype] >= 20]\n",
    "\n",
    "# *****************************************************************************\n",
    "# Make graphs :\n",
    "graph_baseline , dico_prophage_kltype_associated = TropiGAT_graph.build_graph_baseline(DF_info_lvl_0)\n",
    "\n",
    "# *****************************************************************************\n",
    "@torch.no_grad()\n",
    "def evaluate_seed(model, graph, mask):\n",
    "    model.eval()\n",
    "    out_eval = model(graph)\n",
    "    pred = out_eval[mask]\n",
    "    pred = torch.sigmoid(pred)\n",
    "    labels = graph[\"B1\"].y[mask]\n",
    "    #print(pred, labels)\n",
    "    dico_pred = {\"predictions\" : pred.tolist(), \"labels\" : labels.tolist()}\n",
    "    #print(dico_pred)\n",
    "    return dico_pred\n",
    "\n",
    "\n",
    "def get_evalpred_dico(KL_type) :\n",
    "    dico_predictions_seeds = {}\n",
    "    with open(f\"{path_work}/train_nn/best_threshold.tsv\" , \"w\") as log_outfile :\n",
    "        for seed in range(1,6) :\n",
    "            dico_tmp_seed = {}\n",
    "            n_prophage = dico_prophage_count[KL_type]\n",
    "            graph_data_kltype = TropiGAT_graph.build_graph_masking_v2(graph_baseline , dico_prophage_kltype_associated, DF_info_lvl_0, KL_type, 5, 0.7, 0.2, 0.1, seed = seed)\n",
    "            if n_prophage <= 125 :\n",
    "                model = TropiGAT_models.TropiGAT_small_module(hidden_channels = 1280, heads = 1)\n",
    "                n = \"small\"\n",
    "            else :\n",
    "                model = TropiGAT_models.TropiGAT_big_module(hidden_channels = 1280, heads = 1)\n",
    "                n = \"big\"\n",
    "            model.load_state_dict(torch.load(f\"{path_ensemble}/{KL_type}__{seed}.TropiGATv2.0702.pt\"))\n",
    "            #print(model)\n",
    "            dico_seed = evaluate_seed(model, graph_data_kltype,graph_data_kltype[\"B1\"].eval_mask)\n",
    "            dico_predictions_seeds[seed] = dico_seed\n",
    "    return dico_predictions_seeds\n",
    "\n",
    "dico_full_seed = {}\n",
    "\n",
    "for kltype in KLtypes :\n",
    "    dico_predictions_seeds = get_evalpred_dico(kltype)\n",
    "    dico_full_seed[kltype] = dico_predictions_seeds\n",
    "\n",
    "\n",
    "joblib.dump(dico_full_seed, f'{path_work}/dico_full_seed.joblib')\n",
    "\n",
    "\n",
    "print(dico_full_seed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch_geometric]",
   "language": "python",
   "name": "conda-env-torch_geometric-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
