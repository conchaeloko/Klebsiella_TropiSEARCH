{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272229d1-b76b-4fa2-b2ed-7228b4abd423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from collections import Counter\n",
    "import logging\n",
    "import subprocess\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, roc_auc_score, matthews_corrcoef\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Constants\n",
    "PATH_WORK = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/Seqbased_model\"\n",
    "PATH_MODELS = f\"{PATH_WORK}/RF_1309_models\"\n",
    "PATH_TESTING = f\"{PATH_WORK}/RF_1309_data\"\n",
    "PATH_MULTI_FASTA = f\"{PATH_WORK}/Dpo_domains.2912.multi.fasta\"\n",
    "PATH_TMP_CDHIT = f\"{PATH_WORK}/cdhit_clusters_2912\"\n",
    "\n",
    "os.makedirs(PATH_MODELS, exist_ok=True)\n",
    "os.makedirs(PATH_TESTING, exist_ok=True)\n",
    "\n",
    "def load_data():\n",
    "    df_info = pd.read_csv(f\"{PATH_WORK}/TropiGATv2.final_df_v2.tsv\", sep=\"\\t\", header=0)\n",
    "    df_prophages = df_info.drop_duplicates(subset=[\"Phage\"], keep=\"first\")\n",
    "    dico_prophage_info = {row[\"Phage\"]: {\"prophage_strain\": row[\"prophage_id\"], \"ancestor\": row[\"Infected_ancestor\"]} for _, row in df_prophages.iterrows()}\n",
    "    return df_info, dico_prophage_info\n",
    "\n",
    "def get_filtered_prophages(prophage, df_info, dico_prophage_info):\n",
    "    to_exclude = set()\n",
    "    to_keep = {prophage}\n",
    "    df_prophage_group = df_info[(df_info[\"prophage_id\"] == dico_prophage_info[prophage][\"prophage_strain\"]) & \n",
    "                                (df_info[\"Infected_ancestor\"] == dico_prophage_info[prophage][\"ancestor\"])]\n",
    "    \n",
    "    if len(df_prophage_group) > 1:\n",
    "        depo_set = set(df_prophage_group[df_prophage_group[\"Phage\"] == prophage][\"domain_seq\"].values)\n",
    "        combinations = [depo_set]\n",
    "        \n",
    "        for prophage_tmp in df_prophage_group[\"Phage\"].unique():\n",
    "            if prophage_tmp != prophage:\n",
    "                tmp_depo_set = set(df_prophage_group[df_prophage_group[\"Phage\"] == prophage_tmp][\"domain_seq\"].values)\n",
    "                if tmp_depo_set in combinations:\n",
    "                    to_exclude.add(prophage_tmp)\n",
    "                else:\n",
    "                    to_keep.add(prophage_tmp)\n",
    "                    combinations.append(tmp_depo_set)\n",
    "    \n",
    "    return df_prophage_group, to_exclude, to_keep\n",
    "\n",
    "def filter_prophages(df_info, dico_prophage_info):\n",
    "    good_prophages = set()\n",
    "    excluded_prophages = set()\n",
    "\n",
    "    for prophage in tqdm(dico_prophage_info.keys()):\n",
    "        if prophage not in excluded_prophages and prophage not in good_prophages:\n",
    "            _, excluded_members, kept_members = get_filtered_prophages(prophage, df_info, dico_prophage_info)\n",
    "            good_prophages.update(kept_members)\n",
    "            excluded_prophages.update(excluded_members)\n",
    "\n",
    "    df_info_filtered = df_info[df_info[\"Phage\"].isin(good_prophages)]\n",
    "    return df_info_filtered[~df_info_filtered[\"KL_type_LCA\"].str.contains(\"\\\\|\")]\n",
    "\n",
    "def ultrafilter_prophages(df_info):\n",
    "    duplicate_prophage = []\n",
    "    for kltype in df_info[\"KL_type_LCA\"].unique():\n",
    "        df_kl = df_info[df_info[\"KL_type_LCA\"] == kltype][[\"Phage\", \"domain_seq\"]]\n",
    "        set_sets_depo = []\n",
    "        for _, group in df_kl.groupby(\"Phage\"):\n",
    "            set_depo = frozenset(group[\"domain_seq\"].values)\n",
    "            if set_depo in set_sets_depo:\n",
    "                duplicate_prophage.extend(group[\"Phage\"])\n",
    "            else:\n",
    "                set_sets_depo.append(set_depo)\n",
    "    \n",
    "    return df_info[~df_info[\"Phage\"].isin(duplicate_prophage)]\n",
    "\n",
    "def make_cdhit_cluster(threshold):\n",
    "    cdhit_command = f\"cd-hit -i {PATH_MULTI_FASTA} -o {PATH_TMP_CDHIT}/{threshold}.out -c {threshold} -G 0 -aL 0.8\"\n",
    "    subprocess.run(cdhit_command, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "\n",
    "def make_cluster_dico(cdhit_out):\n",
    "    import json\n",
    "    dico_cluster = {}\n",
    "    threshold = cdhit_out.split(\"/\")[-1].split(\".out\")[0]\n",
    "    cluster_file = f\"{cdhit_out}.clstr\"\n",
    "    \n",
    "    with open(cluster_file) as f:\n",
    "        for cluster in f.read().split(\">Cluster\")[1:]:\n",
    "            id_cluster = f\"Dpo_cdhit_{len(dico_cluster)}\"\n",
    "            dico_cluster[id_cluster] = [line.split(\">\")[1].split(\".\")[0] for line in cluster.split(\"\\n\")[1:-1] if line]\n",
    "    \n",
    "    with open(f\"{PATH_WORK}/dico_cluster.cdhit__{threshold}.json\", \"w\") as outfile:\n",
    "        json.dump(dico_cluster, outfile)\n",
    "    \n",
    "    return dico_cluster, threshold\n",
    "\n",
    "def make_DF_binaries(df_info, dico_cluster, threshold):\n",
    "    df_dpo_prophages = pd.DataFrame(index=df_info.Phage.unique(), columns=dico_cluster.keys())\n",
    "    \n",
    "    for phage in df_info.Phage.unique():\n",
    "        df_phage = set(df_info[df_info[\"Phage\"] == phage][\"index\"].values)\n",
    "        df_dpo_prophages.loc[phage] = [bool(set(dpos) & df_phage) for dpos in dico_cluster.values()]\n",
    "    \n",
    "    df_dpo_prophages = df_dpo_prophages.astype(int)\n",
    "    df_dpo_prophages.to_csv(f\"{PATH_WORK}/DF_binaries_{threshold}.csv\", sep=\",\", index=True)\n",
    "    return df_dpo_prophages\n",
    "\n",
    "def make_DF_kltype(df_info, df, KL_type, dico_cluster, ratio=5, collapse=False):\n",
    "    positive_phages = df_info[df_info[\"KL_type_LCA\"] == KL_type][\"Phage\"].unique()\n",
    "    df_positives = df[df.index.isin(positive_phages)].drop_duplicates()\n",
    "    \n",
    "    n_samples = len(df_positives)\n",
    "    negative_phages = random.sample([phage for phage in df_info[\"Phage\"].unique() \n",
    "                                     if KL_type not in dico_prophage_kltype_associated[phage]], \n",
    "                                    int(n_samples * ratio))\n",
    "    \n",
    "    df_kltype = pd.concat([df_positives, df[df.index.isin(negative_phages)]])\n",
    "    labels = [1] * n_samples + [0] * (len(df_kltype) - n_samples)\n",
    "    \n",
    "    if collapse:\n",
    "        df_kltype = df_kltype.loc[:, df_kltype.sum() > 0]\n",
    "    \n",
    "    return df_kltype, labels\n",
    "\n",
    "def fit_rf_model_random_search(df_kl, all_labels, KL_type, threshold, n_splits=5, n_iters=100):\n",
    "    if os.path.isfile(f'{PATH_MODELS}/{threshold}_RF_{KL_type}.full_data.joblib') == False:\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=243)\n",
    "        data_kltype = {}\n",
    "\n",
    "        param_grid = {\n",
    "            'bootstrap': Categorical([True, False]),\n",
    "            'max_depth': Integer(10, 100),\n",
    "            'max_features': Categorical(['auto', 'sqrt']),\n",
    "            'min_samples_leaf': Integer(1, 4),\n",
    "            'min_samples_split': Integer(2, 10),\n",
    "            'n_estimators': Integer(200, 800)\n",
    "        }\n",
    "\n",
    "        for n, (train_index, test_index) in enumerate(skf.split(df_kl, all_labels)):\n",
    "            X_train, X_test = df_kl.iloc[train_index], df_kl.iloc[test_index]\n",
    "            y_train, y_test = pd.Series(all_labels).iloc[train_index], pd.Series(all_labels).iloc[test_index]\n",
    "\n",
    "            if n == 0:\n",
    "                rf = RandomForestClassifier(random_state=42)\n",
    "                bayes_search = BayesSearchCV(rf, param_grid, n_iter=n_iters, cv=4, n_jobs=-1)\n",
    "                bayes_search.fit(X_train, y_train)\n",
    "                best_params = bayes_search.best_params_\n",
    "                best_model = bayes_search.best_estimator_\n",
    "            else:\n",
    "                best_model = RandomForestClassifier(random_state=42, **best_params)\n",
    "                best_model.fit(X_train, y_train)\n",
    "\n",
    "            predictions = best_model.predict(X_test)\n",
    "            data_kltype[n] = {\n",
    "                \"best_parameters\": best_params,\n",
    "                \"model\": best_model,\n",
    "                \"test_data\": (y_test, predictions),\n",
    "                \"test_&_model_predictions\": (X_test, y_test),\n",
    "                \"iteration\": n\n",
    "            }\n",
    "\n",
    "        joblib.dump(data_kltype, f'{PATH_MODELS}/{threshold}_RF_{KL_type}.full_data.joblib')\n",
    "    else :\n",
    "        pass\n",
    "\n",
    "def make_prediction_file(path_file):\n",
    "    dico_cluster, threshold = make_cluster_dico(path_file)\n",
    "    df_binaries = make_DF_binaries(DF_info_lvl_0, dico_cluster, threshold)\n",
    "    \n",
    "    for KL_type, count in KLtype_count.items():\n",
    "        if count >= 5 and not os.path.isfile(f'{PATH_MODELS}/{threshold}_RF_{KL_type}.full_data.joblib'):\n",
    "            logging.info(f\"Processing KL type: {KL_type}\")\n",
    "            df_kl, all_labels = make_DF_kltype(DF_info_lvl_0, df_binaries, KL_type, dico_cluster, collapse=False)\n",
    "            fit_rf_model_random_search(df_kl, all_labels, KL_type, threshold)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    DF_info, dico_prophage_info = load_data()\n",
    "    DF_info_lvl_0 = ultrafilter_prophages(filter_prophages(DF_info, dico_prophage_info))\n",
    "    KLtype_count = Counter(DF_info_lvl_0[\"KL_type_LCA\"])\n",
    "    \n",
    "    dico_prophage_kltype_associated = {\n",
    "        phage: set(DF_info_lvl_0[DF_info_lvl_0[\"Phage\"] == phage][\"KL_type_LCA\"].values)\n",
    "        for phage in DF_info_lvl_0[\"Phage\"].unique()\n",
    "    }\n",
    "    \n",
    "    depo_domains_seq = dict(zip(DF_info_lvl_0[\"index\"], DF_info_lvl_0['domain_seq']))\n",
    "    with open(PATH_MULTI_FASTA, \"w\") as outfile:\n",
    "        for index, seq in depo_domains_seq.items():\n",
    "            outfile.write(f\">{index}\\n{seq}\\n\")\n",
    "    \n",
    "    cdhit_thresholds = [0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 0.975]\n",
    "    for threshold in cdhit_thresholds:\n",
    "        make_cdhit_cluster(threshold)\n",
    "    \n",
    "    cdhit_files = [f\"{PATH_TMP_CDHIT}/{file}\" for file in os.listdir(PATH_TMP_CDHIT) if file.endswith(\".out\")]\n",
    "    \n",
    "    with ThreadPool(10) as p:\n",
    "        p.map(make_prediction_file, cdhit_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch_geometric]",
   "language": "python",
   "name": "conda-env-torch_geometric-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
