{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48156cae-44a3-4c68-aa97-a6be5a91d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData, DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import HeteroConv , GATv2Conv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "import torch\n",
    "from torch import nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder , label_binarize , OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score , matthews_corrcoef\n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import random\n",
    "from collections import Counter\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import warnings\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# TropiGAT modules\n",
    "import TropiGAT_graph\n",
    "import TropiGAT_models\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# *****************************************************************************\n",
    "# Load the Dataframes :\n",
    "path_work = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/train_nn\"\n",
    "\n",
    "DF_info = pd.read_csv(f\"{path_work}/TropiGATv2.final_df_v2.tsv\", sep = \"\\t\" ,  header = 0)\n",
    "DF_info = DF_info.drop_duplicates(subset = [\"Protein_name\"])\n",
    "DF_info = DF_info[~DF_info[\"KL_type_LCA\"].str.contains(\"\\\\|\")]\n",
    "\n",
    "df_prophages = DF_info.drop_duplicates(subset = [\"Phage\"], keep = \"first\")\n",
    "dico_prophage_info = {row[\"Phage\"] : {\"prophage_strain\" : row[\"prophage_id\"] , \"ancestor\" : row[\"Infected_ancestor\"], \"KL_type\" : row[\"KL_type_LCA\"]} for _,row in df_prophages.iterrows()}\n",
    "\n",
    "# *****************************************************************************\n",
    "# The model : Classifier\n",
    "class TropiGAT_small_module(torch.nn.Module):\n",
    "    def __init__(self,hidden_channels, heads, edge_type = (\"B2\", \"expressed\", \"B1\") ,dropout = 0.2, conv = GATv2Conv):\n",
    "        super().__init__()\n",
    "        # GATv2 module :\n",
    "        self.conv = conv((-1,-1), hidden_channels, add_self_loops = False, heads = heads, dropout = dropout, shared_weights = True)\n",
    "        self.hetero_conv = HeteroConv({edge_type: self.conv})\n",
    "        # FNN layers : \n",
    "        self.linear_layers = nn.Sequential(nn.Linear(heads*hidden_channels, 1280),\n",
    "                                           nn.BatchNorm1d(1280),\n",
    "                                           nn.LeakyReLU(),\n",
    "                                           torch.nn.Dropout(dropout),\n",
    "                                           nn.Linear(1280, 480),\n",
    "                                           nn.BatchNorm1d(480),\n",
    "                                           nn.LeakyReLU(),\n",
    "                                           torch.nn.Dropout(dropout),\n",
    "                                           nn.Linear(480 , 1))\n",
    "        \n",
    "    def forward(self, graph_data):\n",
    "        x_B1_dict  = self.hetero_conv(graph_data.x_dict, graph_data.edge_index_dict)\n",
    "        x = self.linear_layers(x_B1_dict[\"B1\"])\n",
    "        return x.view(-1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2563387-98aa-4830-bc6a-0cf42f8de03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "# Pre-process data :\n",
    "# First filtration step :\n",
    "def get_filtered_prophages(prophage) :\n",
    "    combinations = []\n",
    "    to_exclude = set()\n",
    "    to_keep = set()\n",
    "    to_keep.add(prophage)\n",
    "    df_prophage_group = DF_info[(DF_info[\"prophage_id\"] == dico_prophage_info[prophage][\"prophage_strain\"]) & (DF_info[\"Infected_ancestor\"] == dico_prophage_info[prophage][\"ancestor\"])]\n",
    "    if len(df_prophage_group) == 1 :\n",
    "        pass\n",
    "    else :\n",
    "        depo_set = set(df_prophage_group[df_prophage_group[\"Phage\"] == prophage][\"domain_seq\"].values)\n",
    "        for prophage_tmp in df_prophage_group[\"Phage\"].unique().tolist() :\n",
    "            if prophage_tmp != prophage :\n",
    "                tmp_depo_set = set(df_prophage_group[df_prophage_group[\"Phage\"] == prophage_tmp][\"domain_seq\"].values)\n",
    "                if depo_set == tmp_depo_set :\n",
    "                    to_exclude.add(prophage_tmp)\n",
    "                else :\n",
    "                    if tmp_depo_set not in combinations :\n",
    "                        to_keep.add(prophage_tmp)\n",
    "                        combinations.append(tmp_depo_set)\n",
    "                    else :\n",
    "                        to_exclude.add(prophage_tmp)\n",
    "    return df_prophage_group , to_exclude , to_keep\n",
    "\n",
    "good_prophages = set()\n",
    "excluded_prophages = set()\n",
    "\n",
    "for prophage, info_prophage in tqdm(dico_prophage_info.items()) :\n",
    "    if prophage not in excluded_prophages and prophage not in good_prophages:\n",
    "        _, excluded_members , kept_members = get_filtered_prophages(prophage)\n",
    "        good_prophages.update(kept_members)\n",
    "        excluded_prophages.update(excluded_members)\n",
    "\n",
    "DF_info_lvl_0_filtered = DF_info[DF_info[\"Phage\"].isin(good_prophages)]\n",
    "DF_info_lvl_0_final = DF_info_lvl_0_filtered[~DF_info_lvl_0_filtered[\"KL_type_LCA\"].str.contains(\"\\\\|\")]\n",
    "\n",
    "\n",
    "# Second filtration step :\n",
    "duplicate_prophage = []\n",
    "dico_kltype_duplica = {}\n",
    "for kltype in DF_info_lvl_0_final[\"KL_type_LCA\"].unique():\n",
    "    df_kl = DF_info_lvl_0_final[DF_info_lvl_0_final[\"KL_type_LCA\"] == kltype][[\"Phage\", \"Protein_name\", \"KL_type_LCA\", \"Infected_ancestor\", \"index\", \"seq\", \"domain_seq\"]]\n",
    "    prophages_tmp_list = df_kl[\"Phage\"].unique().tolist()\n",
    "    set_sets_depo = []\n",
    "    duplicated = {}  \n",
    "    for prophage_tmp in prophages_tmp_list: \n",
    "        set_depo = frozenset(df_kl[df_kl[\"Phage\"] == prophage_tmp][\"domain_seq\"].values)\n",
    "        for past_set in set_sets_depo:\n",
    "            if past_set == set_depo:\n",
    "                duplicated[past_set] = duplicated.get(past_set, 0) + 1\n",
    "                duplicate_prophage.append(prophage_tmp)\n",
    "                break\n",
    "        else:\n",
    "            set_sets_depo.append(set_depo)\n",
    "            duplicated[set_depo] = 1\n",
    "    dico_kltype_duplica[kltype] = duplicated\n",
    "    \n",
    "DF_info_lvl_0_final_ultrafiltered = DF_info_lvl_0_final[~DF_info_lvl_0_final[\"Phage\"].isin(duplicate_prophage)]\n",
    "DF_info_lvl_0 = DF_info_lvl_0_final_ultrafiltered.copy()\n",
    "\n",
    "# Input graph: \n",
    "# graph_baseline , dico_prophage_kltype_associated = TropiGAT_graph.build_graph_baseline(DF_info_lvl_0)\n",
    "# graph_data_kltype = TropiGAT_graph.build_graph_masking_v2(graph_baseline , dico_prophage_kltype_associated, DF_info_lvl_0, KL_type, 5, 0.7, 0.2, 0.1, seed = seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6de729-faff-4ac6-944e-cc452c801b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "# Training :\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class TropiGAT_small_module(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, heads, edge_type=(\"B2\", \"expressed\", \"B1\"), dropout=0.2, conv=GATv2Conv):\n",
    "        super().__init__()\n",
    "        # GATv2 module :\n",
    "        self.conv = conv((-1, -1), hidden_channels, add_self_loops=False, heads=heads, dropout=dropout, shared_weights=True)\n",
    "        self.hetero_conv = HeteroConv({edge_type: self.conv})\n",
    "        # FNN layers :\n",
    "        self.linear_layers = nn.Sequential(nn.Linear(heads*hidden_channels, 1280),\n",
    "                                           nn.BatchNorm1d(1280),\n",
    "                                           nn.LeakyReLU(),\n",
    "                                           torch.nn.Dropout(dropout),\n",
    "                                           nn.Linear(1280, 480),\n",
    "                                           nn.BatchNorm1d(480),\n",
    "                                           nn.LeakyReLU(),\n",
    "                                           torch.nn.Dropout(dropout),\n",
    "                                           nn.Linear(480, 1))\n",
    "\n",
    "    def forward(self, graph_data):\n",
    "        x_B1_dict = self.hetero_conv(graph_data.x_dict, graph_data.edge_index_dict)\n",
    "        x = self.linear_layers(x_B1_dict[\"B1\"])\n",
    "        return x.view(-1)\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=60, verbose=True, path='best_model.pt', delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, graph, criterion, mask):\n",
    "    model.eval()\n",
    "    out_eval = model(graph)\n",
    "    pred = torch.sigmoid(out_eval[mask]).round()\n",
    "    labels = graph[\"B1\"].y[mask]\n",
    "    val_loss = criterion(out_eval[mask], labels.float())\n",
    "\n",
    "    # Calculate the metrics\n",
    "    f1 = f1_score(labels.cpu(), pred.cpu(), average='binary')\n",
    "    precision = precision_score(labels.cpu(), pred.cpu(), average='binary')\n",
    "    recall = recall_score(labels.cpu(), pred.cpu(), average='binary')\n",
    "    mcc = matthews_corrcoef(labels.cpu(), pred.cpu())\n",
    "    accuracy = accuracy_score(labels.cpu(), pred.cpu())\n",
    "    auc = roc_auc_score(labels.cpu(), out_eval[mask].cpu())\n",
    "\n",
    "    return val_loss.item(), (f1, precision, recall, mcc, accuracy, auc)\n",
    "\n",
    "def train(model, data, optimizer, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = criterion(out[data[\"B1\"].train_mask], data[\"B1\"].y[data[\"B1\"].train_mask].float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def objective(trial):\n",
    "    try:\n",
    "        # Define the hyperparameters:\n",
    "        lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\n",
    "        weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-4)\n",
    "        heads = trial.suggest_int('heads', 1, 5, step=1)\n",
    "        dropout = trial.suggest_uniform('dropout', 0, 0.5)\n",
    "        # Fixed hidden channels:\n",
    "        hidden_channels = 1280\n",
    "        # Define the model:\n",
    "        model = TropiGAT_small_module(hidden_channels=hidden_channels, heads=heads, dropout=dropout)\n",
    "        # Input graph:\n",
    "        graph_baseline , dico_prophage_kltype_associated = TropiGAT_graph.build_graph_baseline(DF_info_lvl_0)\n",
    "        graph_data_kltype = TropiGAT_graph.build_graph_masking_v2(graph_baseline , dico_prophage_kltype_associated, DF_info_lvl_0, KL_type, 5, 0.7, 0.2, 0.1, seed = 243)\n",
    "        # set up the training: \n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "        early_stopping = EarlyStopping(patience=100, verbose=True, path=f\"best_model_trial_{trial.number}_{KL_type}.pt\")\n",
    "        # training: \n",
    "        best_val_loss = float('inf')\n",
    "        for epoch in range(500):\n",
    "            train_loss = train(model, graph_data_kltype, optimizer, criterion)\n",
    "            val_loss, metrics = evaluate(model, graph_data_kltype, criterion, graph_data_kltype[\"B1\"].test_mask)\n",
    "\n",
    "            scheduler.step(val_loss)\n",
    "            early_stopping(val_loss, model)\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                logging.info(f\"Early stopping triggered at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "        # Final evaluation\n",
    "        model.load_state_dict(torch.load(f\"best_model_trial_{trial.number}_{KL_type}.pt\"))\n",
    "        final_val_loss, metrics = evaluate(model, graph_data_kltype, criterion, graph_data_kltype[\"B1\"].eval_mask)\n",
    "\n",
    "        # Log the results\n",
    "        logging.info(f\"Trial {trial.number}: Val Loss: {final_val_loss:.4f}, MCC: {metrics[3]:.4f}, AUC: {metrics[5]:.4f}\")\n",
    "\n",
    "        return final_val_loss  # Return validation loss for minimization\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in trial {trial.number}: {str(e)}\")\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "# Optimize\n",
    "KL_type = \"KL1\"\n",
    "\n",
    "logging.basicConfig(filename = f\"{path_work}/GATv2Conv.{KL_type}.loss.1209.optuna.log\",format='%(asctime)s | %(levelname)s: %(message)s', level=logging.NOTSET, filemode='w')\n",
    "logging.info(\"Starting hyperparameter optimization\")\n",
    "study = optuna.create_study(sampler=TPESampler(), direction='minimize')\n",
    "\n",
    "\n",
    "try:\n",
    "    study.optimize(objective, n_trials=100, n_jobs=-1, catch=(Exception,))\n",
    "\n",
    "    if study.best_trial is not None:\n",
    "        print(f\"Best parameters: {study.best_params}\")\n",
    "        logging.info(f\"Best parameters: {study.best_params}\")\n",
    "        best_trial = study.best_trial\n",
    "        print(f\"Best trial: Val Loss: {best_trial.value:.4f}\")\n",
    "        logging.info(f\"Best trial: Val Loss: {best_trial.value:.4f}\")\n",
    "        # Optionally, you can retrain the model with the best parameters and evaluate on the test set\n",
    "        best_model = TropiGAT_small_module(hidden_channels=1280, heads=best_trial.params['heads'], dropout=best_trial.params['dropout'])\n",
    "        # ... (retrain with best parameters)\n",
    "        # final_test_loss, final_metrics = evaluate(best_model, graph_data, criterion, graph_data[\"B1\"].test_mask)\n",
    "        # print(f\"Final Test Results: Loss: {final_test_loss:.4f}, MCC: {final_metrics[3]:.4f}, AUC: {final_metrics[5]:.4f}\")\n",
    "    else:\n",
    "        logging.warning(\"No trials were successfully completed.\")\n",
    "        print(\"No trials were successfully completed. Check the logs for more information.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred during optimization: {str(e)}\")\n",
    "    print(f\"An error occurred during optimization. Check the logs for more information.\")\n",
    "\n",
    "finally:\n",
    "    # Print a summary of the study\n",
    "    trial_data = study.trials_dataframe()\n",
    "    if not trial_data.empty:\n",
    "        print(\"\\nStudy Summary:\")\n",
    "        print(f\"Number of completed trials: {len(study.trials)}\")\n",
    "        print(f\"Number of pruned trials: {len(study.get_trials(states=[optuna.trial.TrialState.PRUNED]))}\")\n",
    "        print(f\"Number of completed trials: {len(study.get_trials(states=[optuna.trial.TrialState.COMPLETE]))}\")\n",
    "        print(\"\\nBest 5 trials:\")\n",
    "        print(trial_data.sort_values('value').head())\n",
    "    else:\n",
    "        print(\"No trial data available.\")\n",
    "\n",
    "# Save the study results\n",
    "study.trials_dataframe().to_csv(f\"{path_work}/optuna_study_results.{KL_type}.1209.csv\", index=False)\n",
    "logging.info(\"Study results saved to 'optuna_study_results.{KL_type}.1209.csv'\")\n",
    "#best_model = TropiGAT_small_module(hidden_channels=1280, heads=best_trial.params['heads'], dropout=best_trial.params['dropout'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b07e65f-7a8b-4512-9dff-fe8af72921b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#BATCH --job-name=Optuna_1009_\n",
    "#SBATCH --qos=short\n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=32\n",
    "#SBATCH --mem=120gb \n",
    "#SBATCH --time=2-00:00:00 \n",
    "#SBATCH --output=Optuna_1009_%j.log \n",
    "\n",
    "module restore la_base\n",
    "conda activate torch_geometric\n",
    "\n",
    "python /home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/train_nn/script_files/optuna_GATv2Conv_Hetero.loss.1009.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb49d4b-e178-41e2-b873-a79570e1c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsync -avzhe ssh \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/train_nn/optuna_study_results.KL1.1209.csv \\\n",
    "/media/concha-eloko/Linux/PPT_clean/ficheros_28032023\n",
    "\n",
    "rsync -avzhe ssh \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/train_nn/optuna_study_results.KL64.1209.csv \\\n",
    "/media/concha-eloko/Linux/PPT_clean/ficheros_28032023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69a26ff1-49fc-44ea-b6b1-752de307d085",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path_df = \"/media/concha-eloko/Linux/PPT_clean/ficheros_28032023\"\n",
    "\n",
    "kl_64_df = pd.read_csv(f\"{path_df}/optuna_study_results.KL64.1209.csv\", header = 0, sep = \",\", index_col = [\"number\"])\n",
    "kl_1_df = pd.read_csv(f\"{path_df}/optuna_study_results.KL1.1209.csv\", header = 0, sep = \",\", index_col = [\"number\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7c1f735-ea4f-4922-89ec-e3e4de76da7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_dropout</th>\n",
       "      <th>params_heads</th>\n",
       "      <th>params_lr</th>\n",
       "      <th>params_weight_decay</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.214616</td>\n",
       "      <td>2024-09-11 13:13:15.012388</td>\n",
       "      <td>2024-09-11 16:02:22.856435</td>\n",
       "      <td>0 days 02:49:07.844047</td>\n",
       "      <td>0.063113</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.288147</td>\n",
       "      <td>2024-09-11 13:13:15.015634</td>\n",
       "      <td>2024-09-11 16:02:19.889560</td>\n",
       "      <td>0 days 02:49:04.873926</td>\n",
       "      <td>0.387089</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.402074</td>\n",
       "      <td>2024-09-11 13:13:15.017499</td>\n",
       "      <td>2024-09-11 15:40:39.095528</td>\n",
       "      <td>0 days 02:27:24.078029</td>\n",
       "      <td>0.200835</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.341281</td>\n",
       "      <td>2024-09-11 13:13:15.021601</td>\n",
       "      <td>2024-09-11 16:06:48.181022</td>\n",
       "      <td>0 days 02:53:33.159421</td>\n",
       "      <td>0.078880</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.453863</td>\n",
       "      <td>2024-09-11 13:13:15.022937</td>\n",
       "      <td>2024-09-11 15:18:59.106928</td>\n",
       "      <td>0 days 02:05:44.083991</td>\n",
       "      <td>0.135402</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.291542</td>\n",
       "      <td>2024-09-11 15:28:52.372036</td>\n",
       "      <td>2024-09-11 16:42:31.864205</td>\n",
       "      <td>0 days 01:13:39.492169</td>\n",
       "      <td>0.485289</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.292580</td>\n",
       "      <td>2024-09-11 15:32:57.953364</td>\n",
       "      <td>2024-09-11 16:44:26.652001</td>\n",
       "      <td>0 days 01:11:28.698637</td>\n",
       "      <td>0.484483</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.267515</td>\n",
       "      <td>2024-09-11 15:34:28.631242</td>\n",
       "      <td>2024-09-11 16:43:48.094296</td>\n",
       "      <td>0 days 01:09:19.463054</td>\n",
       "      <td>0.494634</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.295961</td>\n",
       "      <td>2024-09-11 15:40:39.597347</td>\n",
       "      <td>2024-09-11 16:43:01.275574</td>\n",
       "      <td>0 days 01:02:21.678227</td>\n",
       "      <td>0.484797</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.283962</td>\n",
       "      <td>2024-09-11 15:41:22.447707</td>\n",
       "      <td>2024-09-11 16:45:36.699226</td>\n",
       "      <td>0 days 01:04:14.251519</td>\n",
       "      <td>0.497714</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           value              datetime_start           datetime_complete  \\\n",
       "number                                                                     \n",
       "0       0.214616  2024-09-11 13:13:15.012388  2024-09-11 16:02:22.856435   \n",
       "1       0.288147  2024-09-11 13:13:15.015634  2024-09-11 16:02:19.889560   \n",
       "2       0.402074  2024-09-11 13:13:15.017499  2024-09-11 15:40:39.095528   \n",
       "3       0.341281  2024-09-11 13:13:15.021601  2024-09-11 16:06:48.181022   \n",
       "4       0.453863  2024-09-11 13:13:15.022937  2024-09-11 15:18:59.106928   \n",
       "...          ...                         ...                         ...   \n",
       "95      0.291542  2024-09-11 15:28:52.372036  2024-09-11 16:42:31.864205   \n",
       "96      0.292580  2024-09-11 15:32:57.953364  2024-09-11 16:44:26.652001   \n",
       "97      0.267515  2024-09-11 15:34:28.631242  2024-09-11 16:43:48.094296   \n",
       "98      0.295961  2024-09-11 15:40:39.597347  2024-09-11 16:43:01.275574   \n",
       "99      0.283962  2024-09-11 15:41:22.447707  2024-09-11 16:45:36.699226   \n",
       "\n",
       "                      duration  params_dropout  params_heads  params_lr  \\\n",
       "number                                                                    \n",
       "0       0 days 02:49:07.844047        0.063113             2   0.000246   \n",
       "1       0 days 02:49:04.873926        0.387089             4   0.000377   \n",
       "2       0 days 02:27:24.078029        0.200835             1   0.000033   \n",
       "3       0 days 02:53:33.159421        0.078880             3   0.000106   \n",
       "4       0 days 02:05:44.083991        0.135402             1   0.000014   \n",
       "...                        ...             ...           ...        ...   \n",
       "95      0 days 01:13:39.492169        0.485289             2   0.000534   \n",
       "96      0 days 01:11:28.698637        0.484483             2   0.000561   \n",
       "97      0 days 01:09:19.463054        0.494634             2   0.000528   \n",
       "98      0 days 01:02:21.678227        0.484797             2   0.000446   \n",
       "99      0 days 01:04:14.251519        0.497714             2   0.000646   \n",
       "\n",
       "        params_weight_decay     state  \n",
       "number                                 \n",
       "0                  0.000080  COMPLETE  \n",
       "1                  0.000007  COMPLETE  \n",
       "2                  0.000056  COMPLETE  \n",
       "3                  0.000003  COMPLETE  \n",
       "4                  0.000005  COMPLETE  \n",
       "...                     ...       ...  \n",
       "95                 0.000055  COMPLETE  \n",
       "96                 0.000003  COMPLETE  \n",
       "97                 0.000002  COMPLETE  \n",
       "98                 0.000002  COMPLETE  \n",
       "99                 0.000002  COMPLETE  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_64_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5906069e-fc60-4641-b6c7-1e81f69a06bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_64_sorted = kl_64_df.sort_values(by='value', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece7d5b-3db3-459d-bd7f-e72252f03c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3697a60a-4a33-4c53-bb07-f9e5be921e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb326948-094b-46d0-afb9-7b9ea3b83db5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_dropout</th>\n",
       "      <th>params_heads</th>\n",
       "      <th>params_lr</th>\n",
       "      <th>params_weight_decay</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.382488</td>\n",
       "      <td>2024-09-11 13:13:39.772638</td>\n",
       "      <td>2024-09-11 15:26:08.790658</td>\n",
       "      <td>0 days 02:12:29.018020</td>\n",
       "      <td>0.470613</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.407244</td>\n",
       "      <td>2024-09-11 13:13:39.774067</td>\n",
       "      <td>2024-09-11 15:18:21.750527</td>\n",
       "      <td>0 days 02:04:41.976460</td>\n",
       "      <td>0.483999</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.554516</td>\n",
       "      <td>2024-09-11 13:13:39.774657</td>\n",
       "      <td>2024-09-11 15:27:10.266010</td>\n",
       "      <td>0 days 02:13:30.491353</td>\n",
       "      <td>0.236198</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.670000</td>\n",
       "      <td>2024-09-11 13:13:39.776294</td>\n",
       "      <td>2024-09-11 14:28:51.772471</td>\n",
       "      <td>0 days 01:15:11.996177</td>\n",
       "      <td>0.162752</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.580515</td>\n",
       "      <td>2024-09-11 13:13:39.777714</td>\n",
       "      <td>2024-09-11 15:09:02.616142</td>\n",
       "      <td>0 days 01:55:22.838428</td>\n",
       "      <td>0.405861</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.463210</td>\n",
       "      <td>2024-09-11 15:10:30.988254</td>\n",
       "      <td>2024-09-11 16:29:31.061318</td>\n",
       "      <td>0 days 01:19:00.073064</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.429945</td>\n",
       "      <td>2024-09-11 15:10:32.724573</td>\n",
       "      <td>2024-09-11 16:22:59.666773</td>\n",
       "      <td>0 days 01:12:26.942200</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.454039</td>\n",
       "      <td>2024-09-11 15:12:12.643011</td>\n",
       "      <td>2024-09-11 16:27:19.980389</td>\n",
       "      <td>0 days 01:15:07.337378</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.390004</td>\n",
       "      <td>2024-09-11 15:15:05.052045</td>\n",
       "      <td>2024-09-11 16:30:08.779319</td>\n",
       "      <td>0 days 01:15:03.727274</td>\n",
       "      <td>0.006730</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.416819</td>\n",
       "      <td>2024-09-11 15:16:53.768269</td>\n",
       "      <td>2024-09-11 16:26:05.919437</td>\n",
       "      <td>0 days 01:09:12.151168</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           value              datetime_start           datetime_complete  \\\n",
       "number                                                                     \n",
       "0       0.382488  2024-09-11 13:13:39.772638  2024-09-11 15:26:08.790658   \n",
       "1       0.407244  2024-09-11 13:13:39.774067  2024-09-11 15:18:21.750527   \n",
       "2       0.554516  2024-09-11 13:13:39.774657  2024-09-11 15:27:10.266010   \n",
       "3       0.670000  2024-09-11 13:13:39.776294  2024-09-11 14:28:51.772471   \n",
       "4       0.580515  2024-09-11 13:13:39.777714  2024-09-11 15:09:02.616142   \n",
       "...          ...                         ...                         ...   \n",
       "95      0.463210  2024-09-11 15:10:30.988254  2024-09-11 16:29:31.061318   \n",
       "96      0.429945  2024-09-11 15:10:32.724573  2024-09-11 16:22:59.666773   \n",
       "97      0.454039  2024-09-11 15:12:12.643011  2024-09-11 16:27:19.980389   \n",
       "98      0.390004  2024-09-11 15:15:05.052045  2024-09-11 16:30:08.779319   \n",
       "99      0.416819  2024-09-11 15:16:53.768269  2024-09-11 16:26:05.919437   \n",
       "\n",
       "                      duration  params_dropout  params_heads  params_lr  \\\n",
       "number                                                                    \n",
       "0       0 days 02:12:29.018020        0.470613             3   0.000068   \n",
       "1       0 days 02:04:41.976460        0.483999             3   0.000755   \n",
       "2       0 days 02:13:30.491353        0.236198             5   0.000015   \n",
       "3       0 days 01:15:11.996177        0.162752             2   0.000017   \n",
       "4       0 days 01:55:22.838428        0.405861             4   0.000071   \n",
       "...                        ...             ...           ...        ...   \n",
       "95      0 days 01:19:00.073064        0.005255             5   0.000913   \n",
       "96      0 days 01:12:26.942200        0.004630             5   0.000954   \n",
       "97      0 days 01:15:07.337378        0.002655             5   0.000910   \n",
       "98      0 days 01:15:03.727274        0.006730             5   0.000987   \n",
       "99      0 days 01:09:12.151168        0.008008             5   0.000964   \n",
       "\n",
       "        params_weight_decay     state  \n",
       "number                                 \n",
       "0                  0.000002  COMPLETE  \n",
       "1                  0.000016  COMPLETE  \n",
       "2                  0.000001  COMPLETE  \n",
       "3                  0.000003  COMPLETE  \n",
       "4                  0.000030  COMPLETE  \n",
       "...                     ...       ...  \n",
       "95                 0.000001  COMPLETE  \n",
       "96                 0.000001  COMPLETE  \n",
       "97                 0.000001  COMPLETE  \n",
       "98                 0.000066  COMPLETE  \n",
       "99                 0.000069  COMPLETE  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17da2234-1d8f-4bfa-97c0-52312481166b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch_geometric]",
   "language": "python",
   "name": "conda-env-torch_geometric-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
