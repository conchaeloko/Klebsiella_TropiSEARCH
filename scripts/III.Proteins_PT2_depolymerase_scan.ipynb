{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **III. Proteins**\n",
    "## The goal here is to scan the (filtered) MSA with the depolymerase DB \n",
    "\n",
    "## 1. hmmcan the MSA\n",
    "## 2. Scan the results\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <b>1. hmmscan command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import subprocess\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import pandas as pd\n",
    "# Generate a list of path of filtered MSA\n",
    "path_decipher = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "path_files = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/15122022_session\"\n",
    "\n",
    "all_proteins = pd.read_csv(f\"{path_files}/part_III_ptB/all_prophage_proteins.names.db.fasta\", names = [\"proteins\"])\n",
    "\n",
    "paths = [f\"{path_decipher}/{prot.split('__')[0]}/mmseqs_out/{prot.split('__')[1]}/{prot.split('.fasta')[0]}.MSA.a2m\" for prot in all_proteins[\"proteins\"] \n",
    "         if os.path.isfile(f\"{path_decipher}/{prot.split('__')[0]}/mmseqs_out/{prot.split('__')[1]}/{prot.split('.fasta')[0]}.MSA.a2m\")==True \n",
    "         if os.path.isfile(f\"{path_decipher}/{prot.split('__')[0]}/DBsuite_depo/{prot.split('__')[1]}/{prot.split('.fasta')[0]}.suite.hhr\")==False]\n",
    "\n",
    "\n",
    "def scan_depolymerase(path_query) :\n",
    "    path_db = \"/home/conchae/databases/depolymerase_building/DBsuite_depolymerase/depolymerase_db.suite\"\n",
    "    phage = path_query.split(\"__\")[1]\n",
    "    query = path_query.split(\"/\")[-1].split(\".MSA\")[0]\n",
    "    path_dir_short = f\"{'/'.join(path_query.split('/')[0:-3])}/DBsuite_depo\"\n",
    "    path_dir = f\"{'/'.join(path_query.split('/')[0:-3])}/DBsuite_depo/{phage}\"\n",
    "    try :\n",
    "        os.mkdir(path_dir_short)\n",
    "    except FileExistsError :\n",
    "        pass\n",
    "    try :\n",
    "        os.mkdir(path_dir)\n",
    "    except FileExistsError :\n",
    "        pass\n",
    "    path_out = f\"{path_dir}/{query}\"\n",
    "    hhmscan_cmmd = f\"hhsearch -i {path_query} -d  {path_db} -o {path_out}.suite.hhr -blasttab {path_out}.suite.tab\"\n",
    "    hhmscan_process = subprocess.Popen(hhmscan_cmmd, shell =True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    scan_out, scan_err = hhmscan_process.communicate()\n",
    "    with open(f\"{path_files}/hhsearch_done\",\"a+\") as outfile :\n",
    "        outfile.write(f\"{path_query}\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(30) as p:\n",
    "        p.map(scan_depolymerase, paths)\n",
    "        \n",
    "        \n",
    "# *********************************************************** \n",
    "#!/bin/bash\n",
    "#BATCH --job-name=scan_ppt__\n",
    "#SBATCH --qos=long\n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=60 \n",
    "#SBATCH --mem=200gb \n",
    "#SBATCH --time=10-00:00:00 \n",
    "#SBATCH --output=scan_ppt__%j.log \n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate HH-suite3\n",
    "\n",
    "python /home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/15122022_session/script_files/part_III/hhsearch.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "><b> 2. Scanning the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import random\n",
    "#import subprocess\n",
    "#from tqdm import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "#import pprint\n",
    "import json \n",
    "#pp = pprint.PrettyPrinter(width = 150)\n",
    "# Generate a list of path of filtered MSA \n",
    "path_decipher = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "path_db = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/15122022_session\"\n",
    "\n",
    "out_names = [\"query\",\"target\",\"x1\",\"hmm\",\"mismatch\",\"gapopen\",\"query_start\",\"query_stop\",\"target_start\",\"target_stop\",\"evalue\",\"score\"]\n",
    "\n",
    "paths = [f\"{path_decipher}/{prot.split('__')[0]}/mmseqs_out/{prot.split('__')[1]}/{prot.split('.fasta')[0]}.MSA.a2m\" for prot in all_proteins[\"proteins\"][0:20] \n",
    "         if os.path.isfile(f\"{path_decipher}/{prot.split('__')[0]}/mmseqs_out/{prot.split('__')[1]}/{prot.split('.fasta')[0]}.MSA.a2m\")==True]\n",
    "\n",
    "\n",
    "def scan_depolymerase(path_query) :\n",
    "    path_db = \"/home/conchae/databases/depolymerase_building/DBsuite_Dpo.v3/DBsuite_Dpo.v3\"\n",
    "    phage = path_query.split(\"__\")[1]\n",
    "    query = path_query.split(\"/\")[-1].split(\".MSA\")[0]\n",
    "    path_dir_short = f\"{'/'.join(path_query.split('/')[0:-3])}/DBsuite_depo_v3\"\n",
    "    path_dir = f\"{'/'.join(path_query.split('/')[0:-3])}/DBsuite_depo_v3/{phage}\"\n",
    "    try :\n",
    "        os.mkdir(path_dir_short)\n",
    "    except FileExistsError :\n",
    "        pass\n",
    "    try :\n",
    "        os.mkdir(path_dir)\n",
    "    except FileExistsError :\n",
    "        pass\n",
    "    path_out = f\"{path_dir}/{query}\"\n",
    "    hhmscan_cmmd = f\"hhsearch -i {path_query} -d  {path_db} -o {path_out}.suite.hhr -blasttab {path_out}.suite.tab\"\n",
    "    hhmscan_process = subprocess.Popen(hhmscan_cmmd, shell =True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    scan_out, scan_err = hhmscan_process.communicate()\n",
    "    print(path_query , scan_out , scan_err , sep = \"\\n\")\n",
    "    with open(f\"{path_files}/hhsearch_done_v3\",\"a+\") as outfile :\n",
    "        outfile.write(f\"{path_query}\\n\")\n",
    "\n",
    "\n",
    "scores_out , dico_count_out, dico_ipr_out, depolymerase_dico_out = scan_tab(path_tabs[\"Paths\"])\n",
    "\n",
    "with open(f\"{path_db}/dico_ipr_out.v3.json\", \"w\") as outfile:\n",
    "    json.dump(dico_ipr_out, outfile)\n",
    "with open(f\"{path_db}/dico_ipr_count.v3.json\", \"w\") as outfile:\n",
    "    json.dump(dico_count_out, outfile)    \n",
    "with open(f\"{path_db}/dbsuite_results.v3.json\", \"w\") as outfile:\n",
    "    json.dump(depolymerase_dico_out, outfile) \n",
    "    \n",
    "scores_list = pd.DataFrame(scores_out)\n",
    "scores_list.to_csv(f\"{path_db}/scores.dbsuite.v3.txt\", header=None, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Build a DF with the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df 1 : [protein name, sequence_index, KL type ancestor, ancestor_id, IPR, score, range alignment, sequence_aa]\n",
    "\n",
    "df 2 : [sequence_index, sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import json\n",
    "\n",
    "path_labels = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_labeling/phageboost\"\n",
    "path_db = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/15122022_session\"\n",
    "path_decipher = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "\n",
    "f_labels=[\"Prophage_name\",\"KL_ancestor\",\"Id_monophyletic_group\",\"Number of clades\",\"Number of leafs\",\"Number of new ancestors\",\"Number of k-type swap\",\"Nodes k-types\",\"Nodes k-types all\"]\n",
    "df_prophages = pd.read_csv(f\"{path_labels}/prophage_data.clusters_80.phageboost_70.tsv\", sep=\"\\t\", names =f_labels) \n",
    "\n",
    "results_DBsuite = json.load(open(f\"{path_db}/dbsuite_results.v3.json\"))\n",
    "\n",
    "def f_path_tab(query) :\n",
    "    \"From the protein name, get the tab output with score >= 20\"\n",
    "    path_decipher = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "    strain , prophage = query.split(\"__\")[0], query.split(\"__\")[1]\n",
    "    path_tab = f\"{path_decipher}/{strain}/DBsuite_depo_v3/{prophage}/{query}.suite.tab\"\n",
    "    out_names = [\"query\",\"target\",\"x1\",\"hmm\",\"mismatch\",\"gapopen\",\"consensus_start\",\"consensus_stop\",\"target_start\",\"target_stop\",\"evalue\",\"score\"]\n",
    "    df_tab = pd.read_csv(f\"{path_tab}\", sep=\"\\t\", names= out_names)\n",
    "    df_tab = df_tab[df_tab[\"score\"] >= 20]\n",
    "    sequence = open(f\"{path_decipher}/{strain}/tmp/{prophage}/{query}.fasta\").read().split(\"\\n\")[1]\n",
    "    return df_tab, sequence\n",
    "\n",
    "def get_qlimits(query,target) :\n",
    "    strain , prophage = query.split(\"__\")[0], query.split(\"__\")[1]\n",
    "    df_tab, sequence = f_path_tab(query)\n",
    "    #print(df_tab, target)\n",
    "    #return (1,2)\n",
    "    consensus_start = df_tab[df_tab[\"target\"]==f\"{target}\"][\"consensus_start\"].values[0] \n",
    "    consensus_stop = df_tab[df_tab[\"target\"]==f\"{target}\"][\"consensus_stop\"].values[0]\n",
    "    msa_seq = \"\".join(open(f\"{path_decipher}/{strain}/mmseqs_out/{prophage}/{query}.MSA.a2m\").read().split(\">\")[1].split(\"\\n\")[1:])\n",
    "    i = 0\n",
    "    for n in range(len(msa_seq)) :\n",
    "        if msa_seq[n] == \"-\" :\n",
    "            pass\n",
    "        else :\n",
    "            i += 1 \n",
    "        if n == int(consensus_start)-1 :\n",
    "            qstart = i\n",
    "        elif n == int(consensus_stop)-1 :\n",
    "            qstop = i \n",
    "            break            \n",
    "    return qstart, qstop\n",
    "        \n",
    "# df 1 : [protein name, #sequence_index# , KL type ancestor, ancestor_id, IPR, score, qstart, qstop, sequence_aa]\n",
    "with open(f\"{path_db}/Results_III_DataFrame.v3.csv\", \"w\") as outfile :\n",
    "    for protein in tqdm(results_DBsuite) :\n",
    "        df_tab , sequence = f_path_tab(protein)\n",
    "        prophage = \"__\".join(protein.split(\"__\")[0:2])+\".fasta\"\n",
    "        df_prot = df_prophages[df_prophages[\"Prophage_name\"]==prophage]\n",
    "        kl_ancestor = df_prot[\"KL_ancestor\"].values[0]\n",
    "        ancestor_id = df_prot[\"Id_monophyletic_group\"].values[0]\n",
    "        #print(prophage, kl_ancestor , ancestor_id)\n",
    "        for index_tab, hit_ipr in df_tab.iterrows() :\n",
    "            target = hit_ipr[\"target\"]\n",
    "            start , stop = get_qlimits(protein,target)\n",
    "            score = hit_ipr[\"score\"]\n",
    "            if stop - start >= 30 :\n",
    "                outfile.write(f\"{protein}\\t{kl_ancestor}\\t{ancestor_id}\\t{target}\\t{score}\\t{start}\\t{stop}\\t{sequence}\\n\")\n",
    "                #print(f\"{protein}\\t{kl_ancestor}\\t{ancestor_id}\\t{target}\\t{score}\\t{start}\\t{stop}\\n\")         \n",
    "                \n",
    "                \n",
    "labels_results = [\"protein_name\",\"KL_type_ancestor\",\"ancestor_id\",\"IPR_entry\",\"score\",\"qstart\",\"qstop\",\"sequence\"]\n",
    "results_df = pd.read_csv(f\"{path_db}/Results_III_DataFrame.v3.csv\", sep=\"\\t\", names= labels_results)\n",
    "\n",
    "sequences_df = results_df[\"sequence\"].unique()\n",
    "with open(f\"{path_db}/Results_III_sequences.v3.csv\", \"w\") as outfile :\n",
    "    for index, sequence in enumerate(sequences_df) :\n",
    "        print(sequence)\n",
    "        outfile.write(f\"{index}\\t{sequence}\\n\")\n",
    "\n",
    "# *******************\n",
    "# DF with index sequences :\n",
    "\n",
    "import pandas as pd \n",
    "import os \n",
    "path_labels = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_labeling/phageboost\"\n",
    "path_db = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/15122022_session\"\n",
    "path_decipher = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "\n",
    "labels_results = [\"protein_name\",\"KL_type_ancestor\",\"ancestor_id\",\"IPR_entry\",\"score\",\"qstart\",\"qstop\",\"sequence\"]\n",
    "results_df = pd.read_csv(f\"{path_db}/Results_III_DataFrame.v3.csv\", sep=\"\\t\", names= labels_results)\n",
    "sequence_df = pd.read_csv(f\"{path_db}/Results_III_sequences.v3.csv\", sep = \"\\t\" ,names= [\"index\", \"sequence\"])\n",
    "\n",
    "results_df[\"index_seq\"] = sequence_df[sequence_df[\"sequence\"]== results_df[\"sequence\"]][\"index\"]\n",
    "\n",
    "index_list = []\n",
    "for index , row in tqdm(results_df.iterrows()) :\n",
    "    index_seq = sequence_df[sequence_df[\"sequence\"] == row[\"sequence\"]][\"index\"].values[0]\n",
    "    index_list.append(index_seq)\n",
    "    \n",
    "results_df[\"index_seq\"] = index_list\n",
    "results_df.to_csv(f\"{path_db}/Results_III_DataFrame.v3.final.csv\", sep=\"\\t\",header =  [\"protein_name\",\"KL_type_ancestor\",\"ancestor_id\",\"IPR_entry\",\"score\",\"qstart\",\"qstop\",\"sequence\",\"index_seq\"], index = False )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#BATCH --job-name=writting_r__\n",
    "#SBATCH --qos=short\n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=5 \n",
    "#SBATCH --mem=20gb \n",
    "#SBATCH --time=1-00:00:00 \n",
    "#SBATCH --output=writting_r__%j.log \n",
    "\n",
    "python /home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/15122022_session/script_files/part_III/writting_db3.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
