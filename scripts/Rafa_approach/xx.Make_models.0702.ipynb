{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a5b1f9-09b5-4e38-933b-8aa5076c83c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import random\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import logging\n",
    "import subprocess\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import joblib\n",
    "\n",
    "# SCikitlearn modules :\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report , roc_auc_score, matthews_corrcoef\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Scipy modules : \n",
    "from scipy.stats import fisher_exact\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "\n",
    "path_work = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/Seqbased_model\"\n",
    "path_models = f\"{path_work}/RF_0702_models\"\n",
    "\n",
    "DF_info = pd.read_csv(f\"{path_work}/TropiGATv2.final_df.tsv\", sep = \"\\t\" ,  header = 0)\n",
    "DF_info_lvl_0 = DF_info[~DF_info[\"KL_type_LCA\"].str.contains(\"\\\\|\")]\n",
    "DF_info_lvl_0 = DF_info_lvl_0.drop_duplicates(subset = [\"Infected_ancestor\",\"index\",\"prophage_id\"] , keep = \"first\").reset_index(drop=True)\n",
    "\n",
    "# useful dictionary :\n",
    "KLtype_count = Counter(DF_info_lvl_0[\"KL_type_LCA\"])\n",
    "KLtype_pred = [kltype for kltype in KLtype_count if KLtype_count[kltype] >= 10]\n",
    "\n",
    "dico_prophage_kltype_associated = {}\n",
    "for negative_index,phage in tqdm(enumerate(DF_info_lvl_0[\"Phage\"].unique().tolist())) :\n",
    "    kltypes = set()\n",
    "    dpos = DF_info_lvl_0[DF_info_lvl_0[\"Phage\"] == phage][\"index\"]\n",
    "    for dpo in dpos : \n",
    "        tmp_kltypes = DF_info_lvl_0[DF_info_lvl_0[\"index\"] == dpo][\"KL_type_LCA\"].values\n",
    "        kltypes.update(tmp_kltypes)\n",
    "    dico_prophage_kltype_associated[phage] = kltypes\n",
    "\n",
    "depo_domains_seq = {index: domain_seq for index, domain_seq in zip(DF_info_lvl_0[\"index\"], DF_info_lvl_0['domain_seq'])}\n",
    "with open(f\"{path_work}/Dpo_domains.1710.multi.fasta\" , \"w\") as outfile : \n",
    "    for index,seq in depo_domains_seq.items() : \n",
    "        outfile.write(f\">{index}\\n{seq}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b174315a-5850-4b08-b28c-16fc203c3b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_threshold_done = {}\n",
    "\n",
    "names = [\"KLtype\", \"Count\",\"mcc\",\"F1\",\"recall\",\"accuracy\",\"AUC\"]\n",
    "\n",
    "for threshold in [0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 0.975] : \n",
    "    df_c = pd.read_csv(f\"{path_work}/RF_report.{threshold}.0702.tsv\", sep = \"\\t\", names = names)\n",
    "    done_kltypes = df_c[\"KLtype\"].tolist()\n",
    "    dico_threshold_done[str(threshold)] = done_kltypes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8454b36-eb52-4b92-90a1-461da557a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************************************************\n",
    "# CD hit step :\n",
    "\n",
    "path_multi_fasta = f\"{path_work}/Dpo_domains.1710.multi.fasta\"\n",
    "path_tmp_cdhit = f\"{path_work}/cdhit_clusters_1710\"\n",
    "\n",
    "def make_cdhit_cluster(threshold) :\n",
    "    cdhit_command = f\"cd-hit -i {path_multi_fasta} -o {path_tmp_cdhit}/{threshold}.out -c {threshold} -G 0 -aL 0.8\"\n",
    "    cdhit_process = subprocess.Popen(cdhit_command, shell =True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT) \n",
    "    scan_out, scan_err = cdhit_process.communicate()\n",
    "    print(scan_out, scan_err)\n",
    "    \n",
    "\n",
    "def make_cluster_dico(cdhit_out) :\n",
    "    import json\n",
    "    dico_cluster = {}\n",
    "    threshold = cdhit_out.split(\"/\")[-1].split(\".out\")[0]\n",
    "    cluster_file = f\"{cdhit_out}.clstr\"\n",
    "    cluster_out = open(cluster_file).read().split(\">Cluster\")\n",
    "    for index,cluster in enumerate(cluster_out[1:]) :\n",
    "        tmp_dpo = []\n",
    "        id_cluster = f\"Dpo_cdhit_{index}\"\n",
    "        for _,line in enumerate(cluster.split(\"\\n\")[1:-1]) :\n",
    "            dpo = line.split(\">\")[1].split(\".\")[0]\n",
    "            tmp_dpo.append(dpo)\n",
    "        dico_cluster[id_cluster] = tmp_dpo\n",
    "    with open(f\"{path_work}/dico_cluster.cdhit__{threshold}.json\", \"w\") as outfile:\n",
    "        json.dump(dico_cluster, outfile)\n",
    "    return dico_cluster , threshold\n",
    "\n",
    "def make_DF_binaries(df_info , dico_cluster, threshold) :\n",
    "    all_dpo_binaries = []\n",
    "    for phage in df_info.Phage.unique() :\n",
    "        dpo_binary = []\n",
    "        df_phage = df_info[df_info[\"Phage\"] == phage][\"index\"].values\n",
    "        for cluster,dpos in dico_cluster.items() :\n",
    "            shared_item = bool(set(dpos) & set(df_phage))\n",
    "            if shared_item == True :\n",
    "                dpo_binary.append(1)\n",
    "            else :\n",
    "                dpo_binary.append(0)\n",
    "        all_dpo_binaries.append(dpo_binary)\n",
    "    df_dpo_prophages = pd.DataFrame(all_dpo_binaries, index=df_info.Phage.unique(), columns=dico_cluster.keys())\n",
    "    df_dpo_prophages.to_csv(f\"{path_work}/DF_binaries_{threshold}.csv\", sep = \",\", index = True, header = True)\n",
    "\n",
    "    return df_dpo_prophages\n",
    "\n",
    "\n",
    "def make_DF_kltype(df_info, df ,KL_type , dico_cluster,ratio = 5, collapse = False) : \n",
    "    # positive data :\n",
    "    positive_phages = df_info[df_info[\"KL_type_LCA\"] == KL_type][\"Phage\"].unique()\n",
    "    df_positives = df[df.index.isin(positive_phages)]\n",
    "    #df_positives = df_positives.drop_duplicates(subset = [\"Phage\"] , keep = \"first\")\n",
    "    df_positives = df_positives[~df_positives.index.duplicated(keep='first')]\n",
    "    binaries_pos = df_positives.values\n",
    "    labels_pos = [1] * len(binaries_pos)\n",
    "    phages_pos = df_positives.index\n",
    "    # negative data :\n",
    "    n_samples = len(phages_pos)\n",
    "    negative_phages = []\n",
    "    for negative_index,phage in enumerate(df_info[\"Phage\"].unique().tolist()) :\n",
    "        if KL_type not in dico_prophage_kltype_associated[phage] :\n",
    "            negative_phages.append(phage)\n",
    "    negative_phages_selected = random.sample(negative_phages, int(n_samples*ratio))\n",
    "    df_negatives = df[df.index.isin(negative_phages_selected)]\n",
    "    binaries_neg = df_negatives.values\n",
    "    labels_neg = [0] * len(binaries_neg)\n",
    "\n",
    "    all_binaries = np.concatenate((binaries_pos, binaries_neg)) \n",
    "    all_labels = labels_pos + labels_neg\n",
    "    all_indices = list(phages_pos) + list(negative_phages_selected)\n",
    "\n",
    "    df_kl = pd.DataFrame(all_binaries, index=all_indices, columns=dico_cluster.keys())\n",
    "    if collapse == True :\n",
    "        dpo_presence = [dpo for dpo in df_kl.columns if sum(df_kl[dpo]) >0]\n",
    "        df_kl = df_kl[dpo_presence]\n",
    "    return (df_kl , all_labels)\n",
    "\n",
    "\n",
    "def fit_rf_model_random_search(df_kl , all_labels,KL_type, threshold):\n",
    "    n_iters = 100\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_kl, all_labels, test_size=0.3, random_state=243)\n",
    "    X_test, X_eval, y_test, y_eval = train_test_split(X_test, y_test, test_size=0.33, random_state=243)\n",
    "    param_grid = {\n",
    "        'bootstrap': Categorical([True, False]),\n",
    "        'max_depth': Integer(10, 100),\n",
    "        'max_features': Categorical(['auto', 'sqrt']),\n",
    "        'min_samples_leaf': Integer(1, 4),\n",
    "        'min_samples_split': Integer(2, 10),\n",
    "        'n_estimators': Integer(200, 800)\n",
    "    }\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    bayes_search = BayesSearchCV(rf, param_grid, n_iter=n_iters, cv=5, n_jobs=-1)\n",
    "    bayes_search.fit(X_train, y_train)\n",
    "    # Predicting with the best \n",
    "    predictions = bayes_search.predict(X_test)\n",
    "    report = classification_report(y_test, predictions, output_dict=True)\n",
    "    joblib.dump(bayes_search.best_estimator_, f'{path_models}/{threshold}_RF_{KL_type}.0702.joblib')\n",
    "    mcc = matthews_corrcoef(y_test, predictions)\n",
    "    auc = roc_auc_score(y_test, predictions)\n",
    "    return mcc , report , auc\n",
    "\n",
    "#list(map(make_cdhit_cluster , [0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 0.975]))\n",
    "cdhit_files = [f\"{path_tmp_cdhit}/{file}\" for file in os.listdir(path_tmp_cdhit) if file[-3:]==\"out\"]\n",
    "\n",
    "def make_prediction_file (path_file) :\n",
    "    dico_cluster , threshold = make_cluster_dico(f\"{path_file}\")\n",
    "    df_binaries = make_DF_binaries(DF_info_lvl_0 , dico_cluster, threshold)\n",
    "    for KL_type in KLtype_count :\n",
    "        if KL_type not in dico_threshold_done[threshold] :\n",
    "            with open(f\"{path_work}/RF_report.{threshold}.0702.tsv\", \"a+\") as outfile :\n",
    "                if KLtype_count[KL_type] < 5 :\n",
    "                    outfile.write(f\"{KL_type}\\t{KLtype_count[KL_type]}\\t***No sufficient Data\\n\")\n",
    "                else :\n",
    "                    df_kl , all_labels = make_DF_kltype(DF_info_lvl_0 ,df_binaries, KL_type , dico_cluster, collapse = False)\n",
    "                    mcc , report, auc = fit_rf_model_random_search(df_kl , all_labels, KL_type,threshold)\n",
    "                    outfile.write(f\"{KL_type}\\t{KLtype_count[KL_type]}\\t{mcc}\\t{report['1']['f1-score']}\\t{report['1']['recall']}\\t{report['accuracy']}\\t{auc}\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with ThreadPool(20) as p:\n",
    "        p.map(make_prediction_file, cdhit_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36f17ef-c53a-47ef-ad7d-009684ba3746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f83a3e7-3c2d-4209-a8de-e45bec397929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b243b91-0f2a-4a23-b452-16b160b6a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsync -avzhe ssh \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/Seqbased_model/RF_1912_models_info \\\n",
    "/media/concha-eloko/Linux/PPT_clean/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfd47f7-f2fb-4126-a438-5e1a36d6f60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/Seqbased_model/RF_1912_models\n",
    "/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/Seqbased_model/RF_2912_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae6d926-e685-4dd1-8118-0148bb4335b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsync -avzhe ssh \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/Seqbased_model/RF_2912_models \\\n",
    "/media/concha-eloko/Linux/PPT_clean/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_geometric",
   "language": "python",
   "name": "torch_geometric"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
