{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The final DpoDetection Tool :\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/concha-eloko/Linux/conda_envs/ML_work/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import torch\n",
    "from torch import nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "path_work = \"/media/concha-eloko/Linux/depolymerase_building\"\n",
    "\n",
    "esm2_model_path = f\"{path_work}/esm2_t12_35M_UR50D-finetuned-depolymerase.labels_4/checkpoint-6015\"\n",
    "DpoDetection_path = f\"{path_work}/DepoDetection.T12.4Labels.1908.model\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(esm2_model_path)\n",
    "esm2_finetuned = AutoModelForTokenClassification.from_pretrained(esm2_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dpo_classifier(nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super(Dpo_classifier, self).__init__()\n",
    "        self.max_length = 1024\n",
    "        self.pretrained_model = pretrained_model\n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size=5, stride=1)  # Convolutional layer\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, stride=1)  # Convolutional layer\n",
    "        self.fc1 = nn.Linear(128 * (self.max_length - 2 * (5 - 1)), 32)  # calculate the output shape after 2 conv layers\n",
    "        self.classifier = nn.Linear(32, 1)  # Binary classification\n",
    "\n",
    "    def make_prediction(self, fasta_txt):\n",
    "        input_ids = tokenizer.encode(fasta_txt, truncation=True, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            outputs = self.pretrained_model(input_ids)\n",
    "            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            token_probs, token_ids = torch.max(probs, dim=-1)            \n",
    "            tokens = token_ids.view(1, -1) # ensure 2D shape\n",
    "            return tokens\n",
    "\n",
    "    def pad_or_truncate(self, tokens):\n",
    "        if tokens.size(1) < self.max_length:\n",
    "            tokens = F.pad(tokens, (0, self.max_length - tokens.size(1)))\n",
    "        elif tokens.size(1) > self.max_length:\n",
    "            tokens = tokens[:, :self.max_length]\n",
    "        return tokens\n",
    "\n",
    "    def forward(self, sequences):\n",
    "        batch_size = len(sequences)\n",
    "        tokens_batch = []\n",
    "        for seq in sequences:\n",
    "            tokens = self.make_prediction(seq)\n",
    "            tokens = self.pad_or_truncate(tokens)\n",
    "            tokens_batch.append(tokens)\n",
    "        \n",
    "        outputs = torch.cat(tokens_batch).view(batch_size, 1, self.max_length)  # ensure 3D shape\n",
    "        outputs = outputs.float()  # Convert to float\n",
    "        \n",
    "        out = F.relu(self.conv1(outputs))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = out.view(batch_size, -1)  # Flatten the tensor\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.classifier(out)\n",
    "        return out, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dpo_classifier(\n",
       "  (pretrained_model): EsmForTokenClassification(\n",
       "    (esm): EsmModel(\n",
       "      (embeddings): EsmEmbeddings(\n",
       "        (word_embeddings): Embedding(33, 480, padding_idx=1)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (position_embeddings): Embedding(1026, 480, padding_idx=1)\n",
       "      )\n",
       "      (encoder): EsmEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x EsmLayer(\n",
       "            (attention): EsmAttention(\n",
       "              (self): EsmSelfAttention(\n",
       "                (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "                (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "                (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (rotary_embeddings): RotaryEmbedding()\n",
       "              )\n",
       "              (output): EsmSelfOutput(\n",
       "                (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (intermediate): EsmIntermediate(\n",
       "              (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            )\n",
       "            (output): EsmOutput(\n",
       "              (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (emb_layer_norm_after): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (contact_head): EsmContactPredictionHead(\n",
       "        (regression): Linear(in_features=240, out_features=1, bias=True)\n",
       "        (activation): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (classifier): Linear(in_features=480, out_features=4, bias=True)\n",
       "  )\n",
       "  (conv1): Conv1d(1, 64, kernel_size=(5,), stride=(1,))\n",
       "  (conv2): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
       "  (fc1): Linear(in_features=130048, out_features=32, bias=True)\n",
       "  (classifier): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classifier = Dpo_classifier(esm2_finetuned) # Create an instance of Dpo_classifier\n",
    "model_classifier.load_state_dict(torch.load(DpoDetection_path), strict = False) # Load the saved weights ; weird Error with some of the keys \n",
    "model_classifier.eval() # Set the model to evaluation mode for inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence(model, sequence):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        sequence = [sequence]  # Wrap the sequence in a list to match the model's input format\n",
    "        outputs, sequence_outputs = model(sequence)\n",
    "        probas = torch.sigmoid(outputs)  # Apply sigmoid activation for binary classification\n",
    "        predictions = (probas > 0.5).float()  # Convert probabilities to binary predictions\n",
    "        sequence_outputs_list = sequence_outputs.cpu().numpy().tolist()[0][0]\n",
    "        prob_predicted = probas[0].item()\n",
    "        return (predictions.item(), prob_predicted), sequence_outputs_list\n",
    "\n",
    "\n",
    "def plot_token(tokens) :\n",
    "    tokens = np.array(tokens)  # convert your list to numpy array for convenience\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for i in range(len(tokens) - 1):\n",
    "        if tokens[i] == 0:\n",
    "            color = 'black'\n",
    "        elif tokens[i] == 1:\n",
    "            color = 'blue'\n",
    "        elif tokens[i] == 2:\n",
    "            color = 'red'\n",
    "        else :\n",
    "            color = 'green'\n",
    "        plt.plot([i, i+1], [tokens[i], tokens[i+1]], color=color, marker='o')\n",
    "    plt.xlabel('Token')\n",
    "    plt.ylabel('Label')\n",
    "    plt.title('Label for each token')\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.yticks(np.arange(2), ['0', '1'])  \n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Predictions Bea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Make predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_out = \"/media/concha-eloko/Linux/PPT_clean/in_vitro/Bea/genomes\"\n",
    "from Bio import SeqIO\n",
    "from tqdm import tqdm \n",
    "\n",
    "prediction_results = {}\n",
    "for fasta_file in tqdm(os.listdir(path_out)) :\n",
    "    fastas = SeqIO.parse(f\"{path_out}/{fasta_file}\" , \"fasta\")\n",
    "    tmp_results = []\n",
    "    for record in fastas :\n",
    "        if len(record.seq) >= 200 :\n",
    "            protein_seq = record.seq.translate()\n",
    "            prediction, sequence_outputs = predict_sequence(model_classifier, str(protein_seq))\n",
    "            if prediction[0] == 1 :\n",
    "                a = (prediction , record.description)\n",
    "                tmp_results.append(a)\n",
    "            else :\n",
    "                pass\n",
    "    prediction_results[fasta_file] = tmp_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Save / Open predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO\n",
    "\n",
    "path_bea = \"/media/concha-eloko/Linux/PPT_clean/in_vitro/Bea\"\n",
    "\n",
    "#dpos = set([prot_id[1] for file in prediction_results for prot_id in prediction_results[file]])\n",
    "\n",
    "#with open(\"/media/concha-eloko/Linux/PPT_clean/in_vitro/Bea/DepoScope_predictions.tsv\", \"w\") as outfile : \n",
    "#    for dpo in dpos :\n",
    "#        outfile.write(dpo + \"\\n\")\n",
    "\n",
    "dpos = open(\"/media/concha-eloko/Linux/PPT_clean/in_vitro/Bea/DepoScore.adjusted_boundaries.tsv\").read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lcl|ON602737.1_cds_UVX30183.1_55 [locus_tag=S13c_00055] [protein=tail fiber protein] [protein_id=UVX30183.1] [location=complement(28158..31880)] [gbkey=CDS]\\t(170, 625)\\t1',\n",
       " 'lcl|ON602746.1_cds_UVX30809.1_96 [locus_tag=S10a_00097] [protein=tail fiber protein] [protein_id=UVX30809.1] [location=complement(51532..53505)] [gbkey=CDS]\\t(206, 529)\\tc',\n",
       " 'lcl|ON602724.1_cds_UVX29033.1_41 [locus_tag=A1o_00041] [protein=tail protein] [protein_id=UVX29033.1] [location=26268..28628] [gbkey=CDS]\\t(286, 577)\\tx',\n",
       " 'lcl|ON602724.1_cds_UVX29037.1_45 [locus_tag=A1o_00045] [protein=tail fiber protein] [protein_id=UVX29037.1] [location=35670..38012] [gbkey=CDS]\\t(319, 648)\\tc',\n",
       " 'lcl|ON602748.1_cds_UVX30914.1_34 [locus_tag=A1c_00034] [protein=tail fiber protein] [protein_id=UVX30914.1] [location=complement(21949..23904)] [gbkey=CDS]\\t(90, 570)\\tc',\n",
       " 'lcl|ON602748.1_cds_UVX30926.1_46 [locus_tag=A1c_00046] [protein=tail protein] [protein_id=UVX30926.1] [location=complement(35881..38196)] [gbkey=CDS]\\t(277, 562)\\tx',\n",
       " 'lcl|ON602762.1_cds_UVX31810.1_9 [locus_tag=A1d_00009] [protein=tail fiber protein] [protein_id=UVX31810.1] [location=complement(4314..6797)] [gbkey=CDS]\\t(304, 690)\\tc',\n",
       " 'lcl|ON602762.1_cds_UVX31814.1_13 [locus_tag=A1d_00013] [protein=tail protein] [protein_id=UVX31814.1] [location=complement(13839..16199)] [gbkey=CDS]\\t(285, 577)\\tx',\n",
       " 'lcl|ON602726.1_cds_UVX29113.1_10 [locus_tag=A1q_00010] [protein=tail spike protein] [protein_id=UVX29113.1] [location=complement(4324..5277)] [gbkey=CDS]\\t(0, 329)\\tx',\n",
       " 'lcl|ON602726.1_cds_UVX29122.1_19 [locus_tag=A1q_00019] [protein=tail fiber protein] [protein_id=UVX29122.1] [location=complement(9429..11804)] [gbkey=CDS]\\t(314, 656)\\tc',\n",
       " 'lcl|ON602726.1_cds_UVX29126.1_23 [locus_tag=A1q_00023] [protein=tail protein] [protein_id=UVX29126.1] [location=complement(18846..21206)] [gbkey=CDS]\\t(285, 577)\\tx',\n",
       " 'lcl|ON602725.1_cds_UVX29055.1_9 [locus_tag=A1r_00009] [protein=tail fiber protein] [protein_id=UVX29055.1] [location=complement(4472..6814)] [gbkey=CDS]\\t(320, 648)\\tc',\n",
       " 'lcl|ON602725.1_cds_UVX29059.1_13 [locus_tag=A1r_00013] [protein=tail protein] [protein_id=UVX29059.1] [location=complement(13856..16216)] [gbkey=CDS]\\t(285, 577)\\tx',\n",
       " 'lcl|ON602749.1_cds_UVX30943.1_11 [locus_tag=P4a_00011] [protein=tail protein] [protein_id=UVX30943.1] [location=5844..8408] [gbkey=CDS]\\t(363, 661)\\tc',\n",
       " 'lcl|ON602749.1_cds_UVX30945.1_13 [locus_tag=P4a_00013] [protein=tail protein] [protein_id=UVX30945.1] [location=8688..11204] [gbkey=CDS]\\t(175, 524)\\tor (175, 691)',\n",
       " 'lcl|ON602756.1_cds_UVX31408.1_12 [locus_tag=A1f_00012] [protein=tail fiber protein] [protein_id=UVX31408.1] [location=complement(6684..8438)] [gbkey=CDS]\\t(117, 401)\\tc',\n",
       " 'lcl|ON602756.1_cds_UVX31420.1_24 [locus_tag=A1f_00024] [protein=tail protein] [protein_id=UVX31420.1] [location=complement(20395..22755)] [gbkey=CDS]\\t(293, 579)\\tx',\n",
       " 'lcl|ON602761.1_cds_UVX31789.1_45 [locus_tag=A1g_00045] [protein=tail protein] [protein_id=UVX31789.1] [location=27287..29647] [gbkey=CDS]\\t(289, 577)\\tx',\n",
       " 'lcl|ON602761.1_cds_UVX31801.1_57 [locus_tag=A1g_00057] [protein=tail spike protein] [protein_id=UVX31801.1] [location=41625..43403] [gbkey=CDS]\\t(45, 506)\\tc',\n",
       " 'lcl|ON602742.1_cds_UVX30492.1_16 [locus_tag=A3b_00016] [protein=tail protein] [protein_id=UVX30492.1] [location=9964..12339] [gbkey=CDS]\\t(283, 578)\\tx',\n",
       " 'lcl|ON602742.1_cds_UVX30497.1_21 [locus_tag=A3b_00021] [protein=tail protein] [protein_id=UVX30497.1] [location=19715..22093] [gbkey=CDS]\\t(322, 658)\\tc',\n",
       " 'lcl|ON602754.1_cds_UVX31298.1_2 [locus_tag=A1j_00002] [protein=tail protein] [protein_id=UVX31298.1] [location=complement(1418..3778)] [gbkey=CDS]\\t(286, 577)\\tx',\n",
       " 'lcl|ON602754.1_cds_UVX31336.1_40 [locus_tag=A1j_00040] [protein=tail fiber protein] [protein_id=UVX31336.1] [location=complement(29581..31851)] [gbkey=CDS]\\t(30, 630)\\tc',\n",
       " 'lcl|ON602754.1_cds_UVX31345.1_49 [locus_tag=A1j_00049] [protein=tail fiber protein] [protein_id=UVX31345.1] [location=complement(36016..38412)] [gbkey=CDS]\\t(320, 654)\\tc',\n",
       " 'lcl|ON602763.1_cds_UVX31864.1_10 [locus_tag=A2a_00010] [protein=tail protein] [protein_id=UVX31864.1] [location=complement(11758..14142)] [gbkey=CDS]\\t(307, 583)\\tx',\n",
       " 'lcl|ON602763.1_cds_UVX31903.1_49 [locus_tag=A2a_00049] [protein=tail fiber protein] [protein_id=UVX31903.1] [location=complement(41220..43532)] [gbkey=CDS]\\t(65, 627)\\tc',\n",
       " 'lcl|ON602727.1_cds_UVX29207.1_45 [locus_tag=A1m_00045] [protein=tail protein] [protein_id=UVX29207.1] [location=27634..29994] [gbkey=CDS]\\t(285, 577)\\tx',\n",
       " 'lcl|ON602727.1_cds_UVX29211.1_49 [locus_tag=A1m_00049] [protein=tail fiber protein] [protein_id=UVX29211.1] [location=37035..39377] [gbkey=CDS]\\t(320, 648)\\tc',\n",
       " 'lcl|ON602750.1_cds_UVX31064.1_43 [locus_tag=D7b_00043] [protein=tail fiber protein] [protein_id=UVX31064.1] [location=22093..24474] [gbkey=CDS]\\t(304, 604)\\tc',\n",
       " 'lcl|ON602728.1_cds_UVX29269.1_50 [locus_tag=A1n_00050] [protein=tail protein] [protein_id=UVX29269.1] [location=31872..34130] [gbkey=CDS]\\t(251, 543)\\tx',\n",
       " 'lcl|ON602723.1_cds_UVX28987.1_55 [locus_tag=A1p_00055] [protein=tail protein] [protein_id=UVX28987.1] [location=32970..35228] [gbkey=CDS]\\t(251, 543)\\tx',\n",
       " 'lcl|ON602753.1_cds_UVX31285.1_36 [locus_tag=A3d_00036] [protein=tail protein] [protein_id=UVX31285.1] [location=22885..25260] [gbkey=CDS]\\t(283, 579)\\tx',\n",
       " 'lcl|ON602753.1_cds_UVX31290.1_41 [locus_tag=A3d_00041] [protein=tail protein] [protein_id=UVX31290.1] [location=32636..35590] [gbkey=CDS]\\t(331, 940)\\tc',\n",
       " 'lcl|ON602753.1_cds_UVX31291.1_42 [locus_tag=A3d_00042] [protein=hypothetical protein] [protein_id=UVX31291.1] [location=35609..37252] [gbkey=CDS]\\t(65, 383)\\tc',\n",
       " 'lcl|ON602738.1_cds_UVX30242.1_34 [locus_tag=S13a_00036] [protein=tail fiber protein] [protein_id=UVX30242.1] [location=21283..25005] [gbkey=CDS]\\t(280, 625)\\tor (280,1110)',\n",
       " 'lcl|ON602755.1_cds_UVX31386.1_39 [locus_tag=A3c_00039] [protein=tail protein] [protein_id=UVX31386.1] [location=23812..26205] [gbkey=CDS]\\t(289, 584)\\tx',\n",
       " 'lcl|ON602755.1_cds_UVX31391.1_44 [locus_tag=A3c_00044] [protein=tail fiber protein] [protein_id=UVX31391.1] [location=33598..36225] [gbkey=CDS]\\t(385, 683)\\tc',\n",
       " 'lcl|ON602755.1_cds_UVX31392.1_45 [locus_tag=A3c_00045] [protein=hypothetical protein] [protein_id=UVX31392.1] [location=36235..37875] [gbkey=CDS]\\t(60, 387)\\tc',\n",
       " 'lcl|ON602740.1_cds_UVX30347.1_5 [locus_tag=A1l_00005] [protein=tail protein] [protein_id=UVX30347.1] [location=complement(8381..10741)] [gbkey=CDS]\\t(287, 577)\\tx',\n",
       " 'lcl|ON602740.1_cds_UVX30400.1_58 [locus_tag=A1l_00058] [protein=tail fiber protein] [protein_id=UVX30400.1] [location=complement(42405..43229)] [gbkey=CDS]\\t(0, 151)\\t1',\n",
       " 'lcl|ON602733.1_cds_UVX29715.1_2 [locus_tag=A3a_00002] [protein=tail protein] [protein_id=UVX29715.1] [location=1548..4493] [gbkey=CDS]\\t(321, 983)\\tc',\n",
       " 'lcl|ON602733.1_cds_UVX29758.1_45 [locus_tag=A3a_00045] [protein=tail protein] [protein_id=UVX29758.1] [location=32132..34498] [gbkey=CDS]\\t(284, 577)\\tx',\n",
       " 'lcl|ON602765.1_cds_UVX31968.1_8 [locus_tag=A2b_00008] [protein=tail fiber protein] [protein_id=UVX31968.1] [location=complement(6907..9219)] [gbkey=CDS]\\t(72, 628)\\tc',\n",
       " 'lcl|ON602765.1_cds_UVX31982.1_22 [locus_tag=A2b_00022] [protein=tail protein] [protein_id=UVX31982.1] [location=complement(22541..24925)] [gbkey=CDS]\\t(295, 583)\\tx',\n",
       " 'lcl|ON602736.1_cds_UVX30045.1_147 [locus_tag=M5a_00170] [protein=tail spike protein] [protein_id=UVX30045.1] [location=86523..88430] [gbkey=CDS]\\t(100, 508)\\tc',\n",
       " 'lcl|ON602736.1_cds_UVX30050.1_152 [locus_tag=M5a_00175] [protein=tail fiber protein] [protein_id=UVX30050.1] [location=96188..97225] [gbkey=CDS]\\t(181, 233)\\tx',\n",
       " 'lcl|ON602736.1_cds_UVX30096.1_198 [locus_tag=M5a_00221] [protein=hypothetical protein] [protein_id=UVX30096.1] [location=complement(125811..126230)] [gbkey=CDS]\\t(8, 141)\\tx',\n",
       " 'lcl|ON602752.1_cds_UVX31228.1_36 [locus_tag=A1b_00036] [protein=tail protein] [protein_id=UVX31228.1] [location=22532..24898] [gbkey=CDS]\\t(304, 580)\\tx',\n",
       " 'lcl|ON602752.1_cds_UVX31240.1_48 [locus_tag=A1b_00048] [protein=tail fiber protein] [protein_id=UVX31240.1] [location=36872..38674] [gbkey=CDS]\\t(128, 442)\\tc',\n",
       " 'lcl|ON602757.1_cds_UVX31465.1_12 [locus_tag=A1e_00012] [protein=tail fiber protein] [protein_id=UVX31465.1] [location=complement(6743..8497)] [gbkey=CDS]\\t(75, 401)\\tx',\n",
       " 'lcl|ON602757.1_cds_UVX31477.1_24 [locus_tag=A1e_00024] [protein=tail protein] [protein_id=UVX31477.1] [location=complement(20454..22814)] [gbkey=CDS]\\t(293, 579)\\tx',\n",
       " 'lcl|ON602745.1_cds_UVX30692.1_36 [locus_tag=S11a_00036] [protein=tail fiber protein] [protein_id=UVX30692.1] [location=complement(19886..21787)] [gbkey=CDS]\\t(186, 506)\\tc',\n",
       " 'lcl|ON602732.1_cds_UVX29661.1_2 [locus_tag=A1a_00002] [protein=tail protein] [protein_id=UVX29661.1] [location=562..2943] [gbkey=CDS]\\t(291, 584)\\tx',\n",
       " 'lcl|ON602732.1_cds_UVX29673.1_14 [locus_tag=A1a_00014] [protein=hypothetical protein] [protein_id=UVX29673.1] [location=14914..16896] [gbkey=CDS]\\t(81, 367)\\tx',\n",
       " 'lcl|ON602751.1_cds_UVX31118.1_20 [locus_tag=P4b_00023] [protein=tail protein] [protein_id=UVX31118.1] [location=complement(27849..30365)] [gbkey=CDS]\\t(170, 540)\\tor (170,682)',\n",
       " 'lcl|ON602751.1_cds_UVX31120.1_22 [locus_tag=P4b_00025] [protein=tail protein] [protein_id=UVX31120.1] [location=complement(30645..33209)] [gbkey=CDS]\\t(364, 661)\\tx',\n",
       " 'lcl|ON602759.1_cds_UVX31607.1_21 [locus_tag=S13e_00021] [protein=tail fiber protein] [protein_id=UVX31607.1] [location=14101..16419] [gbkey=CDS]\\t(255, 774)\\tc',\n",
       " 'lcl|ON602760.1_cds_UVX31720.1_56 [locus_tag=S13d_00057] [protein=tail fiber protein] [protein_id=UVX31720.1] [location=29391..32099] [gbkey=CDS]\\t(191, 795)\\tc',\n",
       " 'lcl|ON602743.1_cds_UVX30533.1_9 [locus_tag=A1h_00009] [protein=tail protein] [protein_id=UVX30533.1] [location=7263..9623] [gbkey=CDS]\\t(287, 577)\\tx',\n",
       " 'lcl|ON602743.1_cds_UVX30537.1_13 [locus_tag=A1h_00013] [protein=tail fiber protein] [protein_id=UVX30537.1] [location=16665..19211] [gbkey=CDS]\\t(397, 767)\\tc',\n",
       " 'lcl|ON602743.1_cds_UVX30545.1_21 [locus_tag=A1h_00021] [protein=tail protein] [protein_id=UVX30545.1] [location=23181..24914] [gbkey=CDS]\\t(116, 423)\\tc',\n",
       " 'lcl|ON602739.1_cds_UVX30300.1_14 [locus_tag=A1k_00014] [protein=tail fiber protein] [protein_id=UVX30300.1] [location=complement(7073..9415)] [gbkey=CDS]\\t(319, 647)\\tc',\n",
       " 'lcl|ON602739.1_cds_UVX30304.1_18 [locus_tag=A1k_00018] [protein=tail protein] [protein_id=UVX30304.1] [location=complement(16456..18816)] [gbkey=CDS]\\t(286, 577)\\tx',\n",
       " 'lcl|ON602735.1_cds_UVX29830.1_7 [locus_tag=D7c_00007] [protein=tail fiber protein] [protein_id=UVX29830.1] [location=6265..8493] [gbkey=CDS]\\t(300, 587)\\tc',\n",
       " 'lcl|ON602744.1_cds_UVX30633.1_56 [locus_tag=S13b_00058] [protein=tail protein] [protein_id=UVX30633.1] [location=30249..32648] [gbkey=CDS]\\t(205, 639)\\tc',\n",
       " 'lcl|ON602729.1_cds_UVX29306.1_32 [locus_tag=M5b_00032] [protein=hypothetical protein] [protein_id=UVX29306.1] [location=15095..15502] [gbkey=CDS]\\t(10, 137)\\t(10, 137)',\n",
       " 'lcl|ON602729.1_cds_UVX29360.1_86 [locus_tag=M5b_00086] [protein=tail fiber protein] [protein_id=UVX29360.1] [location=complement(51837..53558)] [gbkey=CDS]\\t(112, 441)\\tc',\n",
       " 'lcl|ON602758.1_cds_UVX31542.1_31 [locus_tag=M12a_00031] [protein=tail protein] [protein_id=UVX31542.1] [location=complement(17974..20442)] [gbkey=CDS]\\t(261, 615)\\tc',\n",
       " 'lcl|ON602764.1_cds_UVX31929.1_22 [locus_tag=A2a_b_00022] [protein=tail fiber protein] [protein_id=UVX31929.1] [location=complement(15484..17796)] [gbkey=CDS]\\t(34, 650)\\tc',\n",
       " 'lcl|ON602764.1_cds_UVX31943.1_36 [locus_tag=A2a_b_00036] [protein=tail protein] [protein_id=UVX31943.1] [location=complement(31119..33503)] [gbkey=CDS]\\t(304, 583)\\tx',\n",
       " 'lcl|ON602767.1_cds_UVX32108.1_37 [locus_tag=A1i_00037] [protein=tail protein] [protein_id=UVX32108.1] [location=24618..26978] [gbkey=CDS]\\t(290, 577)\\tx',\n",
       " 'lcl|ON602767.1_cds_UVX32112.1_41 [locus_tag=A1i_00041] [protein=tail fiber protein] [protein_id=UVX32112.1] [location=34020..36566] [gbkey=CDS]\\t(397, 769)\\tc',\n",
       " 'lcl|ON602767.1_cds_UVX32120.1_49 [locus_tag=A1i_00049] [protein=tail fiber protein] [protein_id=UVX32120.1] [location=40536..42806] [gbkey=CDS]\\t(40, 632)\\tc',\n",
       " '']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S13c_00055',\n",
       " 'S10a_00097',\n",
       " 'A1o_00041',\n",
       " 'A1o_00045',\n",
       " 'A1c_00034',\n",
       " 'A1c_00046',\n",
       " 'A1d_00009',\n",
       " 'A1d_00013',\n",
       " 'A1q_00010',\n",
       " 'A1q_00019',\n",
       " 'A1q_00023',\n",
       " 'A1r_00009',\n",
       " 'A1r_00013',\n",
       " 'P4a_00011',\n",
       " 'P4a_00013',\n",
       " 'A1f_00012',\n",
       " 'A1f_00024',\n",
       " 'A1g_00045',\n",
       " 'A1g_00057',\n",
       " 'A3b_00016',\n",
       " 'A3b_00021',\n",
       " 'A1j_00002',\n",
       " 'A1j_00040',\n",
       " 'A1j_00049',\n",
       " 'A2a_00010',\n",
       " 'A2a_00049',\n",
       " 'A1m_00045',\n",
       " 'A1m_00049',\n",
       " 'D7b_00043',\n",
       " 'A1n_00050',\n",
       " 'A1p_00055',\n",
       " 'A3d_00036',\n",
       " 'A3d_00041',\n",
       " 'A3d_00042',\n",
       " 'S13a_00036',\n",
       " 'A3c_00039',\n",
       " 'A3c_00044',\n",
       " 'A3c_00045',\n",
       " 'A1l_00005',\n",
       " 'A1l_00058',\n",
       " 'A3a_00002',\n",
       " 'A3a_00045',\n",
       " 'A2b_00008',\n",
       " 'A2b_00022',\n",
       " 'M5a_00170',\n",
       " 'M5a_00175',\n",
       " 'M5a_00221',\n",
       " 'A1b_00036',\n",
       " 'A1b_00048',\n",
       " 'A1e_00012',\n",
       " 'A1e_00024',\n",
       " 'S11a_00036',\n",
       " 'A1a_00002',\n",
       " 'A1a_00014',\n",
       " 'P4b_00023',\n",
       " 'P4b_00025',\n",
       " 'S13e_00021',\n",
       " 'S13d_00057',\n",
       " 'A1h_00009',\n",
       " 'A1h_00013',\n",
       " 'A1h_00021',\n",
       " 'A1k_00014',\n",
       " 'A1k_00018',\n",
       " 'D7c_00007',\n",
       " 'S13b_00058',\n",
       " 'M5b_00032',\n",
       " 'M5b_00086',\n",
       " 'M12a_00031',\n",
       " 'A2a_b_00022',\n",
       " 'A2a_b_00036',\n",
       " 'A1i_00037',\n",
       " 'A1i_00041',\n",
       " 'A1i_00049']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpos\n",
    "\n",
    "prot_ids = [hit.split(\"locus_tag=\")[1].split(\"]\")[0] for hit in dpos if hit]\n",
    "prot_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Get folds :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 46/46 [01:39<00:00,  2.16s/it]\n"
     ]
    }
   ],
   "source": [
    "path_out = \"/media/concha-eloko/Linux/PPT_clean/in_vitro/Bea/genomes\"\n",
    "from Bio import SeqIO\n",
    "from tqdm import tqdm \n",
    "from collections import Counter\n",
    "\n",
    "prediction_results = {}\n",
    "for fasta_file in tqdm(os.listdir(path_out)) :\n",
    "    fastas = SeqIO.parse(f\"{path_out}/{fasta_file}\" , \"fasta\")\n",
    "    tmp_results = []\n",
    "    for record in fastas :\n",
    "        protein_seq = str(record.seq[0:-1].translate())\n",
    "        prot_id = record.description.split(\"locus_tag=\")[1].split(\"]\")[0]\n",
    "        if prot_id in prot_ids :\n",
    "            prediction, sequence_outputs = predict_sequence(model_classifier, protein_seq)\n",
    "            a = (prot_id , dict(Counter(sequence_outputs)))\n",
    "            tmp_results.append(a)\n",
    "    prediction_results[fasta_file] = tmp_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_label = {1.0 : \"right-handed beta-helix\", 2.0 : \"6-bladed beta-propeller\", 3.0 : \"triple-helix\"}\n",
    "fold_dpoes = {}\n",
    "\n",
    "for genome in prediction_results :\n",
    "    if len(prediction_results[genome]) > 0 :\n",
    "        for dpo in prediction_results[genome] :\n",
    "            for label in dpo[1] : \n",
    "                if label in folds_label :\n",
    "                    fold = folds_label[label]\n",
    "                    fold_dpoes[dpo[0]] = fold\n",
    "                    break\n",
    "\n",
    "with open(f\"/media/concha-eloko/Linux/PPT_clean/in_vitro/Bea/dpos_folds.bea.tsv\", \"w\") as outfile : \n",
    "    outfile.write(f\"protein_id\\tFold\\n\")\n",
    "    for protein,fold in fold_dpoes.items():\n",
    "        outfile.write(f\"{protein}\\t{fold}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boundaries_bea = {}\n",
    "for fasta_file in os.listdir(f\"{path_bea}/genomes\") :\n",
    "    multi_fasta = SeqIO.parse(f\"{path_bea}/genomes/{fasta_file}\" , \"fasta\")\n",
    "    for record in multi_fasta :\n",
    "        if record.description in dpos : \n",
    "            if len(record.seq) >= 200 :\n",
    "                protein_seq = record.seq.translate()\n",
    "                prediction, sequence_outputs = predict_sequence(model_classifier, str(protein_seq))\n",
    "                #print(record.description, sequence_outputs, sep = \"\\n\")\n",
    "                boundaries = find_longest_non_zero_suite_with_n_zeros(sequence_outputs , 10)\n",
    "                boundaries_bea[record.description] = boundaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{path_bea}/DepoScope.raw_boundaries.tsv\" , \"w\") as outfile :\n",
    "    for protein in boundaries_bea :\n",
    "        outfile.write(f\"{protein}\\t{boundaries_bea[protein]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Check the differences between the calls made by DepoScope and Bea's report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dpos = [prot_id[1].split(\"locus_tag=\")[1].split(\"]\")[0] for file in prediction_results for prot_id in prediction_results[file]]\n",
    "\n",
    "path_pdb = \"/media/concha-eloko/Linux/PPT_clean/in_vitro/Bea/pdb_depolymerase_proteins_Bea\"\n",
    "\n",
    "deposcope_plus = []\n",
    "for dpo in dpos : \n",
    "    if f\"{dpo}.pdb\" not in os.listdir(path_pdb) :\n",
    "        deposcope_plus.append(dpo)\n",
    "\n",
    "for dpo in deposcope_plus : \n",
    "    print(dpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "deposcope_forgotten = []\n",
    "for dpo_pdb in os.listdir(path_pdb) :\n",
    "    if dpo_pdb.split(\".pdb\")[0] not in dpos :\n",
    "        deposcope_forgotten.append(dpo_pdb.split(\".pdb\")[0])\n",
    "\n",
    "len(deposcope_forgotten) , len(os.listdir(path_pdb)) , len(dpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deposcope_forgotten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Get the plots for each dpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for fasta_file in tqdm(os.listdir(path_out)) :\n",
    "    fastas = SeqIO.parse(f\"{path_out}/{fasta_file}\" , \"fasta\")\n",
    "    tmp_results = []\n",
    "    for record in fastas :\n",
    "        if record.description.split(\"locus_tag=\")[1].split(\"]\")[0] in dpos :\n",
    "            print(record.description)\n",
    "            protein_seq = record.seq.translate()\n",
    "            prediction, sequence_outputs = predict_sequence(model_classifier, str(protein_seq))\n",
    "            plot_token(sequence_outputs)\n",
    "            print(sequence_outputs)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"/media/concha-eloko/Linux/PPT_clean/in_vitro/Bea/DepoScope_plus.sequences.fasta\" , \"w\") as outfile :\n",
    "    for fasta_file in tqdm(os.listdir(path_out)) :\n",
    "        fastas = SeqIO.parse(f\"{path_out}/{fasta_file}\" , \"fasta\")\n",
    "        tmp_results = []\n",
    "        for record in fastas :\n",
    "            if record.description.split(\"locus_tag=\")[1].split(\"]\")[0] in deposcope_plus :\n",
    "                locus_tag = record.description.split(\"locus_tag=\")[1].split(\"]\")[0] \n",
    "                protein_seq = record.seq.translate()\n",
    "                if len(protein_seq) >= 200 :\n",
    "                    outfile.write(f\">{locus_tag}\\n{protein_seq}\\n\")\n",
    "                    print(record.description)\n",
    "                    prediction, sequence_outputs = predict_sequence(model_classifier, str(protein_seq))\n",
    "                    plot_token(sequence_outputs)\n",
    "                    print(protein_seq)\n",
    "                    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def find_longest_non_zero_suite_with_n_zeros(lst, n):\n",
    "    # Initialize variables to keep track of the longest suite\n",
    "    longest_start, longest_end = 0, 0\n",
    "    longest_length = 0\n",
    "    # Initialize variables to keep track of the current suite\n",
    "    current_start = 0\n",
    "    current_length = 0\n",
    "    current_zeros = 0\n",
    "    for i, num in enumerate(lst):\n",
    "        if num == 0:\n",
    "            # Increment the count of zeros in the current suite\n",
    "            current_zeros += 1\n",
    "            # If the number of zeros exceeds n, update the current start index and length\n",
    "            while current_zeros > n:\n",
    "                if lst[current_start] == 0:\n",
    "                    current_zeros -= 1\n",
    "                current_start += 1\n",
    "                current_length -= 1\n",
    "        # Increment the length of the current suite\n",
    "        current_length += 1\n",
    "        # Check if the current suite is longer than the longest suite found so far\n",
    "        if current_length > longest_length:\n",
    "            longest_start = current_start\n",
    "            longest_end = i\n",
    "            longest_length = current_length\n",
    "    return (longest_start, longest_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test_labeled_tokens = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "test_labeled_tokens = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "\n",
    "\n",
    "test_labeled_tokens = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "find_longest_non_zero_suite_with_n_zeros(test_labeled_tokens , 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Run the T30 on the server for the best boundary predictions : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{path_bea}/DepoScope_predictions.bea.full_seq.0709.fasta\" , \"w\") as outfile :\n",
    "    for fasta_file in tqdm(os.listdir(f\"{path_bea}/genomes\")) :\n",
    "        multi_fasta = SeqIO.parse(f\"{path_bea}/genomes/{fasta_file}\" , \"fasta\")\n",
    "        for record in multi_fasta :\n",
    "            locus_tag = record.description.split(\"locus_tag=\")[1].split(\"]\")[0]\n",
    "            protein_seq = record.seq.translate()[0:-1]\n",
    "            if record.description in dposcope_df[\"protein_description\"].to_list() : \n",
    "                if len(protein_seq) >= 200 :\n",
    "                    outfile.write(f\">{locus_tag}\\n{protein_seq}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsync -avzhe ssh \\\n",
    "/media/concha-eloko/Linux/PPT_clean/in_vitro/Bea/DepoScope_predictions.bea.full_seq.0709.fasta \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/PhageDepo_pdb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fasta = \"/home/conchae/PhageDepo_pdb\"\n",
    "\n",
    "fasta_seq = SeqIO.parse(f\"{path_fasta}/DepoScope_predictions.bea.full_seq.0709.fasta\" , \"fasta\")\n",
    "for record in fasta_seq :\n",
    "    sequence , prot_name = str(record.seq) , record.description\n",
    "    prediction, sequence_outputs = predict_sequence(model_classifier, sequence)\n",
    "    if prediction[0] == 1 :\n",
    "        start , end = find_longest_non_zero_suite_with_n_zeros(sequence_outputs, 10)\n",
    "        with open(f\"{path_fasta}/Bea_big_predictions.tsv\" , \"a+\") as outfile :\n",
    "            outfile.write(f\"{prot_name}\\t{start},{end}\\t{sequence[int(start) : int(end)]}\\t{sequence}\\n\")\n",
    "\n",
    "#!/bin/bash\n",
    "#BATCH --job-name=Bea_T30__\n",
    "#SBATCH --qos=short \n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=5\n",
    "#SBATCH --mem=20gb \n",
    "#SBATCH --time=1-00:00:00 \n",
    "#SBATCH --output=Bea_T30__%j.log \n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate embeddings\n",
    "\n",
    "python /home/conchae/PhageDepo_pdb/script_files/deposcope_beaphages.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsync -avzhe ssh \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/DepoScope_predictions.bea.domains.0709.fasta.out \\\n",
    "/media/concha-eloko/Linux/PPT_clean/in_vitro/Bea \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## ESMfold on the unpredicted ones : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO\n",
    "import pandas as pd \n",
    "import DepoScope_functions\n",
    "\n",
    "path_bea = \"/media/concha-eloko/Linux/PPT_clean/in_vitro/Bea\"\n",
    "\n",
    "dposcope_df = pd.read_csv(f\"{path_bea}/DepoScore.adjusted_boundaries.tsv\" , sep = \"\\t\", names = [\"protein_description\",\"boundaries\",\"type\"])\n",
    "\n",
    "dposcope_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Get the multifasta for esmfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{path_bea}/DepoScope_predictions.bea.to_esmfold.fasta\" , \"w\") as outfile :\n",
    "    for fasta_file in tqdm(os.listdir(f\"{path_bea}/genomes\")) :\n",
    "        multi_fasta = SeqIO.parse(f\"{path_bea}/genomes/{fasta_file}\" , \"fasta\")\n",
    "        for record in multi_fasta :\n",
    "            locus_tag = record.description.split(\"locus_tag=\")[1].split(\"]\")[0]\n",
    "            protein_seq = record.seq.translate()[0:-1]\n",
    "            if record.description in dposcope_df[\"protein_description\"].to_list() : \n",
    "                type = dposcope_df[dposcope_df[\"protein_description\"] == record.description][\"type\"].values[0]\n",
    "                if type == \"x\" :\n",
    "                    outfile.write(f\">{locus_tag}\\n{protein_seq}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{path_bea}/DepoScope_predictions.bea.domains.0709.fasta\" , \"w\") as outfile :\n",
    "    for fasta_file in tqdm(os.listdir(f\"{path_bea}/genomes\")) :\n",
    "        multi_fasta = SeqIO.parse(f\"{path_bea}/genomes/{fasta_file}\" , \"fasta\")\n",
    "        for record in multi_fasta :\n",
    "            locus_tag = record.description.split(\"locus_tag=\")[1].split(\"]\")[0]\n",
    "            protein_seq = record.seq.translate()[0:-1]\n",
    "            if record.description in dposcope_df[\"protein_description\"].to_list() : \n",
    "                boundaries = dposcope_df[dposcope_df[\"protein_description\"] == record.description][\"boundaries\"].values[0]\n",
    "                start = int(boundaries.split(\",\")[0].split(\"(\")[1])\n",
    "                end = int(boundaries.split(\",\")[1].split(\")\")[0])\n",
    "                if len(protein_seq) >= 200 :\n",
    "                    outfile.write(f\">{locus_tag}\\n{protein_seq[start : end]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsync -avzhe ssh \\\n",
    "/media/concha-eloko/Linux/PPT_clean/in_vitro/Bea/DepoScope_predictions.bea.domains.0709.fasta \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\n",
    "\n",
    "rsync -avzhe ssh \\\n",
    "/media/concha-eloko/Linux/PPT_clean/in_vitro/Bea/DepoScope_predictions.bea.to_esmfold.fasta \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Extract the representations : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os \n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "path_esm = \"/media/concha-eloko/Linux/PPT_clean/in_vitro/Bea/DepoScope_predictions.bea.domains.0709.fasta.out\"\n",
    "\n",
    "embeddings_esm = {}\n",
    "for file in tqdm(os.listdir(path_esm)) :\n",
    "    path_file = f\"{path_esm}/{file}\"\n",
    "    index = file.split(\".\")[0]\n",
    "    embb = torch.load(f\"{path_file}\")[\"mean_representations\"][33].tolist()\n",
    "    embeddings_esm[index] = embb\n",
    "    \n",
    "with open(f\"/media/concha-eloko/Linux/PPT_clean/in_vitro/Bea/Bea_phages.esm2.embedding.csv\" , \"w\") as outfile :\n",
    "    for index in tqdm(embeddings_esm) :\n",
    "        outfile.write(f\"{index},\")\n",
    "        for _,  emb in enumerate(embeddings_esm[index]) :\n",
    "            outfile.write(f\"{emb},\")\n",
    "        outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_work",
   "language": "python",
   "name": "ml_work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
