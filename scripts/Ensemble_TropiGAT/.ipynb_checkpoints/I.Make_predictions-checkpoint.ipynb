{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f75d265-4748-4c50-8ceb-2fcff5e5e0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData, DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import to_hetero , HeteroConv , GATv2Conv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder , label_binarize , OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score , matthews_corrcoef\n",
    "\n",
    "#from TropiGAT_functions import *\n",
    "#from TropiGAT_functions import get_top_n_kltypes ,clean_print \n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import random\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import logging\n",
    "from multiprocessing.pool import ThreadPool\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# *****************************************************************************\n",
    "# Load the Dataframes :\n",
    "path_work = \"/media/concha-eloko/Linux/PPT_clean\"\n",
    "path_ensemble = f\"{path_work}/ficheros_28032023/ensemble_1908\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a762edd-96c5-4bc8-9997-51f429f6cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_project = \"/media/concha-eloko/Linux/77_strains_phage_project\"\n",
    "path_Dpo_domain_org = \"/media/concha-eloko/Linux/depolymerase_building/clean_77_phages_depo\"\n",
    "\n",
    "dpo_embeddings = pd.read_csv(f\"{path_project}/rbp_work/Dpo_domains_77.esm2.embedding.csv\", sep = \",\" , header = None)\n",
    "dpo_embeddings = dpo_embeddings.drop([1281] , axis = 1)\n",
    "dpo_embeddings.set_index([0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b453e39-1441-4965-b545-47746e2c856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_query_graph(embeddings) :\n",
    "    \"\"\"\n",
    "    This function builds the query graph for the ensemble model.\n",
    "    Input : A list of the ESM2 embeddings of the depolymerase \n",
    "    Output : The query graph\n",
    "    \"\"\"\n",
    "    query_graph = HeteroData()\n",
    "    query_graph[\"B1\"].x = torch.empty((n_dpos, 0))\n",
    "    query_graph[\"B2\"].x = torch.tensor(embeddings , dtype=torch.float)\n",
    "    edge_index_B2_B1 = torch.tensor([0,0] , dtype=torch.long)\n",
    "    query_graph['B2', 'expressed', 'B1'].edge_index = edge_index_B2_B1.t().contiguous()\n",
    "    \n",
    "    return query_graph\n",
    "    \n",
    "def make_ensemble_TropiGAT(path_ensemble) : \n",
    "    \"\"\"\n",
    "    This function builds a dictionary with all the models that are part of the TropiGAT predictor\n",
    "    Input : Path of the models\n",
    "    Output : Dictionary\n",
    "\n",
    "    # Make a json file with the versions of the GNN corresponding to each KL types\n",
    "    # Load it\n",
    "    # Create the correct model instance (TropiGAT_small_module or TropiGAT_big_module)\n",
    "    \"\"\"\n",
    "    dico_ensemble = {}\n",
    "    for GNN_model in os.listdir(path_ensemble) :\n",
    "        if GNN_model[-2:] == \"pt\" : \n",
    "            KL_type = GNN_model.split(\".\")[0]\n",
    "            model = TropiGAT_models.TropiGAT_big_module(hidden_channels = 1280 , heads = 1)\n",
    "            model.load_state_dict(torch.load(f\"{path_ensemble}/{GNN_model}\"))\n",
    "            dico_ensemble[KL_type] = model\n",
    "        \n",
    "    return dico_ensemble\n",
    "\n",
    "@torch.no_grad()\n",
    "def make_predictions(model, data):\n",
    "    \"\"\"\n",
    "    This generic function run the prediction of a binary model\n",
    "    Inputs : The model, the query data\n",
    "    Ouput : the prediction and associated probability\n",
    "    \"\"\"\n",
    "    model.eval() \n",
    "    output = model(data)\n",
    "    probabilities = torch.sigmoid(output)  \n",
    "    predictions = probabilities.round() \n",
    "    \n",
    "    return predictions, probabilities\n",
    "        \n",
    "def run_prediction(query_graph, dico_ensemble) :\n",
    "    dico_predictions = {}\n",
    "    for KL_type in dico_ensemble :\n",
    "        model = dico_ensemble[KL_type]\n",
    "        prediction, probabilities = make_predictions(model, graph)\n",
    "        if int(prediction) == 1 :\n",
    "            dico_predictions[KL_type] = probabilities\n",
    "        else :\n",
    "            continue\n",
    "\n",
    "    return dico_predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cba61e5-3e31-4eb0-98f1-7f80126720e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mA\u001b[0m={ x=[4585, 127] },\n",
       "  \u001b[1mB1\u001b[0m={ x=[7640, 0] },\n",
       "  \u001b[1mB2\u001b[0m={ x=[3449, 1280] },\n",
       "  \u001b[1m(B1, infects, A)\u001b[0m={\n",
       "    edge_index=[2, 7707],\n",
       "    y=[7707]\n",
       "  },\n",
       "  \u001b[1m(B2, expressed, B1)\u001b[0m={\n",
       "    edge_index=[2, 9626],\n",
       "    y=[9626]\n",
       "  },\n",
       "  \u001b[1m(A, harbors, B1)\u001b[0m={\n",
       "    edge_index=[2, 7707],\n",
       "    y=[7707]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_work = \"/media/concha-eloko/Linux/PPT_clean\"\n",
    "graph_data = torch.load(f'{path_work}/Tropi_graph.lvl_1.1909.pt')\n",
    "graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6b2279a-e7f2-4cc9-a7e2-2671aade5a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    1,    2,  ..., 3446, 3447, 3448],\n",
       "        [   0,    0,    1,  ..., 7637, 7638, 7639]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_data[(\"B2\", \"expressed\", \"B1\")].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0f4156-40e9-4826-97b9-bda740eb6a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_geometric",
   "language": "python",
   "name": "torch_geometric"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
