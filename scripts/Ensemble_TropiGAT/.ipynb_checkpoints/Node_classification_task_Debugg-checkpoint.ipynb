{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c6ee9b-7b8c-4cf6-9382-9dd4d11594df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsync -avzhe ssh \\\n",
    "/media/concha-eloko/Linux/PPT_clean/TropiGATv2.final_df.tsv \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023/train_nn \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daa30dbd-9bce-44b6-946d-258f3708b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData, DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, to_hetero , SAGEConv, GATv2Conv, HeteroConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "import torch\n",
    "from torch import nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder , label_binarize , OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score ,matthews_corrcoef\n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import random\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bb7ae35-b4b9-4ce8-9a71-cf19db77502a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (TropiGAT_graph.py, line 99)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m/media/concha-eloko/Linux/conda_envs/torch_geometric/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3508\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 1\u001b[0;36m\n\u001b[0;31m    import TropiGAT_graph\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Documents/GitHub/DpoK-serotypeTropism/scripts/Ensemble_TropiGAT/TropiGAT_graph.py:99\u001b[0;36m\u001b[0m\n\u001b[0;31m    indexation_nodes_B1 = df_info[\"Phage\"].unique().tolist()\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import TropiGAT_graph\n",
    "import TropiGAT_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b120e0-5247-426d-b59e-e90e51f070f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "# Load the Dataframes :\n",
    "path_work = \"/media/concha-eloko/Linux/PPT_clean\"\n",
    "#path_work = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "\n",
    "    # Open the DF\n",
    "DF_info = pd.read_csv(f\"{path_work}/TropiGATv2.final_df.tsv\", sep = \"\\t\" ,  header = 0)\n",
    "DF_info_lvl_0 = DF_info[~DF_info[\"KL_type_LCA\"].str.contains(\"\\\\|\")]\n",
    "DF_info_lvl_0 = DF_info_lvl_0.drop_duplicates(subset = [\"Infected_ancestor\",\"index\",\"prophage_id\"] , keep = \"first\").reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a72e95e-4ac6-4aea-ab67-da4c4c88404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#graph_baseline , dico_prophage_kltype_associated = TropiGAT_graph.build_graph_baseline(DF_info_lvl_0)\n",
    "graph_KL64 = TropiGAT_graph.build_graph_masking(graph_baseline , \n",
    "                                 dico_prophage_kltype_associated, \n",
    "                                 DF_info_lvl_0, \n",
    "                                 \"KL64\",\n",
    "                                 2, 0.8, 0.1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761f6f60-6b7c-4c73-99e3-f39c1017e720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba07e4-3dc4-43dc-adfc-79f487bdd232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c6be857-c3cd-4b7f-81f7-cac16fc36e70",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TropiGAT_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TropiGAT_graph' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "graph_dico = {kltype : TropiGAT_graph.build_graph_masking(graph_baseline , dico_prophage_kltype_associated, DF_info_lvl_0, kltype, 2, 0.8, 0.1, 0.1) for kltype in [\"KL64\", \"KL37\"]}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9452951-294f-4bc7-b7a7-8dafe7b8d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_KL64 = graph_dico[\"KL64\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b604ba78-f36d-4d95-9020-c72ee38522da",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(graph_KL64[\"B1\"].train_mask.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c792017f-924c-49c7-8924-d5b4feefc31e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph_KL37[\"B1\"].train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22881832-e8ea-4845-b043-6fa4d30315aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,value in enumerate(graph_KL37[\"B1\"].y) : \n",
    "    if value != 0 :\n",
    "        print(value,index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13a6c1b-34c8-4752-a56d-3ca885469ba7",
   "metadata": {},
   "source": [
    "# The architecture of the model : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6868ea31-624f-4ef0-b302-b30d6d539e98",
   "metadata": {},
   "source": [
    "***\n",
    "> Original : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8c8d25-75ff-4474-8882-5d6517360c89",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# The model : TropiGAT\n",
    "class TropiGAT_small_module(torch.nn.Module):\n",
    "    def __init__(self,hidden_channels, heads, edge_type = (\"B2\", \"expressed\", \"B1\") ,dropout = 0.2, conv = GATv2Conv):\n",
    "        super().__init__()\n",
    "        # GATv2 module :\n",
    "        self.conv = conv((-1,-1), hidden_channels, add_self_loops = False, heads = heads, dropout = dropout, shared_weights = True)\n",
    "        self.hetero_conv = HeteroConv({edge_type: self.conv})\n",
    "        # FNN layers : \n",
    "        self.linear_layers = nn.Sequential(nn.Linear(heads*hidden_channels, 1280),\n",
    "                                           nn.BatchNorm1d(1280),\n",
    "                                           nn.LeakyReLU(),\n",
    "                                           torch.nn.Dropout(dropout),\n",
    "                                           nn.Linear(1280, 480),\n",
    "                                           nn.BatchNorm1d(480),\n",
    "                                           nn.LeakyReLU(),\n",
    "                                           torch.nn.Dropout(dropout),\n",
    "                                           nn.Linear(480 , 1))\n",
    "        \n",
    "    def forward(self, graph_data):\n",
    "        x_B1_dict = self.hetero_conv(graph_data.x_dict, graph_data.edge_index_dict)\n",
    "        x = self.linear_layers(x_B1_dict[\"B1\"])\n",
    "        return x.view(-1)\n",
    "\n",
    "class TropiGAT_big_module(torch.nn.Module):\n",
    "    def __init__(self,hidden_channels, heads, edge_type = (\"B2\", \"expressed\", \"B1\") ,dropout = 0.2, conv = GATv2Conv):\n",
    "        super().__init__()\n",
    "        # GATv2 module :\n",
    "        self.conv = conv((-1,-1), hidden_channels, add_self_loops = False, heads = heads, dropout = dropout, shared_weights = True)\n",
    "        self.hetero_conv = HeteroConv({edge_type: self.conv})\n",
    "        # FNN layers : \n",
    "        self.linear_layers = nn.Sequential(nn.Linear(heads*hidden_channels, 1280),\n",
    "                                           nn.BatchNorm1d(1280),\n",
    "                                           nn.LeakyReLU(),\n",
    "                                           torch.nn.Dropout(dropout),\n",
    "                                           nn.Linear(1280, 720),\n",
    "                                           nn.BatchNorm1d(720),\n",
    "                                           nn.LeakyReLU(),\n",
    "                                           torch.nn.Dropout(dropout),\n",
    "                                           nn.Linear(720 , 240),\n",
    "                                           nn.BatchNorm1d(240),\n",
    "                                           nn.LeakyReLU(),\n",
    "                                           torch.nn.Dropout(dropout),\n",
    "                                           nn.Linear(240, 1)\n",
    "                                          )\n",
    "        \n",
    "    def forward(self, graph_data):\n",
    "        x = self.hetero_conv(graph_data.x_dict, graph_data.edge_index_dict)\n",
    "        x = self.linear_layers(x)\n",
    "        \n",
    "        return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2544ede1-26c5-4cff-a21b-3bd9f1513e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_model = {\"hidden_channels\" : 1000,\n",
    "                    \"lr\" : 0.0001,\n",
    "                    \"heads\" : 1,\n",
    "                    \"dropout\" : 0.1,\n",
    "                   }\n",
    "\n",
    "TropiGATv2_eg = TropiGAT_models.TropiGAT_small_module(hidden_channels = 1280 , heads = 1)\n",
    "TropiGATv2_eg.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8c7ae2-fc22-4398-ac1e-51214a50b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = TropiGATv2_eg(graph_KL64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb02b1a-5f10-43d6-91d0-fe2f4c321463",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b2bba1-58c0-4939-a066-0e0fc10cc950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(graph_KL64[\"B1\"].train_mask.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d0bf16-6a41-4f1c-930b-d390c15ad79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c309c3e9-8bee-48d4-8c91-79e648d1c134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed00de2-d993-4542-94be-94930e7431d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_KL37[\"B1\"].train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7133f4-397c-4ac0-a4a6-d203cdc7f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.argmax(dim=0)\n",
    "out[graph_KL37[\"B1\"].train_mask]\n",
    "graph_KL37[\"B1\"].train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047f6482-c179-4f10-aaea-80faa12fed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_KL37[\"B1\"].y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a495bd5-ecc1-4e6b-9bab-42ef1d632d93",
   "metadata": {},
   "source": [
    "***\n",
    "# Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1754bd-6a43-4148-8697-8a3818802b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, graph, optimizer, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out_train = model(graph)\n",
    "    loss = criterion(out_train[graph[\"B1\"].train_mask], graph[\"B1\"].y[graph[\"B1\"].train_mask].float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, graph,criterion, mask):\n",
    "    model.eval()\n",
    "    out_eval = model(graph)\n",
    "    #logging.info(f\"Out eval : {out_eval}\")\n",
    "    pred = out_eval[mask]\n",
    "    pred = torch.sigmoid(out_eval).round()\n",
    "    #pred = pred.round()\n",
    "    labels = graph[\"B1\"].y[mask]\n",
    "    val_loss = criterion(out_eval[mask], graph[\"B1\"].y[mask].float())\n",
    "    logging.info(f\"The predictions : {pred} and length {len(pred)}\")\n",
    "    logging.info(f\"The labels after masking : {labels} and the length {len(labels)}. Here are the original labels : {graph['B1'].y} with length {len(graph['B1'].y)} and finally {Counter(graph['B1'].y.numpy())}\\nHere are the masked labels again : {graph['B1'].y[mask]}\\nHere is the mask used : {mask} with {Counter(mask.numpy())}\")\n",
    "    # Calculate the metrics\n",
    "    f1 = f1_score(labels, pred, average='binary')\n",
    "    precision = precision_score(labels, pred, average='binary')\n",
    "    recall = recall_score(labels, pred, average='binary')\n",
    "    mcc = matthews_corrcoef(labels, pred)\n",
    "    accuracy = accuracy_score(labels, pred)\n",
    "    auc = roc_auc_score(labels, out_eval[mask])\n",
    "    return val_loss.item(), (f1, precision, recall, mcc, accuracy, auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0b1ff1-f50e-4286-a152-98e695cf0734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_graph() :\n",
    "    KL_type = \"KL64\"\n",
    "    graph_data_kltype = graph_dico[KL_type]\n",
    "    #logging.info(f\"Let's start the work with {conv}\\t{hidden_channels}\\t{dropout}\\t{lr}\\t{heads}\")\n",
    "    model = TropiGAT_models.TropiGAT_big_module(hidden_channels = 1280, heads = 1)\n",
    "    model(graph_data_kltype)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001 , weight_decay= 0.000001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    for epoch in range(500):\n",
    "        train_loss = TropiGAT_models.train(model, graph_data_kltype, optimizer,criterion)\n",
    "        logging.info(train_loss)\n",
    "        if epoch % 25 == 0:\n",
    "            # Get all metrics\n",
    "            test_loss, metrics = TropiGAT_models.evaluate(model, graph_data_kltype,criterion, graph_data_kltype[\"B1\"].test_mask)\n",
    "            info_training_concise = f'Epoch: {epoch}\\tTrain Loss: {train_loss}\\tTest Loss: {test_loss}\\tMCC: {metrics[3]}\\tAUC: {metrics[5]}'\n",
    "            info_training = f'Epoch: {epoch}, Train Loss: {train_loss}, Test Loss: {test_loss},F1 Score: {metrics[0]}, Precision: {metrics[1]}, Recall: {metrics[2]}, MCC: {metrics[3]},Accuracy: {metrics[4]}, AUC: {metrics[5]}'\n",
    "            logging.info(info_training_concise)\n",
    "            print(info_training)\n",
    "            scheduler.step(test_loss)\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), f\"{path_work}/{kltype}.TropiGATv2.2509.pt\")\n",
    "    # The final eval :\n",
    "    print(\"Final evaluation ...\")\n",
    "    test_loss, metrics = TropiGAT_models.evaluate(model, graph_data_kltype, criterion,graph_data_kltype[\"B1\"].eval_mask)\n",
    "    info_eval = f'Epoch: {epoch}, F1 Score: {metrics[0]}, Precision: {metrics[1]}, Recall: {metrics[2]}, MCC: {metrics[3]},Accuracy: {metrics[4]}, AUC: {metrics[5]}'\n",
    "    print(info_eval)\n",
    "    logging.info(f\"Final evaluation ...\\n{info_eval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be987c2e-6851-461a-acf8-f6a2eae098b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2723fc30-3d30-4fb5-861a-0db337cc24d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1ddb97-c019-4383-8449-68cfebb99fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "graph_dico = {kltype : TropiGAT_graph.build_graph_masking(graph_baseline , dico_prophage_kltype_associated,DF_info_lvl_0, kltype,2, 0.8, 0.1,0.1) \n",
    "             for kltype in DF_info_lvl_0[\"KL_type_LCA\"].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a062f33-074f-4acd-b9b1-eb27dee3e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(graph_KL64[\"B1\"].test_mask.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05cb47b-2caf-4a27-a663-74b6ddd2d9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_geometric",
   "language": "python",
   "name": "torch_geometric"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
