{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6d5daf-a8f3-4c99-8ed4-51bbba154ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData, DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import to_hetero , HeteroConv , GATv2Conv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder , label_binarize , OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score , matthews_corrcoef\n",
    "\n",
    "#import TropiGAT_functions \n",
    "#from TropiGAT_functions import get_top_n_kltypes ,clean_print \n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import random\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import logging\n",
    "from multiprocessing.pool import ThreadPool\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# *****************************************************************************\n",
    "# Load the Dataframes :\n",
    "path_work = \"/media/concha-eloko/Linux/PPT_clean\"\n",
    "path_ensemble = f\"{path_work}/ficheros_28032023/ensemble_2809\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbd3552-5531-4c85-8555-6457e0de52b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_graph(KL_type) :\n",
    "    with open(f\"{path_work}/train_nn/ensemble_2709_log_files/{KL_type}__node_classification.2705.log\" , \"w\") as log_outfile :\n",
    "        n_prophage = dico_prophage_count[KL_type]\n",
    "        graph_data_kltype = graph_dico[KL_type]\n",
    "        model = TropiGAT_models.TropiGAT_big_module(hidden_channels = 1280, heads = 1)\n",
    "        model(graph_data_kltype)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001 , weight_decay= 0.000001)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        early_stopping = TropiGAT_models.EarlyStopping(patience=40, verbose=True, path=f\"{path_ensemble}/{KL_type}.TropiGATv2.2709.pt\", metric='MCC')\n",
    "        try : \n",
    "            for epoch in range(200):\n",
    "                train_loss = TropiGAT_models.train(model, graph_data_kltype, optimizer,criterion)\n",
    "                if epoch % 5 == 0:\n",
    "                    # Get all metrics\n",
    "                    test_loss, metrics = TropiGAT_models.evaluate(model, graph_data_kltype,criterion, graph_data_kltype[\"B1\"].test_mask)\n",
    "                    info_training_concise = f'Epoch: {epoch}\\tTrain Loss: {train_loss}\\tTest Loss: {test_loss}\\tMCC: {metrics[3]}\\tAUC: {metrics[5]}\\n'\n",
    "                    info_training = f'Epoch: {epoch}, Train Loss: {train_loss}, Test Loss: {test_loss},F1 Score: {metrics[0]}, Precision: {metrics[1]}, Recall: {metrics[2]}, MCC: {metrics[3]},Accuracy: {metrics[4]}, AUC: {metrics[5]}'\n",
    "                    log_outfile.write(info_training_concise)\n",
    "                    print(info_training)\n",
    "                    scheduler.step(test_loss)\n",
    "                torch.save(model, f\"{path_ensemble}/{KL_type}.TropiGATv2.2709.pt\")\n",
    "            # The final eval :\n",
    "            print(\"Final evaluation ...\")\n",
    "            model_final = TropiGAT_models.TropiGAT_big_module(hidden_channels = 1280, heads = 1)\n",
    "            model_final.load_state_dict(torch.load(f\"{path_ensemble}/{KL_type}.TropiGATv2.2709.pt\"))\n",
    "            eval_loss, metrics = TropiGAT_models.evaluate(model_final, graph_data_kltype, criterion,graph_data_kltype[\"B1\"].eval_mask)\n",
    "            with open(f\"{path_ensemble}/Metric_Report.2709.tsv\", \"a+\") as metric_outfile :\n",
    "                metric_outfile.write(f\"{KL_type}\\t{n_prophage}\\t{metrics[0]}\\t{metrics[1]}\\t{metrics[2]}\\t{metrics[3]}\\t{metrics[4]}\\t{metrics[5]}\\n\")\n",
    "            info_eval = f'Epoch: {epoch}, F1 Score: {metrics[0]}, Precision: {metrics[1]}, Recall: {metrics[2]}, MCC: {metrics[3]},Accuracy: {metrics[4]}, AUC: {metrics[5]}'\n",
    "            print(info_eval)\n",
    "            log_outfile.write(f\"Final evaluation ...\\n{info_eval}\")\n",
    "        except Exception as e :\n",
    "            log_outfile.write(f\"***Issue here : {e}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c76379b-9651-4bd5-ab27-aa9a609b3574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you already have the model weights and new data\n",
    "pretrained_model_path = \"path_to_pretrained_model.pt\"\n",
    "new_data = graph_data_for_fine_tuning  # Replace with your new data\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = TropiGAT_big_module(hidden_channels=1280, heads=1)\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "# Create an optimizer and scheduler\n",
    "optimizer = Adam(model.parameters(), lr=0.0001, weight_decay=0.000001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Training loop for fine-tuning\n",
    "try:\n",
    "    for epoch in range(200):\n",
    "        # Training\n",
    "        train_loss = TropiGAT_models.train(model, new_data, optimizer, criterion)\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            # Validation\n",
    "            test_loss, metrics = TropiGAT_models.evaluate(model, new_data, criterion, new_data[\"B1\"].test_mask)\n",
    "            \n",
    "            info_training_concise = f'Epoch: {epoch}\\tTrain Loss: {train_loss}\\tTest Loss: {test_loss}\\tMCC: {metrics[3]}\\tAUC: {metrics[5]}\\n'\n",
    "            info_training = f'Epoch: {epoch}, Train Loss: {train_loss}, Test Loss: {test_loss},F1 Score: {metrics[0]}, Precision: {metrics[1]}, Recall: {metrics[2]}, MCC: {metrics[3]},Accuracy: {metrics[4]}, AUC: {metrics[5]}'\n",
    "            \n",
    "            print(info_training)\n",
    "            scheduler.step(test_loss)\n",
    "\n",
    "    # Save the fine-tuned model\n",
    "    torch.save(model.state_dict(), \"fine_tuned_model.pt\")\n",
    "\n",
    "    # Final evaluation\n",
    "    model_final = TropiGAT_big_module(hidden_channels=1280, heads=1)\n",
    "    model_final.load_state_dict(torch.load(\"fine_tuned_model.pt\"))\n",
    "    eval_loss, metrics = TropiGAT_models.evaluate(model_final, new_data, criterion, new_data[\"B1\"].eval_mask)\n",
    "\n",
    "    info_eval = f'Epoch: {epoch}, F1 Score: {metrics[0]}, Precision: {metrics[1]}, Recall: {metrics[2]}, MCC: {metrics[3]},Accuracy: {metrics[4]}, AUC: {metrics[5]}'\n",
    "    print(\"Final evaluation ...\")\n",
    "    print(info_eval)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"***Issue here: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_geometric",
   "language": "python",
   "name": "torch_geometric"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
