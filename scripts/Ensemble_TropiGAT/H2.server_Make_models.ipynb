{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2feba-abbf-4452-a5e3-7b3c90a5dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch geometric modules\n",
    "from torch_geometric.data import HeteroData, DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import to_hetero , HeteroConv , GATv2Conv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "# Torch modules\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# SKlearn modules\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder , label_binarize , OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score , matthews_corrcoef\n",
    "\n",
    "# Ground modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import random\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import logging\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "# TropiGAT modules\n",
    "import TropiGAT_graph\n",
    "import TropiGAT_models\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02014791-bbae-4d23-a94d-bdd9a45d5c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "# Load the Dataframes :\n",
    "path_work = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "DF_info = pd.read_csv(f\"{path_work}/train_nn/TropiGATv2.final_df.tsv\", sep = \"\\t\" ,  header = 0)\n",
    "DF_info_lvl_0 = DF_info[~DF_info[\"KL_type_LCA\"].str.contains(\"\\\\|\")]\n",
    "DF_info_lvl_0 = DF_info_lvl_0.drop_duplicates(subset = [\"Infected_ancestor\",\"index\",\"prophage_id\"] , keep = \"first\").reset_index(drop=True)\n",
    "\n",
    "# Log file : \n",
    "path_ensemble = f\"{path_work}/train_nn/ensemble_2709\"\n",
    "\n",
    "df_prophages = DF_info_lvl_0.drop_duplicates(subset = [\"Phage\"])\n",
    "dico_prophage_count = dict(Counter(df_prophages[\"KL_type_LCA\"]))\n",
    "\n",
    "KLtypes = [kltype for kltype in dico_prophage_count if dico_prophage_count[kltype] >= 20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2be167-93d0-47a6-8d59-b3a389d1c1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "# Make graphs : \n",
    "graph_baseline , dico_prophage_kltype_associated = TropiGAT_graph.build_graph_baseline(DF_info_lvl_0)\n",
    "graph_dico = {kltype : TropiGAT_graph.build_graph_masking(graph_baseline , dico_prophage_kltype_associated,DF_info_lvl_0, kltype, 5, 0.8, 0.1, 0.1) \n",
    "             for kltype in DF_info_lvl_0[\"KL_type_LCA\"].unique()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92244bc-cfe2-4e3e-a208-ee1500813171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "def train_graph(KL_type) :\n",
    "    with open(f\"{path_work}/train_nn/ensemble_2709_log_files/{KL_type}__node_classification.2705.log\" , \"w\") as log_outfile :\n",
    "        n_prophage = dico_prophage_count[KL_type]\n",
    "        graph_data_kltype = graph_dico[KL_type]\n",
    "        if n_prophage <= 125 : \n",
    "            model = TropiGAT_models.TropiGAT_small_module(hidden_channels = 1280, heads = 1)\n",
    "            n = \"small\"\n",
    "        else : \n",
    "            model = TropiGAT_models.TropiGAT_big_module(hidden_channels = 1280, heads = 1)\n",
    "            n = \"big\"\n",
    "        model(graph_data_kltype)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001 , weight_decay= 0.000001)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        early_stopping = TropiGAT_models.EarlyStopping(patience=40, verbose=True, path=f\"{path_ensemble}/{KL_type}.TropiGATv2.2709.pt\", metric='MCC')\n",
    "        try : \n",
    "            for epoch in range(200):\n",
    "                train_loss = TropiGAT_models.train(model, graph_data_kltype, optimizer,criterion)\n",
    "                if epoch % 5 == 0:\n",
    "                    # Get all metrics\n",
    "                    test_loss, metrics = TropiGAT_models.evaluate(model, graph_data_kltype,criterion, graph_data_kltype[\"B1\"].test_mask)\n",
    "                    info_training_concise = f'Epoch: {epoch}\\tTrain Loss: {train_loss}\\tTest Loss: {test_loss}\\tMCC: {metrics[3]}\\tAUC: {metrics[5]}\\n'\n",
    "                    info_training = f'Epoch: {epoch}, Train Loss: {train_loss}, Test Loss: {test_loss},F1 Score: {metrics[0]}, Precision: {metrics[1]}, Recall: {metrics[2]}, MCC: {metrics[3]},Accuracy: {metrics[4]}, AUC: {metrics[5]}'\n",
    "                    log_outfile.write(info_training_concise)\n",
    "                    print(info_training)\n",
    "                    scheduler.step(test_loss)\n",
    "                    early_stopping(metrics[3], model, epoch)\n",
    "                    if early_stopping.early_stop:\n",
    "                        log_outfile.write(f\"Early stopping at epoch = {epoch}\")\n",
    "                        break\n",
    "            else :\n",
    "                torch.save(model, f\"{path_ensemble}/{KL_type}.TropiGATv2.2709.pt\")\n",
    "            # The final eval :\n",
    "            print(\"Final evaluation ...\")\n",
    "            if n == \"small\" : \n",
    "                model_final = TropiGAT_models.TropiGAT_small_module(hidden_channels = 1280, heads = 1)\n",
    "            else :\n",
    "                model_final = TropiGAT_models.TropiGAT_big_module(hidden_channels = 1280, heads = 1)\n",
    "            model_final.load_state_dict(torch.load(f\"{path_ensemble}/{KL_type}.TropiGATv2.2709.pt\"))\n",
    "            eval_loss, metrics = TropiGAT_models.evaluate(model_final, graph_data_kltype, criterion,graph_data_kltype[\"B1\"].eval_mask)\n",
    "            with open(f\"{path_ensemble}/Metric_Report.2709.tsv\", \"a+\") as metric_outfile :\n",
    "                metric_outfile.write(f\"{KL_type}\\t{n_prophage}\\t{metrics[0]}\\t{metrics[1]}\\t{metrics[2]}\\t{metrics[3]}\\t{metrics[4]}\\t{metrics[5]}\\n\")\n",
    "            info_eval = f'Epoch: {epoch}, F1 Score: {metrics[0]}, Precision: {metrics[1]}, Recall: {metrics[2]}, MCC: {metrics[3]},Accuracy: {metrics[4]}, AUC: {metrics[5]}'\n",
    "            print(info_eval)\n",
    "            log_outfile.write(f\"Final evaluation ...\\n{info_eval}\")\n",
    "        except Exception as e :\n",
    "            log_outfile.write(f\"***Issue here : {e}\")\n",
    "            with open(f\"{path_ensemble}/Metric_Report.2709.tsv\", \"a+\") as metric_outfile :\n",
    "                n_prophage = dico_prophage_count[KL_type]\n",
    "                metric_outfile.write(f\"{KL_type}\\t{n_prophage}\\t***Issue***\\n\")\n",
    "            \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with ThreadPool(15) as p:\n",
    "        p.map(train_graph, KLtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644ab39f-6c05-4e47-a70f-6c96c3d03968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9461631c-697f-4885-80d5-fafa6b525eda",
   "metadata": {},
   "source": [
    "> V1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9831d8f5-54dc-40e6-b3de-3632c1bc7d4c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_graph(KL_type) :\n",
    "    logging.basicConfig(filename = f\"{path_work}/train_nn/ensemble_2509_log_files/{KL_type}__node_classification.2505.log\",format='%(asctime)s | %(levelname)s: %(message)s', level=logging.NOTSET, filemode='w')\n",
    "    logging.info(f\"***{KL_type}___\")\n",
    "    graph_data_kltype = graph_dico[KL_type]\n",
    "    model = TropiGAT_models.TropiGAT_big_module(hidden_channels = 1280, heads = 1)\n",
    "    model(graph_data_kltype)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001 , weight_decay= 0.000001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    early_stopping = TropiGAT_models.EarlyStopping(patience=20, verbose=True, path=f\"{path_ensemble}/{KL_type}.TropiGATv2.2509.pt\", metric='MCC')\n",
    "    for epoch in range(100):\n",
    "        train_loss = TropiGAT_models.train(model, graph_data_kltype, optimizer,criterion)\n",
    "        if epoch % 5 == 0:\n",
    "            # Get all metrics\n",
    "            test_loss, metrics = TropiGAT_models.evaluate(model, graph_data_kltype,criterion, graph_data_kltype[\"B1\"].test_mask)\n",
    "            info_training_concise = f'Epoch: {epoch}\\tTrain Loss: {train_loss}\\tTest Loss: {test_loss}\\tMCC: {metrics[3]}\\tAUC: {metrics[5]}'\n",
    "            info_training = f'Epoch: {epoch}, Train Loss: {train_loss}, Test Loss: {test_loss},F1 Score: {metrics[0]}, Precision: {metrics[1]}, Recall: {metrics[2]}, MCC: {metrics[3]},Accuracy: {metrics[4]}, AUC: {metrics[5]}'\n",
    "            logging.info(info_training_concise)\n",
    "            print(info_training)\n",
    "            scheduler.step(test_loss)\n",
    "            early_stopping(metrics[3], model)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "    # The final eval :\n",
    "    print(\"Final evaluation ...\")\n",
    "    model_final = TropiGAT_models.TropiGAT_big_module(hidden_channels = 1280, heads = 1))\n",
    "    model_final.load_state_dict(torch.load(f\"{path_ensemble}/{KL_type}.TropiGATv2.2509.pt\")\n",
    "    test_loss, metrics = TropiGAT_models.evaluate(model_final, graph_data_kltype, criterion,graph_data_kltype[\"B1\"].eval_mask)\n",
    "    with open(f\"{path_ensemble}/Metric_Report.2609\", \"a+\") as metric_outfile : \n",
    "        outfile.write(f\"{KL_type}\\t{metrics[0]}\\t{metrics[1]}\\t{metrics[2]}\\t{metrics[3]}\\t{metrics[4]}\\t{metrics[5]}\\n\")\n",
    "    info_eval = f'Epoch: {epoch}, F1 Score: {metrics[0]}, Precision: {metrics[1]}, Recall: {metrics[2]}, MCC: {metrics[3]},Accuracy: {metrics[4]}, AUC: {metrics[5]}'\n",
    "    print(info_eval)\n",
    "    logging.info(f\"Final evaluation ...\\n{info_eval}\")\n",
    "    # Close the existing handlers\n",
    "    handlers = logging.root.handlers[:]\n",
    "    for handler in handlers:\n",
    "        handler.close()\n",
    "        logging.root.removeHandler(handler)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    wrong_kltypes = []\n",
    "    with open(f\"{path_ensemble}/report.2609\", \"a+\") as outfile : \n",
    "        for kltype in graph_dico :\n",
    "            try : \n",
    "                train_graph(kltype)\n",
    "            except Exception as e :\n",
    "                wrong_kltypes.append(kltype)\n",
    "        outfile.write(f\"Something wrong with those KLtypes: {str(wrong_kltypes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f6ab52-9946-4d52-91a6-682be2075f71",
   "metadata": {},
   "source": [
    "> Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc88eb37-0da6-404f-b324-7912afeb8e32",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_graph() :\n",
    "    KL_type = \"KL64\"\n",
    "    graph_data_kltype = graph_dico[KL_type]\n",
    "    graph_data_kltype = TropiGAT_graph.build_graph_masking(graph_baseline , \n",
    "                                 dico_prophage_kltype_associated, \n",
    "                                 DF_info_lvl_0, \n",
    "                                 \"KL64\",\n",
    "                                 5, 0.8, 0.1,0.1)\n",
    "    #logging.info(f\"Let's start the work with {conv}\\t{hidden_channels}\\t{dropout}\\t{lr}\\t{heads}\")\n",
    "    model = TropiGAT_models.TropiGAT_big_module(hidden_channels = 1280, heads = 1)\n",
    "    model(graph_data_kltype)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001 , weight_decay= 0.000001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    for epoch in range(100):\n",
    "        train_loss = TropiGAT_models.train(model, graph_data_kltype, optimizer,criterion)\n",
    "        if epoch % 5 == 0:\n",
    "            # Get all metrics\n",
    "            test_loss, metrics = TropiGAT_models.evaluate(model, graph_data_kltype,criterion, graph_data_kltype[\"B1\"].test_mask)\n",
    "            info_training_concise = f'Epoch: {epoch}\\tTrain Loss: {train_loss}\\tTest Loss: {test_loss}\\tMCC: {metrics[3]}\\tAUC: {metrics[5]}'\n",
    "            info_training = f'Epoch: {epoch}, Train Loss: {train_loss}, Test Loss: {test_loss},F1 Score: {metrics[0]}, Precision: {metrics[1]}, Recall: {metrics[2]}, MCC: {metrics[3]},Accuracy: {metrics[4]}, AUC: {metrics[5]}'\n",
    "            logging.info(info_training_concise)\n",
    "            print(info_training)\n",
    "            scheduler.step(test_loss)\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), f\"{path_work}/{KL_type}.TropiGATv2.2509.pt\")\n",
    "    # The final eval :\n",
    "    print(\"Final evaluation ...\")\n",
    "    test_loss, metrics = TropiGAT_models.evaluate(model, graph_data_kltype, criterion,graph_data_kltype[\"B1\"].eval_mask)\n",
    "    info_eval = f'Epoch: {epoch}, F1 Score: {metrics[0]}, Precision: {metrics[1]}, Recall: {metrics[2]}, MCC: {metrics[3]},Accuracy: {metrics[4]}, AUC: {metrics[5]}'\n",
    "    print(info_eval)\n",
    "    logging.info(f\"Final evaluation ...\\n{info_eval}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_graph()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_geometric",
   "language": "python",
   "name": "torch_geometric"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
