{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa33c38-5163-4604-8289-ab150e56365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData, DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, HeteroConv , GATConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "import torch\n",
    "from torch import nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder , label_binarize , OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import random\n",
    "from collections import Counter\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ebc72a-8a3b-4fd0-80e5-1c992c41fef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "# Load the Dataframes :\n",
    "path_work = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "logging.basicConfig(filename = f\"{path_work}/optuna_2607.log\",format='%(asctime)s | %(levelname)s: %(message)s', level=logging.NOTSET, filemode='w')\n",
    "\n",
    "graph_data = torch.load(f'{path_work}/train_nn/graph_file.2607.OHE.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f3e810-dced-4196-adc1-5e8dca77d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "logging.basicConfig(filename = f\"{path_work}/train_nn/GATConv.2607.optuna.log\",format='%(asctime)s | %(levelname)s: %(message)s', level=logging.NOTSET, filemode='w')\n",
    "\n",
    "# The model : Classifier\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, edge_type , conv, hidden_channels, heads, dropout): # GCNConv(-1, 64) , SAGEConv((-1, -1), 64), GATConv((-1, -1), 64)\n",
    "        super().__init__()\n",
    "        self.conv = conv((-1,-1), hidden_channels, add_self_loops = False, heads = heads, dropout = dropout, shared_weights = True)\n",
    "        self.hetero_conv = HeteroConv({edge_type: self.conv})\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x = self.hetero_conv(x_dict, edge_index_dict)\n",
    "        return x\n",
    "\n",
    "# Classifier, Binary :\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, heads):\n",
    "        super().__init__()\n",
    "        self.lin1 = torch.nn.Linear(heads*hidden_channels + 127, 512)\n",
    "        self.lin2 = torch.nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, x_dict_A , x_dict_B1, graph_data):\n",
    "        edge_type = (\"B1\", \"infects\", \"A\")\n",
    "        edge_feat_A = x_dict_A[\"A\"][graph_data[edge_type].edge_label_index[1]]\n",
    "        edge_feat_B1 = x_dict_B1[\"B1\"][graph_data[edge_type].edge_label_index[0]]\n",
    "        features_phage = torch.cat((edge_feat_A ,edge_feat_B1), dim=-1)\n",
    "        x = self.lin1(features_phage).relu()\n",
    "        x = self.lin2(x)\n",
    "        return x.view(-1)\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, conv, hidden_channels, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.single_layer_model = GNN((\"B2\", \"expressed\", \"B1\") ,conv, hidden_channels,heads,dropout)\n",
    "        self.EdgeDecoder = EdgeDecoder(hidden_channels,heads)\n",
    "\n",
    "    def forward(self, graph_data):\n",
    "        b1_nodes = self.single_layer_model(graph_data.x_dict , graph_data.edge_index_dict)\n",
    "        a_nodes =  graph_data.x_dict\n",
    "        out = self.EdgeDecoder(a_nodes ,b1_nodes , graph_data)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181dd7d0-b3c3-4d74-baf7-d337b79778ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "# Pre-process data :\n",
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1, \n",
    "    num_test=0.2, \n",
    "    #disjoint_train_ratio=...,  \n",
    "    neg_sampling_ratio=1.0,  \n",
    "    add_negative_train_samples=True, \n",
    "    edge_types=(\"B1\", \"infects\", \"A\"),\n",
    "    rev_edge_types=(\"A\", \"harbors\", \"B1\"), \n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(graph_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951a8a61-3372-4a55-916f-f3836b097d7b",
   "metadata": {},
   "source": [
    "> Minimizing the loss : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057d2b72-ea26-4515-a1b4-127288aab63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "# Training :\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available\n",
    "\n",
    "def train(model, data, optimizer, criterion, edge_type):\n",
    "    model.train()\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    edge_labels = data[edge_type].edge_label\n",
    "    loss = criterion(out, edge_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data, criterion, edge_type):\n",
    "    model.eval()\n",
    "    data = data.to(device)\n",
    "    out = model(data)\n",
    "    edge_labels = data[edge_type].edge_label\n",
    "    val_loss = criterion(out, edge_labels)\n",
    "    probs = torch.sigmoid(out)\n",
    "    pred_class = probs.round()\n",
    "    all_preds = pred_class.cpu().numpy()\n",
    "    all_labels = edge_labels.cpu().numpy()\n",
    "    all_probs = probs.cpu().numpy()\n",
    "    # Calculate the metrics\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')  # Calculate recall\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)  # Calculate MCC\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    return val_loss.item(), f1, precision, recall, mcc, accuracy, auc  # Include recall and MCC in return values\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters\n",
    "    conv = GATConv\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "    hidden_channels = trial.suggest_int('hidden_channels', 500, 2000, step=50)\n",
    "    dropout = trial.suggest_uniform('dropout', 0, 0.5)\n",
    "    heads = trial.suggest_int('heads', 1, 8, step=1)\n",
    "    # Define and train the model using the given hyperparameters\n",
    "    model = Model(conv,hidden_channels,heads,dropout).to(device)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    edge_type = (\"B1\", \"infects\", \"A\")\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(3000):\n",
    "        train_loss = train(model, train_data, optimizer, criterion, edge_type)\n",
    "        if epoch % 50 == 0:\n",
    "            val_loss, f1, precision, recall, mcc, accuracy, auc = evaluate(model, test_data, criterion, edge_type)\n",
    "            # Early stopping based on validation loss\n",
    "            if val_loss <= best_loss:\n",
    "                best_loss = val_loss\n",
    "            else:\n",
    "                break  # stop training if the validation loss does not decrease\n",
    "\n",
    "    return best_loss  # this is the value to minimize\n",
    "\n",
    "\n",
    "# Optimize\n",
    "logging.info(f\"Let's start the work\")\n",
    "study = optuna.create_study(sampler=TPESampler() , direction='minimize') \n",
    "study.optimize(objective, n_trials=500 ,  n_jobs=-1)\n",
    "\n",
    "print(f\"Best parameters: {study.best_params}\")\n",
    "logging.info(f\"Best parameters: {study.best_params}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4346754f-f7f1-42fb-a76c-153301c0c1e5",
   "metadata": {},
   "source": [
    "> Maximizing the mcc :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948ecb3a-8393-4a77-9b69-61e0018fc542",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available\n",
    "\n",
    "def train(model, data, optimizer, criterion, edge_type):\n",
    "    model.train()\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    edge_labels = data[edge_type].edge_label\n",
    "    loss = criterion(out, edge_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data, criterion, edge_type):\n",
    "    model.eval()\n",
    "    data = data.to(device)\n",
    "    out = model(data)\n",
    "    edge_labels = data[edge_type].edge_label\n",
    "    val_loss = criterion(out, edge_labels)\n",
    "    probs = torch.sigmoid(out)\n",
    "    pred_class = probs.round()\n",
    "    all_preds = pred_class.cpu().numpy()\n",
    "    all_labels = edge_labels.cpu().numpy()\n",
    "    all_probs = probs.cpu().numpy()\n",
    "    # Calculate the metrics\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')  # Calculate recall\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)  # Calculate MCC\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    return val_loss.item(), f1, precision, recall, mcc, accuracy, auc  # Include recall and MCC in return values\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "    hidden_channels = trial.suggest_int('hidden_channels', 500, 1280, step=50)\n",
    "    dropout = trial.suggest_uniform('dropout', 0, 0.5)\n",
    "    heads = trial.suggest_int('heads', 1, 8, step=1)\n",
    "    # Define and train the model using the given hyperparameters\n",
    "    model = Model(hidden_channels, heads,dropout=dropout).to(device)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    edge_type = (\"B1\", \"infects\", \"A\")\n",
    "    best_mcc = float('-inf')\n",
    "    for epoch in range(3000):\n",
    "        train_loss = train(model, train_data, optimizer, criterion, edge_type)\n",
    "        if epoch % 10 == 0:\n",
    "            val_loss, f1, precision, recall, mcc, accuracy, auc = evaluate(model, test_data, criterion, edge_type)\n",
    "            logging.info(f\"lr:{lr}\\thidden_channels:{hidden_channels}\\tdropout:{dropout}\\tf1:{f1}\\tprecision:{precision}\\tmcc:{mcc}\\taccuracy:{accuracy}\\trecall:{recall}\\tauc:{auc}\")\n",
    "            # Early stopping based on MCC\n",
    "            if mcc >= best_mcc:\n",
    "                best_mcc = mcc\n",
    "            else:\n",
    "                logging.info(f\"Next round after {epoch} epochs\")\n",
    "                break\n",
    "    return best_mcc\n",
    "\n",
    "# Optimize\n",
    "logging.info(f\"Let's start the work\")\n",
    "study = optuna.create_study(sampler=TPESampler() , direction='maximize')  # use as many processes as possible\n",
    "study.optimize(objective, n_trials=50, n_jobs = -1)\n",
    "\n",
    "print(f\"Best parameters: {study.best_params}\")\n",
    "logging.info(f\"Best parameters: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49deecfe-7502-4c20-beb5-e0f447ee1e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best parameters: {'lr': 0.005082551361677657, 'hidden_channels': 800, 'dropout': 0.3185921909740461, 'heads': 6}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01c28bc-f270-47c3-9cfd-c7861e15c7e3",
   "metadata": {},
   "source": [
    "> Make predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20706f1b-3b54-499f-b04d-fd12e2116f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, data):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    data = data.to(device)  # Transfer the data to the device\n",
    "    with torch.no_grad():  # No need to track gradients for prediction\n",
    "        output = model(data)\n",
    "    probabilities = torch.sigmoid(output)  # Convert output to probabilities\n",
    "    predictions = probabilities.round()  # Convert probabilities to class labels\n",
    "    return predictions.cpu().numpy(), probabilities.cpu().numpy()\n",
    "\n",
    "# Load the saved model\n",
    "hidden_channels = 1000  # this should be the same value you used during training #used to be 1000\n",
    "model = Model(hidden_channels)\n",
    "model.load_state_dict(torch.load(f\"{path_work}/GATConv.model.single_batch.1807.pt\"))\n",
    "model = model.to(device)\n",
    "\n",
    "# Predict using the new data\n",
    "new_data = ...  # load or create new data here. It should have the same format as your training/test data\n",
    "predictions, probabilities = make_predictions(model, new_data)\n",
    "\n",
    "print(f\"Predictions: {predictions}\")\n",
    "print(f\"Probabilities: {probabilities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16536c4-57c4-4a11-8896-9635e254d37a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2296441-d26b-4353-81c0-1b014bb568bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a858c3-82d8-4ff2-b336-82c10753361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData, DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, HeteroConv , GATConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder , label_binarize , OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import random\n",
    "from collections import Counter\n",
    "import optuna\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# *****************************************************************************\n",
    "# Load the Dataframes :\n",
    "path_work = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "logging.basicConfig(filename = f\"{path_work}/optuna_2107.loss.log\",format='%(asctime)s | %(levelname)s: %(message)s', level=logging.NOTSET,filemode='w')\n",
    "\n",
    "graph_data = torch.load(f'{path_work}/train_nn/graph_file.1107.pt')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available\n",
    "\n",
    "# *****************************************************************************\n",
    "# The model : dot product\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, edge_type , hidden_channels, dropout, heads, conv=GATConv):\n",
    "        super().__init__()\n",
    "        self.conv = conv((-1,-1), hidden_channels, add_self_loops = False, heads = heads, dropout = dropout)\n",
    "        self.hetero_conv = HeteroConv({edge_type: self.conv})\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x = self.hetero_conv(x_dict, edge_index_dict)\n",
    "        return x\n",
    "# Dot product :\n",
    "class Classifier(torch.nn.Module):\n",
    "    def forward(self, x_dict_A , x_dict_B1, edge_index):\n",
    "        edge_type = (\"B1\", \"infects\", \"A\")\n",
    "        edge_feat_A = x_dict_A[\"A\"][edge_index[edge_type].edge_label_index[1]]\n",
    "        edge_feat_B1 = x_dict_B1[\"B1\"][edge_index[edge_type].edge_label_index[0]]\n",
    "        return (edge_feat_A * edge_feat_B1).sum(dim=-1)\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, out_channels, dropout):\n",
    "        super().__init__()\n",
    "        self.single_layer_model = GNN((\"B2\", \"expressed\", \"B1\") , out_channels, dropout)\n",
    "        self.second_layer_model = GNN((\"B1\", \"infects\", \"A\") , out_channels, dropout)\n",
    "        self.classifier_dot = Classifier()\n",
    "\n",
    "    def forward(self, graph_data):\n",
    "        b1_nodes = self.single_layer_model(graph_data.x_dict , graph_data.edge_index_dict)\n",
    "        updated_dict = {}\n",
    "        updated_dict[\"A\"], updated_dict[\"B2\"] = graph_data.x_dict[\"A\"], graph_data.x_dict[\"B2\"]\n",
    "        updated_dict[\"B1\"] = b1_nodes[\"B1\"]\n",
    "        a_nodes = self.second_layer_model(updated_dict , graph_data.edge_index_dict)\n",
    "        dot_product = self.classifier_dot(a_nodes ,b1_nodes , graph_data)\n",
    "\n",
    "        return dot_product\n",
    "# *****************************************************************************\n",
    "# Pre-process data :\n",
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.2,\n",
    "    #disjoint_train_ratio=...,\n",
    "    neg_sampling_ratio=1.0,\n",
    "    add_negative_train_samples=True,\n",
    "    edge_types=(\"B1\", \"infects\", \"A\"),\n",
    "    rev_edge_types=(\"A\", \"harbors\", \"B1\"),\n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(graph_data)\n",
    "\n",
    "\n",
    "def train(model, data, optimizer, criterion, edge_type):\n",
    "    model.train()\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    edge_labels = data[edge_type].edge_label\n",
    "    loss = criterion(out, edge_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data, criterion, edge_type):\n",
    "    model.eval()\n",
    "    data = data.to(device)\n",
    "    out = model(data)\n",
    "    edge_labels = data[edge_type].edge_label\n",
    "    val_loss = criterion(out, edge_labels)\n",
    "    probs = torch.sigmoid(out)\n",
    "    pred_class = probs.round()\n",
    "    all_preds = pred_class.cpu().numpy()\n",
    "    all_labels = edge_labels.cpu().numpy()\n",
    "    all_probs = probs.cpu().numpy()\n",
    "    # Calculate the metrics\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')  # Calculate recall\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)  # Calculate MCC\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    return val_loss.item(), f1, precision, recall, mcc, accuracy, auc  # Include recall and MCC in return values\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "    hidden_channels = trial.suggest_int('hidden_channels', 500, 1280, step=50)\n",
    "    dropout = trial.suggest_uniform('dropout', 0, 0.5)\n",
    "    heads = trial.suggest_int('heads', 0, 8, step=1)\n",
    "    # Define and train the model using the given hyperparameters\n",
    "    model = Model(hidden_channels, dropout=dropout,heads=heads).to(device)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    edge_type = (\"B1\", \"infects\", \"A\")\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(5000):\n",
    "        train_loss = train(model, train_data, optimizer, criterion, edge_type)\n",
    "        if epoch % 10 == 0:\n",
    "            val_loss, f1, precision, recall, mcc, accuracy, auc = evaluate(model, test_data, criterion, edge_type)\n",
    "            logging.info(f\"lr:{lr}\\thidden_channels:{hidden_channels}\\tdropout:{dropout}\\tf1:{f1}\\tprecision:{precision}\\tmcc:{mcc}\\taccuracy:{accuracy}\\trecall:{recall}\\tauc:{auc}\")\n",
    "            if val_loss <= best_loss:\n",
    "                best_loss = val_loss\n",
    "            else:\n",
    "                break  # stop training if the validation loss does not decrease\n",
    "    return best_loss  # this is the value to minimize\n",
    "# Optimize\n",
    "logging.info(f\"Let's start the work\")\n",
    "study = optuna.create_study(direction='minimize')  # use as many processes as possible\n",
    "study.optimize(objective, n_trials=50, n_jobs = -1)\n",
    "\n",
    "print(f\"Best parameters: {study.best_params}\")\n",
    "logging.info(f\"Best parameters: {study.best_params}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_geometric",
   "language": "python",
   "name": "torch_geometric"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
