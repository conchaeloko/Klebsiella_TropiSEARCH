{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa33c38-5163-4604-8289-ab150e56365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData, DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, HeteroConv , GATConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "import torch\n",
    "from torch import nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder , label_binarize , OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import random\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ebc72a-8a3b-4fd0-80e5-1c992c41fef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "# Load the Dataframes :\n",
    "path_work = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "graph_data = torch.load(f'{path_work}/train_nn/graph_file.1107.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f3e810-dced-4196-adc1-5e8dca77d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "# The model : dot product\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, edge_type , hidden_channels, conv=GATConv): # GCNConv(-1, 64) , SAGEConv((-1, -1), 64), GATConv((-1, -1), 64)\n",
    "        super().__init__()\n",
    "        self.conv = conv((-1,-1), hidden_channels, add_self_loops = False, heads = 3, dropout = 0.1)\n",
    "        self.hetero_conv = HeteroConv({edge_type: self.conv})\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x = self.hetero_conv(x_dict, edge_index_dict)\n",
    "        return x\n",
    "\n",
    "# Dot product :\n",
    "class Classifier(torch.nn.Module):\n",
    "    def forward(self, x_dict_A , x_dict_B1, edge_index):\n",
    "        edge_type = (\"B1\", \"infects\", \"A\")\n",
    "        edge_feat_A = x_dict_A[\"A\"][edge_index[edge_type].edge_label_index[1]]\n",
    "        edge_feat_B1 = x_dict_B1[\"B1\"][edge_index[edge_type].edge_label_index[0]]\n",
    "        return (edge_feat_A * edge_feat_B1).sum(dim=-1)\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__()\n",
    "        self.single_layer_model = GNN((\"B2\", \"expressed\", \"B1\") , out_channels)\n",
    "        self.second_layer_model = GNN((\"B1\", \"infects\", \"A\") , out_channels)\n",
    "        self.classifier_dot = Classifier()\n",
    "\n",
    "    def forward(self, graph_data):\n",
    "        b1_nodes = self.single_layer_model(graph_data.x_dict , graph_data.edge_index_dict)\n",
    "        updated_dict = {}\n",
    "        updated_dict[\"A\"], updated_dict[\"B2\"] = graph_data.x_dict[\"A\"], graph_data.x_dict[\"B2\"]\n",
    "        updated_dict[\"B1\"] = b1_nodes[\"B1\"]\n",
    "        a_nodes = self.second_layer_model(updated_dict , graph_data.edge_index_dict)\n",
    "        dot_product = self.classifier_dot(a_nodes ,b1_nodes , graph_data)\n",
    "\n",
    "        return dot_product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181dd7d0-b3c3-4d74-baf7-d337b79778ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "# Pre-process data :\n",
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1, \n",
    "    num_test=0.2, \n",
    "    #disjoint_train_ratio=...,  \n",
    "    neg_sampling_ratio=1.0,  \n",
    "    add_negative_train_samples=True, \n",
    "    edge_types=(\"B1\", \"infects\", \"A\"),\n",
    "    rev_edge_types=(\"A\", \"harbors\", \"B1\"), \n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(graph_data)\n",
    "\n",
    "'''train_loader = LinkNeighborLoader(\n",
    "    data=train_data,  \n",
    "    num_neighbors= [-1],  \n",
    "    edge_label_index=((\"B1\", \"infects\", \"A\"), train_data[\"B1\", \"infects\", \"A\"].edge_label_index),\n",
    "    edge_label=train_data[\"B1\", \"infects\", \"A\"].edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = LinkNeighborLoader(\n",
    "    data=val_data,  \n",
    "    num_neighbors= [-1],  \n",
    "    edge_label_index=((\"B1\", \"infects\", \"A\"), val_data[\"B1\", \"infects\", \"A\"].edge_label_index),\n",
    "    edge_label=val_data[\"B1\", \"infects\", \"A\"].edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_loader = LinkNeighborLoader(\n",
    "    data=test_data,  \n",
    "    num_neighbors= [-1],  \n",
    "    edge_label_index=((\"B1\", \"infects\", \"A\"), test_data[\"B1\", \"infects\", \"A\"].edge_label_index),\n",
    "    edge_label=test_data[\"B1\", \"infects\", \"A\"].edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057d2b72-ea26-4515-a1b4-127288aab63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "# Training :\n",
    "\n",
    "def train(model, data, optimizer, criterion, edge_type):\n",
    "    model.train()\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    edge_labels = data[edge_type].edge_label\n",
    "    loss = criterion(out, edge_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data, criterion, edge_type):\n",
    "    model.eval()\n",
    "    data = data.to(device)\n",
    "    out = model(data)\n",
    "    edge_labels = data[edge_type].edge_label\n",
    "    val_loss = criterion(out, edge_labels)\n",
    "    probs = torch.sigmoid(out)\n",
    "    pred_class = probs.round()\n",
    "    all_preds = pred_class.cpu().numpy()\n",
    "    all_labels = edge_labels.cpu().numpy()\n",
    "    all_probs = probs.cpu().numpy()\n",
    "    # Calculate the metrics\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')  # Calculate recall\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)  # Calculate MCC\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    return val_loss.item(), f1, precision, recall, mcc, accuracy, auc  # Include recall and MCC in return values\n",
    "\n",
    "def main():\n",
    "    hidden_channels = 1000 # 1280\n",
    "    model = Model(hidden_channels).to(device)\n",
    "    model(train_data)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    # Add weigth decay to prevent overfitting ! \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00001) #weight_decay=0.001\n",
    "    edge_type = (\"B1\", \"infects\", \"A\")\n",
    "    for epoch in range(3000):\n",
    "        train_loss = train(model, train_data, optimizer, criterion, edge_type)\n",
    "        if epoch % 10 == 0:\n",
    "            # Get all metrics including recall and MCC from evaluate function\n",
    "            test_loss, f1, precision, recall, mcc, accuracy, auc = evaluate(model, test_data, criterion, edge_type)\n",
    "            print(f'Epoch: {epoch}, Train Loss: {train_loss}, Test Loss: {test_loss}, F1 Score: {f1}, Precision: {precision}, Recall: {recall}, MCC: {mcc}, Accuracy: {accuracy}, AUC: {auc}')\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), f\"{path_work}/GATConv.model.single_batch.1807.pt\")\n",
    "    # The final eval : \n",
    "    print(\"Final evaluation ...\")\n",
    "    val_loss, f1, precision, recall, mcc, accuracy, auc = evaluate(model, val_data, criterion, edge_type)\n",
    "    print(f'F1 Score: {f1}, Precision: {precision}, Recall: {recall}, MCC: {mcc}, Accuracy: {accuracy}, AUC: {auc}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01c28bc-f270-47c3-9cfd-c7861e15c7e3",
   "metadata": {},
   "source": [
    "> Make predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20706f1b-3b54-499f-b04d-fd12e2116f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, data):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    data = data.to(device)  # Transfer the data to the device\n",
    "    with torch.no_grad():  # No need to track gradients for prediction\n",
    "        output = model(data)\n",
    "    probabilities = torch.sigmoid(output)  # Convert output to probabilities\n",
    "    predictions = probabilities.round()  # Convert probabilities to class labels\n",
    "    return predictions.cpu().numpy(), probabilities.cpu().numpy()\n",
    "\n",
    "# Load the saved model\n",
    "hidden_channels = 1000  # this should be the same value you used during training #used to be 1000\n",
    "model = Model(hidden_channels)\n",
    "model.load_state_dict(torch.load(f\"{path_work}/GATConv.model.single_batch.1807.pt\"))\n",
    "model = model.to(device)\n",
    "\n",
    "# Predict using the new data\n",
    "new_data = ...  # load or create new data here. It should have the same format as your training/test data\n",
    "predictions, probabilities = make_predictions(model, new_data)\n",
    "\n",
    "print(f\"Predictions: {predictions}\")\n",
    "print(f\"Probabilities: {probabilities}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_geometric",
   "language": "python",
   "name": "torch_geometric"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
