{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a6b12f-933c-4200-b1a8-0ef0b728a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData, DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, to_hetero , SAGEConv , HeteroConv , GATConv, GATv2Conv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "import torch\n",
    "from torch import nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder , label_binarize , OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score , matthews_corrcoef\n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import random\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "# *****************************************************************************\n",
    "# Load the Dataframes :\n",
    "path_work = \"/media/concha-eloko/Linux/PPT_clean\"\n",
    "graph_data = torch.load(f'{path_work}/graph_file.2407.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "973e251b-9b5f-4254-ab71-bc6a3d2f5836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mA\u001b[0m={ x=[4530, 127] },\n",
       "  \u001b[1mB1\u001b[0m={ x=[11339, 0] },\n",
       "  \u001b[1mB2\u001b[0m={ x=[3608, 1280] },\n",
       "  \u001b[1m(B1, infects, A)\u001b[0m={\n",
       "    edge_index=[2, 7731],\n",
       "    y=[7731]\n",
       "  },\n",
       "  \u001b[1m(B2, expressed, B1)\u001b[0m={\n",
       "    edge_index=[2, 13285],\n",
       "    y=[13285]\n",
       "  },\n",
       "  \u001b[1m(A, harbors, B1)\u001b[0m={\n",
       "    edge_index=[2, 7731],\n",
       "    y=[7731]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d6e6f10-45f5-460a-9243-59ef307d0674",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Binary classification \n",
    "# *****************************************************************************\n",
    "logging.basicConfig(filename = f\"{path_work}/GATConv.log\",format='%(asctime)s | %(levelname)s: %(message)s', level=logging.NOTSET, filemode='w')\n",
    "\n",
    "# The model : dot product\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, edge_type , conv, hidden_channels, heads, dropout): # GCNConv(-1, 64) , SAGEConv((-1, -1), 64), GATConv((-1, -1), 64)\n",
    "        super().__init__()\n",
    "        self.conv = conv((-1,-1), hidden_channels, add_self_loops = False, heads = heads, dropout = dropout, shared_weights = True)\n",
    "        self.hetero_conv = HeteroConv({edge_type: self.conv})\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x = self.hetero_conv(x_dict, edge_index_dict)  \n",
    "        return x\n",
    "\n",
    "# Classifier, Binary :\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, heads):\n",
    "        super().__init__()\n",
    "        self.lin1 = torch.nn.Linear(heads*hidden_channels + 127, 512)\n",
    "        self.lin2 = torch.nn.Linear(512, 1)\n",
    "        \n",
    "    def forward(self, x_dict_A , x_dict_B1, graph_data):\n",
    "        edge_type = (\"B1\", \"infects\", \"A\")\n",
    "        edge_feat_A = x_dict_A[\"A\"][graph_data[edge_type].edge_label_index[1]]\n",
    "        edge_feat_B1 = x_dict_B1[\"B1\"][graph_data[edge_type].edge_label_index[0]]\n",
    "        features_phage = torch.cat((edge_feat_A ,edge_feat_B1), dim=-1)\n",
    "        x = self.lin1(features_phage).relu()\n",
    "        x = self.lin2(x)\n",
    "        return x.view(-1)\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, conv, hidden_channels, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.single_layer_model = GNN((\"B2\", \"expressed\", \"B1\") ,conv, hidden_channels,heads,dropout) \n",
    "        self.EdgeDecoder = EdgeDecoder(hidden_channels,heads)\n",
    "        \n",
    "    def forward(self, graph_data):\n",
    "        b1_nodes = self.single_layer_model(graph_data.x_dict , graph_data.edge_index_dict)\n",
    "        a_nodes =  graph_data.x_dict\n",
    "        out = self.EdgeDecoder(a_nodes ,b1_nodes , graph_data)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5453b88e-b722-49cf-aab3-21a9fdcd3e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass classification \n",
    "# *****************************************************************************\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "logging.basicConfig(filename = f\"{path_work}/GATConv.log\",format='%(asctime)s | %(levelname)s: %(message)s', level=logging.NOTSET, filemode='w')\n",
    "\n",
    "# The model : dot product\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, edge_type , conv, hidden_channels, heads, dropout): # GCNConv(-1, 64) , SAGEConv((-1, -1), 64), GATConv((-1, -1), 64)\n",
    "        super().__init__()\n",
    "        self.conv = conv((-1,-1), hidden_channels, add_self_loops = False, heads = heads, dropout = dropout, shared_weights = True)\n",
    "        self.hetero_conv = HeteroConv({edge_type: self.conv})\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x = self.hetero_conv(x_dict, edge_index_dict)  \n",
    "        return x\n",
    "\n",
    "# Classifier, multiclass :\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, heads):\n",
    "        super().__init__()\n",
    "        self.lin1 = torch.nn.Linear(heads*hidden_channels, 512)\n",
    "        self.lin2 = torch.nn.Linear(512, 127)\n",
    "        \n",
    "    def forward(self , x_dict_B1, graph_data):\n",
    "        edge_type = (\"B1\", \"infects\", \"A\")\n",
    "        edge_feat_B1 = x_dict_B1[\"B1\"][graph_data[edge_type].edge_label_index[0]]\n",
    "        x = self.lin1(edge_feat_B1).relu()\n",
    "        x = self.lin2(x)\n",
    "        return x \n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, conv, hidden_channels, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.single_layer_model = GNN((\"B2\", \"expressed\", \"B1\") ,conv, hidden_channels,heads,dropout) \n",
    "        self.EdgeDecoder = EdgeDecoder(hidden_channels,heads)\n",
    "        \n",
    "    def forward(self, graph_data):\n",
    "        b1_nodes = self.single_layer_model(graph_data.x_dict , graph_data.edge_index_dict)\n",
    "        a_nodes =  graph_data.x_dict\n",
    "        out = self.EdgeDecoder(b1_nodes , graph_data)\n",
    "        labels = graph_data.x_dict[\"A\"]\n",
    "        return out , labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c637cd56-51e5-4eca-940a-0a0cb6dd8882",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = Model(GATConv , 1000, 3, 0.1)\n",
    "out, labels = model_test(sampled_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2197ff8b-0f2c-4ec3-9c9a-787e2264f757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff0f038e-ce6b-49bf-a406-1fef88c6f464",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "# Pre-process data :\n",
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1, \n",
    "    num_test=0.2, \n",
    "    #disjoint_train_ratio=...,  \n",
    "    neg_sampling_ratio=1.0,  \n",
    "    add_negative_train_samples=True, \n",
    "    edge_types=(\"B1\", \"infects\", \"A\"),\n",
    "    rev_edge_types=(\"A\", \"harbors\", \"B1\"), \n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(graph_data)\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,  \n",
    "    num_neighbors= [-1],  \n",
    "    edge_label_index=((\"B1\", \"infects\", \"A\"), train_data[\"B1\", \"infects\", \"A\"].edge_label_index),\n",
    "    edge_label=train_data[\"B1\", \"infects\", \"A\"].edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = LinkNeighborLoader(\n",
    "    data=val_data,  \n",
    "    num_neighbors= [-1],  \n",
    "    edge_label_index=((\"B1\", \"infects\", \"A\"), val_data[\"B1\", \"infects\", \"A\"].edge_label_index),\n",
    "    edge_label=val_data[\"B1\", \"infects\", \"A\"].edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_loader = LinkNeighborLoader(\n",
    "    data=test_data,  \n",
    "    num_neighbors= [-1],  \n",
    "    edge_label_index=((\"B1\", \"infects\", \"A\"), test_data[\"B1\", \"infects\", \"A\"].edge_label_index),\n",
    "    edge_label=test_data[\"B1\", \"infects\", \"A\"].edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "128306ce-dc4b-4eaa-8239-762269f6fda3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data = next(iter(train_loader))\n",
    "\n",
    "sampled_data.edge_index_dict[(\"B1\", \"infects\", \"A\")]\n",
    "sampled_data.x_dict[\"A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0ef30d-1ffc-4e8f-aa92-caa1c424d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "# Training : Binary \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available\n",
    "\n",
    "def train(model, data, optimizer, criterion, edge_type):\n",
    "    model.train()\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    edge_labels = data[edge_type].edge_label\n",
    "    loss = criterion(out, edge_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data, criterion, edge_type):\n",
    "    model.eval()\n",
    "    data = data.to(device)\n",
    "    out = model(data)\n",
    "    edge_labels = data[edge_type].edge_label\n",
    "    val_loss = criterion(out, edge_labels)\n",
    "    probs = torch.sigmoid(out)\n",
    "    pred_class = probs.round()\n",
    "    all_preds = pred_class.cpu().numpy()\n",
    "    all_labels = edge_labels.cpu().numpy()\n",
    "    all_probs = probs.cpu().numpy()\n",
    "    # Calculate the metrics\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')  # Calculate recall\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)  # Calculate MCC\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    return val_loss.item(), f1, precision, recall, mcc, accuracy, auc  # Include recall and MCC in return values\n",
    "\n",
    "def main():\n",
    "    hidden_channels = 1000\n",
    "    lr = 0.0001\n",
    "    conv = GATConv\n",
    "    heads = 3\n",
    "    dropout = 0.1\n",
    "    logging.info(f\"Let's start the work with {conv}\\t{hidden_channels}\\t{dropout}\\t{lr}\\t{heads}\")\n",
    "    model = Model(conv,hidden_channels,heads,dropout).to(device)\n",
    "    model(train_data)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr) #lr=0.00001, weight_decay=0.001\n",
    "    edge_type = (\"B1\", \"infects\", \"A\")\n",
    "    for epoch in range(3000):\n",
    "        train_loss = train(model, train_data, optimizer, criterion, edge_type)\n",
    "        if epoch % 10 == 0:\n",
    "            # Get all metrics including recall and MCC from evaluate function\n",
    "            test_loss, f1, precision, recall, mcc, accuracy, auc = evaluate(model, test_data, criterion, edge_type)\n",
    "            info_training = f'Epoch: {epoch}, Train Loss: {train_loss}, Test Loss: {test_loss}, F1 Score: {f1}, Precision: {precision}, Recall: {recall}, MCC: {mcc}, Accuracy: {accuracy}, AUC: {auc}'\n",
    "            logging.info(info_training)\n",
    "            print(info_training)\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), f\"{path_work}/{conv}.model.single_batch.2407.pt\")\n",
    "    # The final eval : \n",
    "    print(\"Final evaluation ...\")\n",
    "    val_loss, f1, precision, recall, mcc, accuracy, auc = evaluate(model, val_data, criterion, edge_type)\n",
    "    print(f'F1 Score: {f1}, Precision: {precision}, Recall: {recall}, MCC: {mcc}, Accuracy: {accuracy}, AUC: {auc}')\n",
    "    logging.info(f\"Final evaluation ...\\nF1 Score: {f1}, Precision: {precision}, Recall: {recall}, MCC: {mcc}, Accuracy: {accuracy}, AUC: {auc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c7dbc-540c-4ca0-9c5e-deb587bfa10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "# Training : Multiclass :\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available\n",
    "\n",
    "def train(model, data, optimizer, criterion):\n",
    "    model.train()\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    out, labels = model(data)\n",
    "    labels = torch.argmax(labels, dim=1)  # one-hot to indices\n",
    "    loss = criterion(out, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data, criterion, num_classes):\n",
    "    model.eval()\n",
    "    data = data.to(device)\n",
    "    out, labels = model(data)\n",
    "    labels = torch.argmax(labels, dim=1)  # one-hot to indices\n",
    "    val_loss = criterion(out, labels)\n",
    "    pred_class = out.argmax(dim=1)\n",
    "    accuracy = (pred_class == labels).sum().item() / labels.size(0)\n",
    "    per_class_accuracy = [(pred_class[labels == i] == labels[labels == i]).sum().item() / (labels == i).sum().item() for i in range(num_classes)]\n",
    "    conf_mat = confusion_matrix(labels.cpu().numpy(), pred_class.cpu().numpy())\n",
    "    auc_roc = roc_auc_score(label_binarize(labels.cpu().numpy(), classes=range(num_classes)), out.cpu().detach().numpy(), multi_class='ovr')\n",
    "    return val_loss.item(), accuracy, per_class_accuracy, conf_mat, auc_roc\n",
    "\n",
    "def main():\n",
    "    hidden_channels = 1000\n",
    "    lr = 0.0001\n",
    "    conv = GATConv\n",
    "    heads = 3\n",
    "    dropout = 0.1\n",
    "    num_classes = 127  # modify this to match your number of classes\n",
    "    logging.info(f\"Let's start the work with {conv}\\t{hidden_channels}\\t{dropout}\\t{lr}\\t{heads}\")\n",
    "    model = Model(conv,hidden_channels,heads,dropout).to(device)\n",
    "    criterion = CrossEntropyLoss()  # Use CrossEntropyLoss for multi-class tasks\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr) \n",
    "    for epoch in range(3000):\n",
    "        train_loss = train(model, train_data, optimizer, criterion)\n",
    "        if epoch % 10 == 0:\n",
    "            val_loss, accuracy, per_class_accuracy, conf_mat, auc_roc = evaluate(model, test_data, criterion, num_classes)\n",
    "            info_training = f'Epoch: {epoch}, Train Loss: {train_loss}, Test Loss: {val_loss}, Accuracy: {accuracy}, Per Class Accuracy: {per_class_accuracy}, Confusion Matrix: {conf_mat}, AUC_ROC: {auc_roc}'\n",
    "            logging.info(info_training)\n",
    "            print(info_training)\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), f\"{path_work}/{conv}.model.single_batch.2407.pt\")\n",
    "    # The final eval : \n",
    "    print(\"Final evaluation ...\")\n",
    "    val_loss, accuracy, per_class_accuracy, conf_mat, auc_roc = evaluate(model, val_data, criterion, num_classes)\n",
    "    print(f'Final Test Loss: {val_loss}, Accuracy: {accuracy}, Per Class Accuracy: {per_class_accuracy}, Confusion Matrix: {conf_mat}, AUC_ROC: {auc_roc}')\n",
    "    logging.info(f\"Final evaluation ...\\nFinal Test Loss: {val_loss}, Accuracy: {accuracy}, Per Class Accuracy: {per_class_accuracy}, Confusion Matrix: {conf_mat}, AUC_ROC: {auc_roc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3127bfc2-7967-43c6-aad2-ae95d5459067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f836377-0995-4cee-aa4d-ca45f51dbe39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c577d263-a419-4abe-9df1-fe4fe7419f9d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_geometric",
   "language": "python",
   "name": "torch_geometric"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
