{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aa33c38-5163-4604-8289-ab150e56365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData, DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, HeteroConv , GATConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "import torch\n",
    "from torch import nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder , label_binarize , OneHotEncoder\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, matthews_corrcoef, accuracy_score, roc_auc_score\n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import random\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73ebc72a-8a3b-4fd0-80e5-1c992c41fef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "# Load the Dataframes :\n",
    "path_work = \"/media/concha-eloko/Linux/PPT_clean\"\n",
    "graph_data = torch.load(f'{path_work}/graph_file.1107.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee796efb-42df-40e8-b603-224bcec3a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "# Load the Dataframes :\n",
    "path_work = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/depolymerase_decipher/ficheros_28032023\"\n",
    "graph_data = torch.load(f'{path_work}/train_nn/graph_file.1107.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab16fcf-c591-4f48-b87f-a248ad14ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model : dot product\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, edge_type , hidden_channels, conv=GATConv): # GCNConv(-1, 64) , SAGEConv((-1, -1), 64), GATConv((-1, -1), 64)\n",
    "        super().__init__()\n",
    "        self.conv = conv((-1,-1), hidden_channels, add_self_loops = False, heads = 3, dropout = 0.1)\n",
    "        self.hetero_conv = HeteroConv({edge_type: self.conv})\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x = self.hetero_conv(x_dict, edge_index_dict)  \n",
    "        return x\n",
    "\n",
    "# Dot product :\n",
    "class Classifier(torch.nn.Module):\n",
    "    def forward(self, x_dict_A , x_dict_B1, edge_index):\n",
    "        edge_type = (\"B1\", \"infects\", \"A\")\n",
    "        edge_feat_A = x_dict_A[\"A\"][edge_index[edge_type].edge_label_index[1]]\n",
    "        edge_feat_B1 = x_dict_B1[\"B1\"][edge_index[edge_type].edge_label_index[0]]\n",
    "        return (edge_feat_A * edge_feat_B1).sum(dim=-1)\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, out_channels , conv=GATConv):\n",
    "        super().__init__()\n",
    "        self.single_layer_model = GNN((\"B2\", \"expressed\", \"B1\") , out_channels) \n",
    "        self.second_layer_model = GNN((\"B1\", \"infects\", \"A\") , out_channels)\n",
    "        self.classifier_dot = Classifier()\n",
    "        \n",
    "    def forward(self, graph_data):\n",
    "        b1_nodes = self.single_layer_model(graph_data.x_dict , graph_data.edge_index_dict)\n",
    "        updated_dict = {}\n",
    "        updated_dict[\"A\"], updated_dict[\"B2\"] = graph_data.x_dict[\"A\"], graph_data.x_dict[\"B2\"]\n",
    "        updated_dict[\"B1\"] = b1_nodes[\"B1\"]\n",
    "        a_nodes = self.second_layer_model(updated_dict , graph_data.edge_index_dict)\n",
    "        dot_product = self.classifier_dot(a_nodes ,b1_nodes , graph_data)\n",
    "        \n",
    "        return dot_product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "181dd7d0-b3c3-4d74-baf7-d337b79778ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "# Pre-process data :\n",
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1, \n",
    "    num_test=0.2, \n",
    "    #disjoint_train_ratio=...,  \n",
    "    neg_sampling_ratio=1.0,  \n",
    "    add_negative_train_samples=True, \n",
    "    edge_types=(\"B1\", \"infects\", \"A\"),\n",
    "    rev_edge_types=(\"A\", \"harbors\", \"B1\"), \n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(graph_data)\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,  \n",
    "    num_neighbors= [-1],  \n",
    "    edge_label_index=((\"B1\", \"infects\", \"A\"), train_data[\"B1\", \"infects\", \"A\"].edge_label_index),\n",
    "    edge_label=train_data[\"B1\", \"infects\", \"A\"].edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = LinkNeighborLoader(\n",
    "    data=val_data,  \n",
    "    num_neighbors= [-1],  \n",
    "    edge_label_index=((\"B1\", \"infects\", \"A\"), val_data[\"B1\", \"infects\", \"A\"].edge_label_index),\n",
    "    edge_label=val_data[\"B1\", \"infects\", \"A\"].edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_loader = LinkNeighborLoader(\n",
    "    data=test_data,  \n",
    "    num_neighbors= [-1],  \n",
    "    edge_label_index=((\"B1\", \"infects\", \"A\"), test_data[\"B1\", \"infects\", \"A\"].edge_label_index),\n",
    "    edge_label=test_data[\"B1\", \"infects\", \"A\"].edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2f05063-4fd8-42a8-a0b5-92b62f6eb8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mA\u001b[0m={\n",
       "    x=[157, 127],\n",
       "    n_id=[157]\n",
       "  },\n",
       "  \u001b[1mB1\u001b[0m={\n",
       "    x=[270, 0],\n",
       "    n_id=[270]\n",
       "  },\n",
       "  \u001b[1mB2\u001b[0m={\n",
       "    x=[139, 1280],\n",
       "    n_id=[139]\n",
       "  },\n",
       "  \u001b[1m(B1, infects, A)\u001b[0m={\n",
       "    edge_index=[2, 250],\n",
       "    y=[250],\n",
       "    edge_label=[128],\n",
       "    edge_label_index=[2, 128],\n",
       "    e_id=[250],\n",
       "    input_id=[128]\n",
       "  },\n",
       "  \u001b[1m(B2, expressed, B1)\u001b[0m={\n",
       "    edge_index=[2, 176],\n",
       "    y=[176],\n",
       "    e_id=[176]\n",
       "  },\n",
       "  \u001b[1m(A, harbors, B1)\u001b[0m={\n",
       "    edge_index=[2, 125],\n",
       "    y=[125],\n",
       "    e_id=[125]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data = next(iter(train_loader))\n",
    "\n",
    "sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec4be6c0-bb0b-41b5-bed9-a0c8682a8855",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(20)\n",
    "val = model(sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44c9bb66-5021-4803-9a32-d77be375087a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0097,  0.0120,  0.0120,  0.0120, -0.0154,  0.0123,  0.0123,  0.0123,\n",
       "         0.0123,  0.0123,  0.0123,  0.0123,  0.0123,  0.0119,  0.0119,  0.0119,\n",
       "         0.0119, -0.0036,  0.0119,  0.0119,  0.0119,  0.0117,  0.0117,  0.0117,\n",
       "         0.0034,  0.0117,  0.0123,  0.0123,  0.0123,  0.0123,  0.0123,  0.0123,\n",
       "         0.0123,  0.0120,  0.0120,  0.0120,  0.0120,  0.0120,  0.0120, -0.0057,\n",
       "         0.0120,  0.0120, -0.0291,  0.0122,  0.0122,  0.0122, -0.0085,  0.0122,\n",
       "         0.0122,  0.0122, -0.0081, -0.0130, -0.0130,  0.0116,  0.0116,  0.0123,\n",
       "         0.0123,  0.0115,  0.0115,  0.0115,  0.1085, -0.0099,  0.0113, -0.0099,\n",
       "         0.0119,  0.0119, -0.0002,  0.0119,  0.0119,  0.0119,  0.0119,  0.0119,\n",
       "         0.0123,  0.0123,  0.0792,  0.0117,  0.0792,  0.0117,  0.0117,  0.0104,\n",
       "         0.0104, -0.0090, -0.0090,  0.0115,  0.0545,  0.0121,  0.0121,  0.0121,\n",
       "         0.0121,  0.0121,  0.0121,  0.0121,  0.0121,  0.0121,  0.0121,  0.0121,\n",
       "         0.0121,  0.0121, -0.0200, -0.0200,  0.0123,  0.0844,  0.0844,  0.0118,\n",
       "         0.0118, -0.0128,  0.0123,  0.0123,  0.0123,  0.0123,  0.0114,  0.0878,\n",
       "         0.0123,  0.0697,  0.0697,  0.0697, -0.0367,  0.0123, -0.0367, -0.0367,\n",
       "        -0.0367,  0.0123, -0.0143, -0.0143, -0.0119, -0.0119,  0.0123,  0.0123,\n",
       "        -0.0095, -0.0138,  0.0092,  0.0117,  0.0117,  0.0117,  0.0117,  0.0116,\n",
       "         0.0003,  0.0116,  0.0116,  0.0234,  0.0117, -0.0137,  0.0117,  0.0117,\n",
       "         0.0119, -0.0251,  0.0119,  0.0119,  0.0830,  0.0117,  0.0117,  0.0117,\n",
       "         0.0830,  0.0123,  0.0123,  0.0122,  0.0033,  0.0033, -0.0162,  0.0117,\n",
       "         0.0774,  0.0774,  0.0123,  0.0123,  0.0123,  0.0024,  0.0024,  0.0123,\n",
       "         0.0123,  0.0545,  0.0123,  0.0123,  0.0123, -0.0118, -0.0118,  0.0123,\n",
       "         0.0123, -0.0118,  0.0122,  0.0122,  0.0997,  0.0122,  0.0122, -0.0183,\n",
       "         0.0123,  0.0123,  0.0123, -0.0124, -0.0124, -0.0040, -0.0120,  0.0117,\n",
       "        -0.0063,  0.0117, -0.0063,  0.0123, -0.0087,  0.0120, -0.0034,  0.0111,\n",
       "        -0.0130, -0.0130,  0.0123,  0.0160,  0.0160,  0.0123,  0.0123,  0.0123,\n",
       "        -0.0072, -0.0072, -0.0122, -0.0122, -0.0050, -0.0050,  0.0122,  0.0122,\n",
       "        -0.0116,  0.0892,  0.0892,  0.0113,  0.0122,  0.0122,  0.0122,  0.0853,\n",
       "         0.0123, -0.0037, -0.0079,  0.0122,  0.0766,  0.0123,  0.0034,  0.0122,\n",
       "         0.0122,  0.0122,  0.0123,  0.0122,  0.0122, -0.0687,  0.0123, -0.0718,\n",
       "         0.0122,  0.0122,  0.0123,  0.0123,  0.0123,  0.0160, -0.0638,  0.0122,\n",
       "         0.0123, -0.0704], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7c3d90-c5e3-49de-8e91-f32a9790074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "# Training :\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available\n",
    "\n",
    "def train(model, loader, optimizer, criterion, edge_type):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        edge_labels = data[edge_type].edge_label\n",
    "        loss = criterion(out, edge_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, edge_type):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []  # Collect output probabilities for AUC\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        edge_labels = data[edge_type].edge_label\n",
    "        val_loss = criterion(out, edge_labels)\n",
    "        total_loss += val_loss.item()\n",
    "        probs = torch.sigmoid(out)  # Convert output to probabilities\n",
    "        pred_class = probs.round()  # Round to nearest integer to get class predictions\n",
    "        all_preds.extend(pred_class.cpu().numpy())\n",
    "        all_labels.extend(edge_labels.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())  # Collect output probabilities\n",
    "    # Calculate the metrics\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "    precision = precision_score(all_labels, all_preds, average='binary')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')  # Calculate recall\n",
    "    mcc = matthews_corrcoef(all_labels, all_preds)  # Calculate MCC\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    return total_loss / len(loader), f1, precision, recall, mcc, accuracy, auc  # Include recall and MCC in return values\n",
    "\n",
    "def main():\n",
    "    hidden_channels = 1000\n",
    "    model = Model(hidden_channels).to(device)\n",
    "    # Due to lazy initialization, we need to run one model step so the number\n",
    "    # of parameters can be inferred:\n",
    "    eg_gratia_data = next(iter(val_loader))\n",
    "    edge_type = (\"B1\", \"infects\", \"A\")\n",
    "    with torch.no_grad():\n",
    "        model(eg_gratia_data.to(device))\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    for epoch in range(1000):\n",
    "        train_loss = train(model, train_loader, optimizer, criterion, edge_type)\n",
    "        if epoch % 10 == 0:\n",
    "            val_loss, f1, precision, recall, mcc, accuracy, auc = evaluate(model, test_loader, criterion, edge_type)\n",
    "            print(f'Epoch: {epoch}, Train Loss: {train_loss}, Val Loss: {val_loss}, F1 Score: {f1}, Precision: {precision}, Recall: {recall}, MCC: {mcc}, Accuracy: {accuracy}, AUC: {auc}')\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), f\"{path_work}/SAGEConv.dot.model.2007.pt\")\n",
    "    print(\"Final evaluation ...\")\n",
    "    val_loss, f1, precision, recall, mcc, accuracy, auc = evaluate(model, val_loader, criterion, edge_type)\n",
    "    print(f'F1 Score: {f1}, Precision: {precision}, Recall: {recall}, MCC: {mcc}, Accuracy: {accuracy}, AUC: {auc}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_geometric",
   "language": "python",
   "name": "torch_geometric"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
