{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17607d7d-c105-48e3-a251-a5109440a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData, DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, to_hetero , SAGEConv , HeteroConv , GATConv, GATv2Conv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "import torch\n",
    "from torch import nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder , label_binarize , OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score , matthews_corrcoef\n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import random\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "# *****************************************************************************\n",
    "# Load the Dataframes :\n",
    "path_work = \"/media/concha-eloko/Linux/PPT_clean\"\n",
    "graph_data = torch.load(f'{path_work}/graph_file.2607.LE.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62b1d1e6-e2b1-40d0-8c93-5eb28a8a326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "# Pre-process data :\n",
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.2,\n",
    "    add_negative_train_samples=False,\n",
    "    edge_types=(\"B1\", \"infects\", \"A\"),\n",
    "    rev_edge_types=(\"A\", \"harbors\", \"B1\"),\n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(graph_data)\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,\n",
    "    num_neighbors= [-1],\n",
    "    edge_label_index=((\"B1\", \"infects\", \"A\"), train_data[\"B1\", \"infects\", \"A\"].edge_label_index),\n",
    "    edge_label=train_data[\"B1\", \"infects\", \"A\"].edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = LinkNeighborLoader(\n",
    "    data=val_data,\n",
    "    num_neighbors= [-1],\n",
    "    edge_label_index=((\"B1\", \"infects\", \"A\"), val_data[\"B1\", \"infects\", \"A\"].edge_label_index),\n",
    "    edge_label=val_data[\"B1\", \"infects\", \"A\"].edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_loader = LinkNeighborLoader(\n",
    "    data=test_data,\n",
    "    num_neighbors= [-1],\n",
    "    edge_label_index=((\"B1\", \"infects\", \"A\"), test_data[\"B1\", \"infects\", \"A\"].edge_label_index),\n",
    "    edge_label=test_data[\"B1\", \"infects\", \"A\"].edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "047e1f4b-533c-4361-acd9-51255c5f42cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mA\u001b[0m={\n",
       "    x=[127, 127],\n",
       "    n_id=[127]\n",
       "  },\n",
       "  \u001b[1mB1\u001b[0m={\n",
       "    x=[299, 0],\n",
       "    n_id=[299]\n",
       "  },\n",
       "  \u001b[1mB2\u001b[0m={\n",
       "    x=[111, 1280],\n",
       "    n_id=[111]\n",
       "  },\n",
       "  \u001b[1m(B1, infects, A)\u001b[0m={\n",
       "    edge_index=[2, 299],\n",
       "    y=[299],\n",
       "    edge_label=[128],\n",
       "    edge_label_index=[2, 128],\n",
       "    e_id=[299],\n",
       "    input_id=[128]\n",
       "  },\n",
       "  \u001b[1m(B2, expressed, B1)\u001b[0m={\n",
       "    edge_index=[2, 155],\n",
       "    y=[155],\n",
       "    e_id=[155]\n",
       "  },\n",
       "  \u001b[1m(A, harbors, B1)\u001b[0m={\n",
       "    edge_index=[2, 128],\n",
       "    y=[128],\n",
       "    e_id=[128]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data = next(iter(train_loader))\n",
    "sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2395d67d-b01f-4ffb-ae10-e38994bece3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mA\u001b[0m={ x=[4530, 127] },\n",
       "  \u001b[1mB1\u001b[0m={ x=[11339, 0] },\n",
       "  \u001b[1mB2\u001b[0m={ x=[3608, 1280] },\n",
       "  \u001b[1m(B1, infects, A)\u001b[0m={\n",
       "    edge_index=[2, 5412],\n",
       "    y=[5412],\n",
       "    edge_label=[1546],\n",
       "    edge_label_index=[2, 1546]\n",
       "  },\n",
       "  \u001b[1m(B2, expressed, B1)\u001b[0m={\n",
       "    edge_index=[2, 13285],\n",
       "    y=[13285]\n",
       "  },\n",
       "  \u001b[1m(A, harbors, B1)\u001b[0m={\n",
       "    edge_index=[2, 5412],\n",
       "    y=[5412]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "626560c4-edf1-44c4-9283-02db3fede4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************************************\n",
    "# The model : multi class classification \n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, edge_type , conv, hidden_channels, heads, dropout): # GCNConv(-1, 64) , SAGEConv((-1, -1), 64), GATConv((-1, -1), 64)\n",
    "        super().__init__()\n",
    "        self.conv = conv((-1,-1), hidden_channels, add_self_loops = False, heads = heads, dropout = dropout, shared_weights = True)\n",
    "        self.hetero_conv = HeteroConv({edge_type: self.conv})\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x = self.hetero_conv(x_dict, edge_index_dict)  \n",
    "        return x\n",
    "\n",
    "# Classifier, multiclass :\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, heads):\n",
    "        super().__init__()\n",
    "        self.lin1 = torch.nn.Linear(heads*hidden_channels, 512)\n",
    "        self.lin2 = torch.nn.Linear(512, 127)\n",
    "        \n",
    "    def forward(self , x_dict_B1, graph_data):\n",
    "        edge_type = (\"B1\", \"infects\", \"A\")\n",
    "        labels = graph_data.x_dict[\"A\"][graph_data[edge_type].edge_label_index[1]]\n",
    "        edge_feat_B1 = x_dict_B1[\"B1\"][graph_data[edge_type].edge_label_index[0]]\n",
    "        x = self.lin1(edge_feat_B1).relu()\n",
    "        x = self.lin2(x)\n",
    "        return x , labels\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, conv, hidden_channels, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.single_layer_model = GNN((\"B2\", \"expressed\", \"B1\") ,conv, hidden_channels,heads,dropout) \n",
    "        self.EdgeDecoder = EdgeDecoder(hidden_channels,heads)\n",
    "        \n",
    "    def forward(self, graph_data):\n",
    "        b1_nodes = self.single_layer_model(graph_data.x_dict , graph_data.edge_index_dict)\n",
    "        a_nodes =  graph_data.x_dict\n",
    "        out ,labels = self.EdgeDecoder(b1_nodes , graph_data)\n",
    "        return out , labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e11c4de1-a8eb-4b93-9355-baa048644235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
       "        0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "        1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "        1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
       "        0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
       "        1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
       "        1., 1.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data[(\"B1\", \"infects\", \"A\")].edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a9b035e-4f05-4569-9a4f-fde5d513ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(GATv2Conv,20,1,0.1)\n",
    "out , labels = model(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a638b281-9b86-4f73-8104-2fd021f36e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.x_dict[\"A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddd2e99a-6e77-42b9-a0d8-31e4f1f8549a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5412"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71714ed9-9eee-4f15-802a-efb561857f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a0634d3-60ee-4037-9c91-82082811616b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_labels = set()\n",
    "for label in labels:\n",
    "    clean_labels.add(tuple(label.tolist())) \n",
    "len(clean_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41e08dbf-4a52-40de-aa01-56d85095651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_back = torch.argmax(labels, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "862d44e2-0967-4e4b-9907-428017e086b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7,  8, 39, 74, 95])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_back.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f220f757-4794-40d7-b997-c452e055a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "# Training : Multiclass :\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available\n",
    "\n",
    "def train(model, data, optimizer, criterion):\n",
    "    model.train()\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    out, labels = model(data)\n",
    "    loss = criterion(out, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data, criterion, num_classes):\n",
    "    model.eval()\n",
    "    data = data.to(device)\n",
    "    out, labels = model(data)\n",
    "    labels = torch.argmax(labels, dim=1)  # one-hot to indices\n",
    "    val_loss = criterion(out, labels)\n",
    "    pred_class = out.argmax(dim=1)\n",
    "    accuracy = (pred_class == labels).sum().item() / labels.size(0)\n",
    "    per_class_accuracy = [(pred_class[labels == i] == labels[labels == i]).sum().item() / (labels == i).sum().item() for i in range(num_classes)]\n",
    "    conf_mat = confusion_matrix(labels, pred_class)\n",
    "    auc_roc = roc_auc_score(label_binarize(labels, classes=range(num_classes)), out.cpu().detach().numpy(), multi_class='ovr')\n",
    "    return val_loss.item(), accuracy, per_class_accuracy, conf_mat, auc_roc\n",
    "\n",
    "def main():\n",
    "    hidden_channels = 1000\n",
    "    lr = 0.0001\n",
    "    conv = GATConv\n",
    "    heads = 1\n",
    "    dropout = 0.1\n",
    "    decay = 5e-4\n",
    "    num_classes = 127  # modify this to match your number of classes\n",
    "    logging.info(f\"Let's start the work with {conv}\\t{hidden_channels}\\t{dropout}\\t{lr}\\t{heads}\")\n",
    "    model = Model(conv,hidden_channels,heads,dropout).to(device)\n",
    "    criterion = CrossEntropyLoss()  \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=decay) \n",
    "    for epoch in range(3000):\n",
    "        train_loss = train(model, train_data, optimizer, criterion)\n",
    "        if epoch % 50 == 0:\n",
    "            val_loss, accuracy, per_class_accuracy, conf_mat, auc_roc = evaluate(model, test_data, criterion, num_classes)\n",
    "            info_training = f'Epoch: {epoch}, Train Loss: {train_loss}, Test Loss: {val_loss}, Accuracy: {accuracy}, Per Class Accuracy: {per_class_accuracy}, Confusion Matrix: {conf_mat}, AUC_ROC: {auc_roc}'\n",
    "            logging.info(info_training)\n",
    "            print(info_training)\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), f\"{path_work}/GATv2Conv.model.{heads}.multiclass.single_batch.2407.pt\")\n",
    "    # The final eval : \n",
    "    print(\"Final evaluation ...\")\n",
    "    val_loss, accuracy, per_class_accuracy, conf_mat, auc_roc = evaluate(model, val_data, criterion, num_classes)\n",
    "    print(f'Final Test Loss: {val_loss}, Accuracy: {accuracy}, Per Class Accuracy: {per_class_accuracy}, Confusion Matrix: {conf_mat}, AUC_ROC: {auc_roc}')\n",
    "    logging.info(f\"Final evaluation ...\\nFinal Test Loss: {val_loss}, Accuracy: {accuracy}, Per Class Accuracy: {per_class_accuracy}, Confusion Matrix: {conf_mat}, AUC_ROC: {auc_roc}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b443d7-a614-48f7-a86f-b92fbd783a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_geometric",
   "language": "python",
   "name": "torch_geometric"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
