{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **II. Prophages**<br>\n",
    "### The goal is to predict the prophages and to identify the strains in which they are present\n",
    "## 1. Prophage prediction \n",
    "## 2. FastANI process\n",
    "## 3. Inspecting FastANI output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 1. Prophage prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The prediction command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prophage annotation : \n",
    "#***********************************************************  \n",
    "from os import system, listdir, chdir, mkdir\n",
    "from os.path import isdir\n",
    "import os\n",
    "import random                                   \n",
    "path_klebsiella=\"/home/conchae/prediction_depolymerase_tropism\"\n",
    "path_phageboost=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/phageboost/phageboost_prediction\"\n",
    "\n",
    "good_strains=open(f\"{path_klebsiella}/panacota_pangenome/panacota_pangenome_list.txt\").read().split(\"\\n\")\n",
    "\n",
    "for specie in os.listdir(path_klebsiella):\n",
    "    if specie[0]==\"k\" and os.path.isdir(f\"{path_klebsiella}/{specie}\")== True:\n",
    "        for strain in random.sample(os.listdir(f\"{path_klebsiella}/{specie}/refseq/bacteria\"), len(os.listdir(f\"{path_klebsiella}/{specie}/refseq/bacteria\"))):\n",
    "            if strain in good_strains :\n",
    "                path_fna=f\"{path_klebsiella}/{specie}/refseq/bacteria/{strain}/prokka_annotation_all/{strain}.fna\"\n",
    "                path_prophage=f\"{path_phageboost}/{strain}\"\n",
    "                try :\n",
    "                    mkdir(path_prophage)\n",
    "                except FileExistsError :\n",
    "                    print(\"The output for phageboost already exists for some reason. We shall continue\")\n",
    "                if len(os.listdir(f\"{path_prophage}\")) == 0:\n",
    "                    system(f\"PhageBoost -f {path_fna} -o {path_prophage}  --threads 4\")\n",
    "                    with open(f\"{path_prophage}/process_done\",\"w\") as outfile:\n",
    "                        outfile.write(\"This strain has been studied\")\n",
    "                    \n",
    "#!/bin/bash\n",
    "#BATCH --job-name=PhageBoost_cmd\n",
    "#SBATCH --partition=medium \n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=40\n",
    "#SBATCH --mem=125gb \n",
    "#SBATCH --time=7-00:00:00 \n",
    "#SBATCH --output=PhageBoost_cmd%j.log \n",
    "\n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate PhageBoost-env\n",
    "\n",
    "python3 /home/conchae/prediction_depolymerase_tropism/script_files/prophage_prediction/phageboost_script.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Getting the prediction score for each prophage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Writting some info files ...\n",
    "from os import system, listdir, chdir, mkdir\n",
    "from os.path import isdir\n",
    "import os\n",
    "\n",
    "path_phageboost=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/phageboost\"\n",
    "\n",
    "with open(f\"{path_phageboost}/score_distribution.phageboost.csv\",\"w\") as outfile:\n",
    "    for strain in os.listdir(f\"{path_phageboost}/phageboost_prediction\") :\n",
    "        if len(os.listdir(f\"{path_phageboost}/phageboost_prediction/{strain}\")) > 2 :\n",
    "            for file in os.listdir(f\"{path_phageboost}/phageboost_prediction/{strain}\"):\n",
    "                if file[0:6]==\"phages\":\n",
    "                    info_file=open(f\"{path_phageboost}/phageboost_prediction/{strain}/{file}\").read().split(\"\\n\")[2:]\n",
    "                    for index_info, info in enumerate(info_file):\n",
    "                        if info :\n",
    "                            score=info.split(\"\\t\")[5]\n",
    "                            outfile.write(f\"{strain},{score}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 2. FastANI computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "> The actual command "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# *******************************************************************************************************************************************\n",
    "# The fastANI command :\n",
    "# *******************************************************************************************************************************************\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "path_phageboot_info=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_info\"\n",
    "path_phageboost_pred=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_prediction\"\n",
    "path_fastANI_2=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_similarity/phageboost/fastANI_20102022\"\n",
    "path_ktype=\"/home/conchae/prediction_depolymerase_tropism\"\n",
    "\n",
    "\n",
    "    # But first, the strain_ktype dictionary :\n",
    "strain_ktype={}\n",
    "good_strain=open(f\"{path_ktype}/results_kleborate_count.tsv\").read().split(\"\\n\")\n",
    "for index_strain, info in enumerate(good_strain):\n",
    "    if info:\n",
    "        strain=info.split(\"\\t\")[0].strip()\n",
    "        ktype=info.split(\"\\t\")[2].strip()\n",
    "        strain_ktype[strain]=ktype\n",
    "\n",
    "with open(f\"{path_phageboot_info}/results_phageboost.70.20102022.tsv\",\"w\") as outfile1 :\n",
    "    outfile1.write(f\"Prophage_name\\tProphage_length\\tN_genes\\tScore\\tK_type\\n\")\n",
    "    for strain in tqdm(os.listdir(path_phageboost_pred)):\n",
    "        # Opening the resume file of phageboost prediction :\n",
    "        for file in os.listdir(f\"{path_phageboost_pred}/{strain}\"):\n",
    "            if file[0:6]==\"phages\":\n",
    "                try :\n",
    "                    resume= pd.read_csv(f\"{path_phageboost_pred}/{strain}/{file}\", skiprows=1, sep=\"\\t\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Seems like there is no prophage for \")\n",
    "                #Scanning the file for phage with a score > 0.70\n",
    "                for index_info, info in resume.iterrows():\n",
    "                    if float(info[\"score\"])>= 0.70 :\n",
    "                        # Getting the prophage info :\n",
    "                        prophage_id= info[\"attributes\"].split(\"phage_id=\")[1]\n",
    "                        prophage_len= int(info[\"start\"]) -int(info[\"end\"])\n",
    "                        n_genes= info[\"attributes\"].split(\"n_genes=\")[1].split(\";\")[0]\n",
    "                        for file2 in os.listdir(f\"{path_phageboost_pred}/{strain}\"):\n",
    "                            if file2.count(prophage_id)>0:\n",
    "                                seq=open(f\"{path_phageboost_pred}/{strain}/{file2}\").read().split(\"\\n\")[1]\n",
    "                                if os.path.isfile(f\"{path_fastANI_2}/{strain}__{prophage_id}.fasta\")==False:\n",
    "                                    with open(f\"{path_fastANI_2}/{strain}__{prophage_id}.fasta\",\"w\") as outfile :\n",
    "                                        outfile.write(f\">{strain}__{prophage_id}\\n{seq}\")\n",
    "                        outfile1.write(f\"{strain}__{prophage_id}\\t{str(prophage_len)}\\t{n_genes}\\t{info['score']}\\t{strain_ktype[strain]}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#*****************************************************************************************************************************************\n",
    "#!/bin/bash\n",
    "#BATCH --job-name=writting_phb\n",
    "#SBATCH --partition=small \n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=5\n",
    "#SBATCH --mem=15gb \n",
    "#SBATCH --time=0-05:00:00 \n",
    "#SBATCH --output=writting_phb%j.log \n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate ScaleAP\n",
    "\n",
    "python3 /home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_similarity/phageboost/script_files/py_files/prepare_fastani.20102022.py\n",
    "\n",
    "#*****************************************************************************************************************************************        \n",
    "# Step 2 :\n",
    "# Writting the path file :\n",
    "\n",
    "with open(f\"{path_phageboot_info}/fastANI_list.20102022.tsv\",\"w\") as outfile :\n",
    "    for file in tqdm(os.listdir(path_fastANI_2)):\n",
    "        outfile.write(f\"{path_fastANI_2}/{file}\\n\")\n",
    "        \n",
    "        \n",
    "#*****************************************************************************************************************************************    \n",
    "# Step 3 :        \n",
    "# fatANI commands : \n",
    "\n",
    "#!/bin/bash\n",
    "#BATCH --job-name=fatANI_phb\n",
    "#SBATCH --partition=medium \n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=40\n",
    "#SBATCH --mem=200gb \n",
    "#SBATCH --time=4-00:00:00 \n",
    "#SBATCH --output=fatANI_phb%j.log \n",
    "\n",
    "module restore la_base\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate fastani\n",
    "\n",
    "fastANI  --ql /home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_info/fastANI_list.20102022.tsv --rl /home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_info/fastANI_list.20102022.tsv -o /home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_similarity/phageboost/fastANI_out_20102022  --matrix  -t 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 3. Inspecting FastANI output \n",
    "\n",
    "> First round inspection : Get the pairs of prophages with a ANI score>0.99 and coverage > 80%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *******************************************************************************************************************************************\n",
    "# Inspecting the fastANI outputs :\n",
    "# *******************************************************************************************************************************************\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "path_fastani=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_similarity/phageboost/fastANI_20102022_out\"\n",
    "path_ktype=\"/home/conchae/prediction_depolymerase_tropism\"\n",
    "\n",
    "# Generating the dico with the k_type info for each strain\n",
    "strain_ktype={}\n",
    "good_strain=open(f\"{path_ktype}/results_kleborate_count.tsv\").read().split(\"\\n\")\n",
    "for index_strain, info in enumerate(good_strain):\n",
    "    if info:\n",
    "        strain=info.split(\"\\t\")[0].strip()\n",
    "        ktype=info.split(\"\\t\")[2].strip()\n",
    "        strain_ktype[strain]=ktype\n",
    "    \n",
    "fastani_names = [\"Query\",\"Reference_genome\",\"ANI\",\"fragments\",\"total_fragments\"]\n",
    "fastani_df = pd.read_csv(f\"{path_fastani}/fastANI_out_20102022\",sep=\"\\t\", names = fastani_names, nrows=10000)\n",
    "\n",
    "\n",
    "families = []\n",
    "fastani_dict = fastani_df.to_dict('records')\n",
    "for row in tqdm(fastani_dict) :\n",
    "    if float(row[\"ANI\"]) >=99 and float(row[\"fragments\"])/float(row[\"total_fragments\"])>=0.80:\n",
    "        prophage_1 = row[\"Query\"].split(\"/\")[-1]\n",
    "        prophage_2 = row[\"Reference_genome\"].split(\"/\")[-1]\n",
    "        pair = [prophage_1, prophage_2]\n",
    "        for cluster in families :\n",
    "            if prophage_1 in cluster or prophage_2 in cluster: \n",
    "                cluster.add(prophage_1)\n",
    "                cluster.add(prophage_2)\n",
    "                break\n",
    "        else :\n",
    "            cluster = set()\n",
    "            cluster.add(prophage_1)\n",
    "            cluster.add(prophage_2)\n",
    "            families.append(cluster)\n",
    "\n",
    "with open(f\"{path_fastani}/clusters_99_80.info.tsv\",'w') as outfile :\n",
    "    with open(f\"{path_fastani}/clusters_99_80.tsv\",'w') as outfile_cluster :\n",
    "        outfile.write(\"Family_index\\tMember\\n\")\n",
    "        outfile_cluster.write(\"Family_index\\tMembers\\n\")\n",
    "        for index_c, cluster in enumerate(families) :\n",
    "            outfile_cluster.write(f\"{index_c}\\t\")\n",
    "            cluster_c_l = []\n",
    "            for member in cluster :\n",
    "                outfile.write(f\"family {index_c}\\t{member}\\n\")\n",
    "                cluster_c_l.append(member)\n",
    "            outfile_cluster.write(\",\".join(cluster_c_l))\n",
    "            outfile_cluster.write(\"\\n\")\n",
    "\n",
    "# *******************************************************************************************************************************************                    \n",
    "#!/bin/bash\n",
    "#BATCH --job-name=post_ANI2_\n",
    "#SBATCH --partition=short \n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem=10gb \n",
    "#SBATCH --time=1-00:00:00 \n",
    "#SBATCH --output=post_ANI2_%j.log \n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate ScaleAP\n",
    "\n",
    "python3 /home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_similarity/phageboost/script_files/py_files/post_fastani.20102022.py\n",
    "# *******************************************************************************************************************************************                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fix the families "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Check the integrety of the DF :\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "path_fastani=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_similarity/phageboost/fastANI_20102022_out\"\n",
    "path_phages = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_similarity/phageboost/fastANI_20102022\"\n",
    "path_ktype=\"/home/conchae/prediction_depolymerase_tropism\"\n",
    "\n",
    "families = pd.read_csv(f\"{path_fastani}/clusters_99_80.tsv\", header = 0, sep='\\t')\n",
    "families_set = [set(fam.split(\",\")) for fam in families[\"Members\"]]\n",
    "\n",
    "clean_families = []\n",
    "for index_set, cluster in tqdm(enumerate(families_set)) :\n",
    "    clean_cluster = cluster.copy()\n",
    "    #print(clean_cluster)\n",
    "    for index_2, cluster_2 in enumerate(families_set):\n",
    "        if clean_cluster.isdisjoint(cluster_2) == False :\n",
    "            clean_cluster.update(cluster_2)\n",
    "            continue\n",
    "        else :\n",
    "            continue\n",
    "    #print(clean_cluster)\n",
    "    if clean_cluster not in clean_families :\n",
    "        clean_families.append(clean_cluster)\n",
    "        \n",
    "\n",
    "# Repeat the iteration : \n",
    "clean_families_2 = []\n",
    "for index_set, cluster in tqdm(enumerate(clean_families)) :\n",
    "    clean_cluster = cluster.copy()\n",
    "    for index_2, cluster_2 in enumerate(clean_families):\n",
    "        if clean_cluster.isdisjoint(cluster_2) == False :\n",
    "            clean_cluster.update(cluster_2)\n",
    "            continue\n",
    "        else :\n",
    "            continue\n",
    "    if clean_cluster not in clean_families_2 :\n",
    "        clean_families_2.append(clean_cluster)\n",
    "\n",
    "# *******************************************************************************************************************************************************************\n",
    "n_iteration = 10\n",
    "clean_families = []\n",
    "for n in range(n_iteration):\n",
    "    tmp_families = []\n",
    "    for index_set, cluster in tqdm(enumerate(clean_families)) :\n",
    "        clean_cluster = cluster.copy()\n",
    "        #print(clean_cluster)\n",
    "        for index_2, cluster_2 in enumerate(families_set):\n",
    "            if clean_cluster.isdisjoint(cluster_2) == False :\n",
    "                clean_cluster.update(cluster_2)\n",
    "                continue\n",
    "            else :\n",
    "                continue\n",
    "        #print(clean_cluster)\n",
    "        if clean_cluster not in clean_families :\n",
    "            clean_families.append(clean_cluster)\n",
    "    \n",
    "    \n",
    "\n",
    "# *******************************************************************************************************************************************************************\n",
    "        \n",
    "with open(f\"{path_fastani}/clusters_99_80.clean.tsv\",\"w\") as outfile :\n",
    "    outfile.write(\"Family_index\\tMembers\\n\")\n",
    "    phages = set()\n",
    "    for index_f, family in tqdm(enumerate(clean_families_2)) :\n",
    "        cluster_list = \",\".join(list(family))\n",
    "        outfile.write(f\"Family_{index_f}\\t{cluster_list}\\n\")\n",
    "    for phage in tqdm(os.listdir(path_phages)):\n",
    "        for index_f, family in enumerate(clean_families_2):\n",
    "            if phage in family :\n",
    "                break\n",
    "        else :\n",
    "            outfile.write(f\"Loner\\t{phage}\\n\")\n",
    "            \n",
    "            \n",
    "# Check the integrity of the files :\n",
    "cluster = pd.read_csv(f\"{path_fastani}/clusters_99_80.clean.tsv\", header = 0, sep=\"\\t\")\n",
    "phages = []\n",
    "cluster_dict = cluster.to_dict(\"records\")\n",
    "\n",
    "for row in tqdm(cluster_dict) :\n",
    "    for member in row[\"Members\"].split(\",\") :\n",
    "        phages.append(member)\n",
    "        \n",
    "loners_df = cluster[cluster[\"Family_index\"]==\"Loner\"]\n",
    "fammmm_df = cluster[cluster[\"Family_index\"]!=\"Loner\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Create directory phageboost with the new prophage name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre step : \n",
    "# Create a tmp with all the candidates :\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "path_phageboost_pred=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_prediction\"\n",
    "path_fasta=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_similarity/phageboost/fastANI_20102022\"\n",
    "path_fastani=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_similarity/phageboost/fastANI_out_20102022\"\n",
    "path_decipher = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "path_ktype=\"/home/conchae/prediction_depolymerase_tropism\"\n",
    "\n",
    "\n",
    "# Generating the dico with the k_type info for each strain\n",
    "strain_ktype={}\n",
    "good_strain=open(f\"{path_ktype}/results_kleborate_count.tsv\").read().split(\"\\n\")\n",
    "for index_strain, info in enumerate(good_strain):\n",
    "    if info:\n",
    "        strain=info.split(\"\\t\")[0].strip()\n",
    "        ktype=info.split(\"\\t\")[1].strip()\n",
    "        strain_ktype[strain]=ktype\n",
    "        \n",
    "\n",
    "for phage in tqdm(os.listdir(path_fasta)):       \n",
    "    strain=phage.split(\"\\t\")[0].split(\"__\")[0]\n",
    "    prophage_id=phage.split(\"\\t\")[0].split(\"__\")[1].split(\".fasta\")[0]\n",
    "    prophage=phage.split(\"\\t\")[0].split(\".fasta\")[0]\n",
    "    print(strain,prophage_id,prophage)\n",
    "    try :\n",
    "        os.mkdir(f\"{path_decipher}/{strain}\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    if os.path.isfile(f\"{path_decipher}/{strain}/{prophage}\")== False :\n",
    "        copy_fasta = f\"cp {path_fasta}/{prophage}.fasta {path_decipher}/{strain}/{prophage}.fasta\"\n",
    "        copy_fasta_process = subprocess.Popen(copy_fasta, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "        press_out, press_err = copy_fasta_process.communicate()\n",
    "    genecall=pd.read_csv(f\"{path_phageboost_pred}/{strain}/genecalls_{strain.split('.')[0]}.gff3\", sep=\"\\t\")\n",
    "    for file in os.listdir(f\"{path_phageboost_pred}/{strain}\"):\n",
    "        if file[0:6]==\"phages\":\n",
    "            resume= pd.read_csv(f\"{path_phageboost_pred}/{strain}/{file}\", skiprows=1, sep=\"\\t\")\n",
    "            break\n",
    "    print(resume)\n",
    "    attributes = resume[\"attributes\"].to_list()\n",
    "    for index_att, attri in enumerate(attributes):\n",
    "        if attri.split(\"phage_id=\")[1] == prophage_id :\n",
    "            attribute_line = attri\n",
    "            break\n",
    "    frag_id = resume[resume[\"attributes\"] == attribute_line][\"#seqid\"].values[0]\n",
    "    start_genome ,stop_genome =resume[resume[\"attributes\"] == attribute_line][\"start\"].values[0], resume[resume[\"attributes\"] == attribute_line][\"end\"].values[0]\n",
    "    print(frag_id ,start_genome, stop_genome)\n",
    "    #break\n",
    "    genecall_frag = genecall[genecall[\"contig\"] == frag_id]\n",
    "    genecall_frag_dict = genecall_frag.to_dict('records')\n",
    "    with open(f\"{path_decipher}/{strain}/{prophage_id}.multi.candidates.faa\", \"w\") as outfile_faa :\n",
    "        with open(f\"{path_decipher}/{strain}/{prophage_id}.multi.candidates.ffn\", \"w\") as outfile_ffn :\n",
    "            for line in genecall_frag_dict : \n",
    "                if line[\"start\"] in range(start_genome, stop_genome) :\n",
    "                    nt_seq, aa_seq, prot_id =line[\"DNAseq\"] , line[\"AAseq\"],  line[\"id\"]\n",
    "                    print(len(aa_seq), \"Protein_id : \", prot_id)\n",
    "                    if len(aa_seq) > 200 :\n",
    "                        outfile_faa.write(f\">{strain}__{prophage_id}__{prot_id}\\n{aa_seq}\\n\")\n",
    "                        outfile_ffn.write(f\">{strain}__{prophage_id}__{prot_id}\\n{nt_seq}\\n\")\n",
    "                        print(f\">{strain}__{prophage_id}__{prot_id}\\n{aa_seq}\\n\", f\">{strain}__{prophage_id}__{prot_id}\\n{nt_seq}\\n\")\n",
    "                \n",
    "    \n",
    "# *******************************************************************************************************************************************************************\n",
    "#!/bin/bash\n",
    "#BATCH --job-name=candidates\n",
    "#SBATCH --partition=short \n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem=10gb \n",
    "#SBATCH --time=1-00:00:00 \n",
    "#SBATCH --output=candidates%j.log \n",
    "\n",
    "module restore la_base\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate ScaleAP\n",
    "\n",
    "python /home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_similarity/phageboost/script_files/py_files/post_fastani_pt3.py\n",
    "# *******************************************************************************************************************************************************************\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "path_phageboost_pred=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_prediction\"\n",
    "path_fasta=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_similarity/phageboost/fastANI_20102022\"\n",
    "path_fastani=\"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_similarity/phageboost/fastANI_out_20102022\"\n",
    "path_decipher = \"/home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_decipher/phageboost/phageboost_70_20102022\"\n",
    "path_ktype=\"/home/conchae/prediction_depolymerase_tropism\"\n",
    "\n",
    "\n",
    "for strain in os.listdir(path_decipher):\n",
    "    try :\n",
    "        os.mkdir (f\"{path_decipher}/{strain}/hmmer_out\")\n",
    "        os.mkdir (f\"{path_decipher}/{strain}/tmp\")\n",
    "    except FileExistsError :\n",
    "        pass\n",
    "    hmmer_out=f\"{path_decipher}/{strain}/hmmer_out\"\n",
    "    tmp=f\"{path_decipher}/{strain}/tmp\"\n",
    "    for file in os.listdir(f\"{path_decipher}/{strain}\"):\n",
    "        if file[-14:]==\"candidates.faa\":\n",
    "            candidates= open(f\"{path_decipher}/{strain}/{file}\").read().split(\">\")\n",
    "            prophage_name=file.split(\".\")[0]\n",
    "            try :\n",
    "                os.mkdir (f\"{tmp}/{prophage_name}\")\n",
    "                os.mkdir (f\"{hmmer_out}/{prophage_name}\")\n",
    "            except FileExistsError :\n",
    "                pass\n",
    "            path_out=f\"{hmmer_out}/{prophage_name}\"\n",
    "            for index_seq, seq_faa in enumerate(candidates) :\n",
    "                if seq_faa :\n",
    "                    seq_name=seq_faa.split(\"\\n\")[0]\n",
    "                    if os.path.isfile(f\"{tmp}/{prophage_name}/{seq_name}.fasta\")== False :\n",
    "                        with open(f\"{tmp}/{prophage_name}/{seq_name}.fasta\",\"w\") as outfile :\n",
    "                            outfile.write(f\">{seq_faa}\")\n",
    "\n",
    "# *******************************************************************************************************************************************\n",
    "#!/bin/bash\n",
    "#BATCH --job-name=tmp_file\n",
    "#SBATCH --partition=short \n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=5\n",
    "#SBATCH --mem=10gb \n",
    "#SBATCH --time=1-00:00:00 \n",
    "#SBATCH --output=tmp_file%j.log \n",
    "\n",
    "module restore la_base                                \n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate ScaleAP\n",
    "                                                      \n",
    "python /home/conchae/prediction_depolymerase_tropism/prophage_prediction/prophage_similarity/phageboost/script_files/py_files/create_tmp.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
